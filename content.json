{"meta":{"title":"FYF's Blog","subtitle":"欢迎来到我的blog","description":"Welcome to my world","author":"FYF","url":"https://fan-yu-feng.github.io"},"posts":[{"title":"git-commands","slug":"Git/git-commands","date":"2022-01-05T07:07:11.000Z","updated":"2022-01-07T03:43:00.646Z","comments":true,"path":"2022/01/05/Git/git-commands/","link":"","permalink":"https://fan-yu-feng.github.io/2022/01/05/Git/git-commands/","excerpt":"前言​    平时自以为 Git 一些比较简单的命令会使用了，就可以熟练的使用版本控制工具了；然而实际上每每遇到问题都要去网上查找解决方案，其中一些命令总是记不住，和小白差不多。因此想学习总结 Git 常用的命令。并通过不断的使用达到孰能生巧的地步。\n阮一峰的网络日志-git命令\nGit 官网","text":"前言​ 平时自以为 Git 一些比较简单的命令会使用了，就可以熟练的使用版本控制工具了；然而实际上每每遇到问题都要去网上查找解决方案，其中一些命令总是记不住，和小白差不多。因此想学习总结 Git 常用的命令。并通过不断的使用达到孰能生巧的地步。 阮一峰的网络日志-git命令 Git 官网 Git 流程原理 工作目录 workspace ：是本地放代码的地方。 暂存区 index：暂时存放你的修改的代码。 资源库 repository：稳定存放代码的本地区域。 远程仓库 remote ：托管代码的服务器。 git help 获取帮助第一种如下所示。verb 为命令，通过 git help 可以打开本地的 Git 综合手册。内容全面，就是挺长的，阅读起来可能难找到重点。 12git help &lt;verb&gt;git &lt;verb&gt; --help 第二种我比较推荐的，比较直观的获取命令的各种参数及说明。多使用这个命令可以很好的学习掌握 Git 各种命令。 12345678910111213141516171819202122232425git &lt;verb&gt; -h# example 查看 add 命令的参数$ git add -husage: git add [&lt;options&gt;] [--] &lt;pathspec&gt;... -n, --dry-run dry run -v, --verbose be verbose -i, --interactive interactive picking -p, --patch select hunks interactively -e, --edit edit current diff and apply -f, --force allow adding otherwise ignored files -u, --update update tracked files --renormalize renormalize EOL of tracked files (implies -u) -N, --intent-to-add record only the fact that the path will be added later -A, --all add changes from all tracked and untracked files --ignore-removal ignore paths removed in the working tree (same as --no-all) --refresh don&#x27;t add, only refresh the index --ignore-errors just skip files which cannot be added because of errors --ignore-missing check if - even missing - files are ignored in dry run --sparse allow updating entries outside of the sparse-checkout cone --chmod (+|-)x override the executable bit of the listed files --pathspec-from-file &lt;file&gt; read pathspec from file --pathspec-file-nul with --pathspec-from-file, pathspec elements are separated with NUL character 仓库管理初始化初始化仓库有两种方式，一种是在本地初始化未版本控制的目录。第二种是直接 clone 网上已存在的仓库。 123456# 第一种 在当前目录新建一个Git代码库git init# 新建一个目录，将其初始化为Git代码库git init [project-name]# 第二种 克隆项目git clone [url] 初始化结束后，会在项目目录中生成一个 .git 文件，版本控制的信息基本都在该目录中。 配置Git的设置文件为.gitconfig，它可以在用户主目录下(全局配置)，也可以在项目目录下(项目配置)。 使用帮助命令查看一些 配置命令的参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344$ git config -h usage: git config [&lt;options&gt;]# 查看 config 的命令参数Config file location # 使用配置生效位置 --global use global config file --system use system config file --local use repository config file --worktree use per-worktree config file -f, --file &lt;file&gt; use given config file --blob &lt;blob-id&gt; read config from given blob objectAction --get get value: name [value-pattern] --get-all get all values: key [value-pattern] --get-regexp get values for regexp: name-regex [value-pattern] --get-urlmatch get value specific for the URL: section[.var] URL --replace-all replace all matching variables: name value [value-pattern] --add add a new variable: name value --unset remove a variable: name [value-pattern] --unset-all remove all matches: name [value-pattern] --rename-section rename section: old-name new-name --remove-section remove a section: name -l, --list list all --fixed-value use string equality when comparing values to &#x27;value-pattern&#x27; -e, --edit open an editor --get-color find the color configured: slot [default] --get-colorbool find the color setting: slot [stdout-is-tty]Type -t, --type &lt;&gt; value is given this type --bool value is &quot;true&quot; or &quot;false&quot; --int value is decimal number --bool-or-int value is --bool or --int --bool-or-str value is --bool or string --path value is a path (file or directory name) --expiry-date value is an expiry dateOther -z, --null terminate values with NUL byte --name-only show variable names only --includes respect include directives on lookup --show-origin show origin of config (file, standard input, blob, command line) --show-scope show scope of config (worktree, local, global, system, command) --default &lt;value&gt; with --get, use default value when missing entry 先查看 config 文件配置列表，然后根据键值对去修改配置，只要掌握了这个，基本所有配置都可以修改。 1234567891011121314151617181920212223242526272829$ git config -lhttp.sslbackend=openssldiff.astextplain.textconv=astextplainfilter.lfs.clean=git-lfs clean -- %ffilter.lfs.smudge=git-lfs smudge -- %ffilter.lfs.process=git-lfs filter-processfilter.lfs.required=truecredential.helper=manager-corecore.autocrlf=truecore.fscache=truehttp.sslbackend=openssldiff.astextplain.textconv=astextplainfilter.lfs.clean=git-lfs clean -- %ffilter.lfs.smudge=git-lfs smudge -- %ffilter.lfs.process=git-lfs filter-processfilter.lfs.required=truecredential.helper=manager-corecore.autocrlf=truecore.fscache=truecore.symlinks=false ...# 如设置本地的用户和账号$ git config [--local] user.name &quot;[name]&quot;$ git config [--local] user.email &quot;[email address]&quot;http.sslbackend=openssl# 设置连接方式为 openssl 或 schannelgit config --global http.sslbackend openssl | schannel # 设置 Sll 连接为 false git config --global http.sslVerify &quot;false&quot; 增加、删除新增和删除文件到暂存区中，命令一般为 git add 和 git rm。这部分可以使用帮助命令查看参数，这里列举常用的命令，其余基本和配置类似。 123456789101112131415# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 提交将代码提交到本地的仓库区域。使用 commit 命令。 123456789101112131415# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 将add和commit合为一步$ git commit -am &#x27;message&#x27;# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 同步代码同步则是指将远程仓库的代码同步到本地仓库代码、本地仓库更新代码推送到远程仓库。 123456789101112131415161718# 同步以及推送$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并 撤销撤销则是指在暂存区上的文件取消保存、将工作区的文件重置到上一次 commit，如果是取消暂存区保存则用 checkout，如果将工作区和暂存区的文件重置到上一次 commit 则用 reset。 12345678910111213141516171819202122# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 分支1234567891011121314151617181920212223242526272829303132333435# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]# 检出版本v2.0$ git checkout v2.0# 从远程分支develop创建新本地分支devel并检出$ git checkout -b devel origin/develop# 检出head版本的README文件（可用于修改错误回退）git checkout -- README 查看信息1234567891011121314151617181920212223242526272829303132333435363738394041# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 标签123456789101112131415161718# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 其他123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384git init # 初始化本地git仓库（创建新仓库）git config --global user.name &quot;xxx&quot; # 配置用户名git config --global user.email &quot;xxx@xxx.com&quot; # 配置邮件git config --global --unset http.proxy # remove proxy configuration on gitgit commit -m &#x27;xxx&#x27; # 提交git commit --amend -m &#x27;xxx&#x27; # 合并上一次提交（用于反复修改）git commit -am &#x27;xxx&#x27; # 将add和commit合为一步git rm xxx # 删除index中的文件git rm -r * # 递归删除git log # 显示提交日志git log -1 # 显示1行日志 -n为n行git log --stat # 显示提交日志及相关变动文件git log -p -mgit show [commit log] # 显示某个提交的详细内容git show dfb02 # 可只用commitid的前几位git show HEAD # 显示HEAD提交日志git show HEAD^ # 显示HEAD的父（上一个版本）的提交日志 ^^为上两个版本 ^5为上5个版本git tag # 显示已存在的taggit tag -a v2.0 -m &#x27;xxx&#x27; # 增加v2.0的taggit show v2.0 # 显示v2.0的日志及详细内容git log v2.0 # 显示v2.0的日志git diff # 显示所有未添加至index的变更git diff --cached # 显示所有已添加index但还未commit的变更git diff HEAD^ # 比较与上一个版本的差异git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异git diff origin/master..master # 比较远程分支master上有本地分支master上没有的git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容# 增加远程仓库关联（用于push/pull/fetch）git remote add origin [url]git branch # 显示本地分支git branch --contains 50089 # 显示包含提交50089的分支git branch -a # 显示所有分支git branch -r # 显示所有原创分支git branch --merged # 显示所有已合并到当前分支的分支git branch --no-merged # 显示所有未合并到当前分支的分支git branch -m master master_copy # 本地分支改名git checkout -b master_copy # 从当前分支创建新分支master_copy并检出git checkout -b master master_copy # 上面的完整版git checkout features/performance # 检出已存在的features/performance分支git checkout --track hotfixes/BJVEP933 # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支git checkout v2.0 # 检出版本v2.0git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出git checkout -- README # 检出head版本的README文件（可用于修改错误回退）git merge origin/master # 合并远程master分支至当前分支git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改git push origin master # 将当前分支push到远程master分支git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支git push --tags # 把所有tag推送到远程仓库# 获取所有远程分支（不更新本地分支，另需merge）git fetch # 获取所有原创分支并清除服务器上已删掉的分支 git fetch --prune # 获取远程分支master并merge到当前分支git pull origin master git mv README README2 # 重命名文件README为README2git reset --hard HEAD # 将当前版本重置为HEAD（通常用于merge失败回退）git rebasegit branch -d hotfixes/BJVEP933 # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支）git branch -D hotfixes/BJVEP933 # 强制删除分支hotfixes/BJVEP933git ls-files # 列出git index包含的文件git show-branch # 图示当前分支历史git show-branch --all # 图示所有分支历史git whatchanged # 显示提交历史对应的文件修改git revert dfb02e6e4f2f7b573337763e5c0013802e392818 # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818git ls-tree HEAD # 内部命令：显示某个git对象git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASHgit reflog # 显示所有提交，包括孤立节点git show HEAD@&#123;5&#125;git show master@&#123;yesterday&#125; # 显示master分支昨天的状态git log --pretty=format:&#x27;%h %s&#x27; --graph # 图示提交日志git show HEAD~3git show -s --pretty=raw 2be7fcb476git stash # 暂存当前修改，将所有至为HEAD状态git stash list # 查看所有暂存git stash show -p stash@&#123;0&#125; # 参考第一次暂存git stash apply stash@&#123;0&#125; # 应用第一次暂存git grep &quot;delete from&quot; # 文件中搜索文本“delete from”git grep -e &#x27;#define&#x27; --and -e SORT_DIRENTgit gcgit fsck# 生成一个可供发布的压缩包$ git archive 带薪刷题的一小时，然后 leetcode 就崩了， emo了。","raw":null,"content":null,"categories":[{"name":"Git","slug":"Git","permalink":"https://fan-yu-feng.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://fan-yu-feng.github.io/tags/Git/"}]},{"title":"实验0 C++ Primer （2020）","slug":"CMU/cmu-lab-c","date":"2021-12-31T07:29:41.000Z","updated":"2022-01-25T09:35:19.219Z","comments":true,"path":"2021/12/31/CMU/cmu-lab-c/","link":"","permalink":"https://fan-yu-feng.github.io/2021/12/31/CMU/cmu-lab-c/","excerpt":"前言由于完成整个课程实验需要有 C++ 的基础，然而2019年没有 C++ 相关的实验，因此该实验室2020年版本的，在 2019 年并没有该实验。下面是实验地址。\nPROJECT #0 C++ PRIMER","text":"前言由于完成整个课程实验需要有 C++ 的基础，然而2019年没有 C++ 相关的实验，因此该实验室2020年版本的，在 2019 年并没有该实验。下面是实验地址。 PROJECT #0 C++ PRIMER 实验要求实现三个类，Matrix, RowMatrix, and RowMatrixOperations,这些矩阵为二维矩阵，你实现的类必须能完成矩阵加、乘以及 General Matrix Multiply (GEMM) 操作。 下面是实验说明。 只需修改单个文件： p0_starter.h 文件目录：src/include/primer/p0_starter.h. 在这个头文件只需要实现三个类。 Matrix 为抽象类，定义公有的函数，RowMatrix为其派生类。 RowMatrixOperations使用 RowMatrix的功能函数去完成实验要求的操作。 实现所有的构造器、解析器、成员函数。 不能添加额外的函数或成员变量，只能使用定义好的函数。 设置实验环境由于之前已经完成了课程环境的搭建，详情请看这篇 CMU环境搭建 测试1234$ mkdir build$ cd build$ make starter_test$ ./test/starter_test 其中 DISABLED 的就是未完成的实验。 代码格式Your code must follow the Google C++ Style Guide. We use Clang to automatically check the quality of your source code. Your project grade will be zero if your submission fails any of these checks. 12345# 代码格式化$ make format# 检查代码格式，将错误的地方打印出来$ make check-lint$ make check-clang-tidy 日志Instead of using printf statements for debugging, use the LOG_* macros for logging information like this: 根据日志的打印级别打印日志信息。 12LOG_INFO(&quot;# Pages: %d&quot;, num_pages);LOG_DEBUG(&quot;Fetching page %d&quot;, page_id); 日志打印配置 1234$ mkdir build$ cd build$ cmake -DCMAKE_BUILD_TYPE=DEBUG ..$ make 日志文件头：位于src/include/common/logger.h，默认日志等级为 LOG_LEVEL_INFO ，当使用日志打印的时候，需要在文件中添加头文件。#include &quot;common/logger.h&quot;。 鼓励使用 gdb 去 debug 实验。 实现过程 说实话，第一眼看到整个 starter_test.cpp 代码没看懂，要再去补习一下C++了… 隔了几个星期，回来填坑了，C++也是工作之余一边刷题leetcode一边学习，学的比较慢。说实话，学 C++ 的过程，模板 STL 、指针、引用搞得有点头疼，现在也还是有点晕。不过 C++ 的内存管理机制是我比较感兴趣的点。后面继续学习慢慢理解不懂的点。 src/include/primer/p0_starter.h.这个头文件中实现三个类 Matrix 基类矩阵，作为派生类，类似 Java 的父类，抽象矩阵的方法和属性， RowsMatrix 派生类矩阵，继承基类 Matrix RowMatrixOperations 矩阵操作类，实现矩阵的操作，也就是本实验的矩阵加、乘以及GEMM Matrix 基类矩阵要求： 在构造函数中对 rows，cols 进行赋值，然后为 linear 指针分配空间 在析构函数中释放分配给 linear 的空间 知识点： 初始化构造函数 ： C++构造函数&amp;析构函数 为数组分配内存空间 123// 动态方式 new malloc linear_ = new T[rows * cols];linear_ = (T*)malloc(rows * cols *sizeof(T)) 在析构函数中释放空间 1delete[] linear_; RowsMatrix 派生类矩阵要求： 为二维数组 data_ 在构造函数中分配空间 在析构函数中释放 data_ 空间 获取行数、获取列数，设置下标为 i、j 的 data_ 值、获取下标为 i、j 的 data_ 值。 使用一维数组 source 的值分配给 data_ 知识点： 二维数组分配内存 释放二维数组内存 1234567891011121314151617181920212223242526272829// 二维数组分配空间// 固定方式 1、常量 2、宏 // 1、常量 const int M = 100;const int N = 200;int arr[M][N];// 2、宏定义#define M 100#define N 200int arr[M][N];// 非固定方式：1、二维数组空间不连续；2、二维数组存放在一组连续空间内// 1、二维数组空间不连续for(int i=0;i&lt;M;i++) arr[i] = new int[N];// 1.1 释放空间 for(int i=0;i&lt;M;i++) delete[] arr[i]; delete[] arr; arr = nullptr;// 2、二维数组存放在一组连续空间内int **arr = new int*[M];int *buffer = new int[M*N];for(int i=0;i&lt;M;i++) arr[i] = buffer+i*N;// 2.1 释放空间 delete []buffer; buffer = nullptr; delete []arr; arr = nullptr; RowMatrixOperations 矩阵操作类在进行矩阵操作类实现之前需要学习：unique_ptr 智能指针， &lt;memory&gt; c + + 标准库的标头中定义的内容。 unique_ptr 参考链接 好处：unique_ptr 不共享其指针，任意时刻指向资源的只有一个 unique_ptr ，方便管理，不容易出现内存泄漏等问题。 使用： 12345// 初始化数组 make_unique 但不能用来初始化数组// 如 初始化i*j 大小的 RowMatrix&lt;T&gt;std::unique_ptr&lt;RowMatrix&lt;T&gt;&gt; res = std::make_unique&lt;RowMatrix&lt;T&gt;&gt;(i, j);// 移动 unique_ptr 使用 move(matrixA)RowMatrix&lt;T&gt; *matrix = std::move(res); 实现矩阵加法：矩阵加法实现比较简单，在做加法操作之前，判断下标是否合法，也就是两个矩阵的行和列相等。在进行矩阵加法操作。 实现矩阵乘法 具体内容查看 矩阵乘法百度百科 。矩阵乘法之前线性代数学过，不过实现起来老是碰壁，归根也是没有理解。现在重新学习了下，有几个注意的点： 当矩阵A的列数（column）等于矩阵B的行数（row）时，A与B可以相乘。 如下图所示 实现矩阵 GEMM 实现过程如下。其他的便不贴了，自行实现。 1234567static std::unique_ptr&lt;RowMatrix&lt;T&gt;&gt; GEMM(const RowMatrix&lt;T&gt; *matrixA, const RowMatrix&lt;T&gt; *matrixB,const RowMatrix&lt;T&gt; *matrixC) &#123; // TODO(P0): Add implementation std::unique_ptr&lt;RowMatrix&lt;T&gt;&gt; matrix(new RowMatrix&lt;T&gt;(matrixA-&gt;GetRowCount(),matrixB-&gt;GetColumCount())); matrix = Multiply(std::move(matrixA), std::move(matrixB)); if (matrix != nullptr) return Add(matrix, matrixC); return matrix;&#125; 写完 code 后，去进行测试。发现都是 DISABLED，后面查明原因是需要在 test\\primer\\starter_test.cpp 文件夹下，把前缀 DISABLED_ 删除才能进行测试。 将 DISABLED_ 前缀删除 完成实验","raw":null,"content":null,"categories":[{"name":"CMU","slug":"CMU","permalink":"https://fan-yu-feng.github.io/categories/CMU/"}],"tags":[{"name":"CMU","slug":"CMU","permalink":"https://fan-yu-feng.github.io/tags/CMU/"}]},{"title":"cmu 作业1","slug":"CMU/cmu-hw1","date":"2021-12-30T02:23:09.000Z","updated":"2021-12-31T09:40:48.669Z","comments":true,"path":"2021/12/30/CMU/cmu-hw1/","link":"","permalink":"https://fan-yu-feng.github.io/2021/12/30/CMU/cmu-hw1/","excerpt":"作业地址：2020 CMU 15-445 HW1 作业有说明环境及作业文件下载等数据。\n这个作业后面的有些题还是挺复杂的，训练逻辑思维还是可以的，不过工作的话，用不到这么复杂的语句。复杂的题也是想了很久才理清逻辑。\n完成该作业有 Sql基础知识 或了解 CTEs（Common Table Expressions）| CTEs  公用表达式会更好","text":"作业地址：2020 CMU 15-445 HW1 作业有说明环境及作业文件下载等数据。 这个作业后面的有些题还是挺复杂的，训练逻辑思维还是可以的，不过工作的话，用不到这么复杂的语句。复杂的题也是想了很久才理清逻辑。 完成该作业有 Sql基础知识 或了解 CTEs（Common Table Expressions）| CTEs 公用表达式会更好 Q1 [0 POINTS] (Q1_SAMPLE):The purpose of this query is to make sure that the formatting of your output matches exactly the formatting of our auto-grading script. Details: List all types of work ordered by type ascendingly. 1select name from work_type order by name Q2 [5 POINTS] (Q2_LONG_NAME):List works with longest name of each type. Details: For each work type, find works that have the longest names. There might be cases where there is a tie for the longest names - in that case, return all of them. Display work names and corresponding type names, and order it according to work type (ascending) and use work name (ascending) as tie-breaker. 123456789101112131415161718&#x2F;&#x2F; 每种类型最长名字分组 表: tem_workselect max(length(work.name)) as max_length,work.type as typefrom workgroup by work.type &#x2F;&#x2F; 和类型表取交集 select work.name,work_type.name from tem_work inner join work on work.type &#x3D; tem_work.type and tem_work.max_length &#x3D; length(work.name) inner join work_type on work_type.id &#x3D; work.typeorder by work.name asc, work.type asc;&#x2F;&#x2F; emmm 第二种实现方式select count(*)from (select max(length(work.name)) as max_length, work.name as name ,work.type as typefrom workgroup by work.type ) as tem_work inner join work_type on work_type.id &#x3D; tem_work.typeorder by tem_work.name asc, tem_work.type asc; Q3 [5 POINTS] (Q3_OLD_MUSIC_NATIONS):List top 10 countries with the most classical music artists (born or started before 1850) along with the number of associated artists. Details: Print country and number of associated arists before 1850. For example, Russia|191. Sort by number of artists in descending order. 12345678910# 条件：在1850年之前出生、限制 TOP10，# 查询：数目和国家名select count(*) as number,a.name from artist inner join area a on a.id = artist.areawhere begin_date_year &lt; 1850 group by areaorder by number desc limit 10 Q4 [10 POINTS] (Q4_DUBBED_SMASH):List the top 10 dubbed artist names with the number of dubs. Details: Count the number of distinct names in artist_alias for each artist in the artist table, and list only the top ten who’s from the United Kingdom and started after 1950 (not included). Print the artist name in the artist table and the number of corresponding distinct dubbed artist names in the artist_alias table. 123456789101112131415# 条件 英国地区、获得艺术家别名前十的艺术家、(艺术别名有重复 注意去重)# 查询 艺术家名称、别名数量# 获取英国的地区 id 为 221select * from area where area.name like &#x27;united%&#x27; select a.name,count(distinct al.name) as numfrom artist as ainner join artist_alias as alon al.artist = a.idwhere a.begin_date_year &gt; 1950and a.area = 221group by a.idorder by num desclimit 10; Q5 [10 POINTS] (Q5_VINYL_LOVER):List the distinct names of releases issued in vinyl format by the British band Coldplay. Details: Vinyl format includes ALL vinyl dimensions excluding VinylDisc. Sort the release names by release date ascendingly. 1234567891011121314# 查询 由 Coldplay 以 vinyl 格式发行的 releases # 按时间升序、格式以 Vinyl 结尾select distinct r1.name as rnamefrom artist_credit_name a1 inner join artist_credit a2 on a1.artist_credit = a2.id inner join release r1 on a2.id = r1.artist_credit inner join release_info r2 on r1.id = r2.release inner join medium m1 on r1.id = m1.release inner join medium_format m2 on m1.format = m2.idwhere a1.name = &#x27;Coldplay&#x27; and m2.name like &#x27;%Vinyl&#x27;order by date_year, date_month, date_day; Q6 [10 POINTS] (Q6_OLD_IS_NOT_GOLD):Which decades saw the most number of official releases? List the number of official releases in every decade since 1900. Like 1970s|57210. Details: Print all decades and the number of official releases. Releases with different issue dates or countries are considered different releases. Print the relevant decade in a fancier format by constructing a string that looks like this: 1970s. Sort the decades in decreasing order with respect to the number of official releases and use decade (descending) as tie-breaker. Remember to exclude releases whose dates are NULL. 123456789101112131415# 查询 relase 每十年发行的数量# 每十年|数量 在1900年之后,不同国家和不同 issue dates 算1条Select decade, count(*) as cntfrom ( select (CAST((date_year / 10) as int) * 10) || &#x27;s&#x27; as decade from release inner join release_info on release.id = release_info.release where release.status = 1 and date_year &gt;= 1900 )Group by decadeOrder by cnt desc, decade desc; Q7 [15 POINTS] (Q7_RELEASE_PERCENTAGE):List the month and the percentage of all releases issued in the corresponding month all over the world in the past year. Display like 2020.01|5.95. Details: The percentage of releases for a month is the number of releases issued in that month devided by the total releases in the past year from 07/2019 to 07/2020, both included. Releases with different issue dates or countries are considered different releases. Round the percentage to decimal places using ROUND(). Sort by dates in ascending order. 12345678910111213141516171819202122232425262728293031323334# 查询： 2019/07-2020/07 每个月分发行唱片的百分比 格式：2020.01|5.95# 条件： 时间：07/2019 to 07/2020、 按时间升序with past_year_release (year, month) as ( select date_year, date_month from release_info r1 inner join release r2 on r1.release = r2.id where ( ( date_year = 2019 and date_month &gt;= 7 ) or ( date_year = 2020 and date_month &lt;= 7 ) ))select cast(year as varchar) || &#x27;.&#x27; || ( case when month &lt; 10 then &#x27;0&#x27; else &#x27;&#x27; end ) || cast(month as varchar) as date, round( count(*) * 100.0 / ( select count(*) from past_year_release ), 2 )from past_year_releasegroup by dateorder by date; Q8 [15 POINTS] (Q8_COLLABORATE_ARTIST):List the number of artists who have collaborated with Ariana Grande. Details: Print only the total number of artists. An artist is considered a collaborator if they appear in the same artist_credit with Ariana Grande. The answer should include Ariana Grande herself. 12345678# 查询和 Ariana Grande 合作的艺术家数量Select count(distinct artist)From artist_credit_nameWhere artist_credit in ( select artist_credit from artist_credit_name where name = &#x27;Ariana Grande&#x27; ); Q9 [15 POINTS] (Q9_DRE_AND_EMINEM):List the rank, artist names, along with the number of collaborative releases of Dr. Dre and Eminem among other most productive duos (as long as they appear in the same release) both started after 1960 (not included). Display like [rank]|Dr. Dre|Eminem|[# of releases]. Details: For example, if you see a release by A, B, and C, it will contribute to three pairs of duos: A|B|1, A|C|1, and B|C|1. You will first need to calculate a rank of these duos by number of collaborated releases (release with artist_credit shared by both artists) sorted descendingly, and then find the rank of Dr. Dre and Eminem. Only releases in English are considered. Both artists should be solo artists. All pairs of names should have the alphabetically smaller one first. Use artist names (asc) as tie breaker. Hint: Artist aliases may be used everywhere. When doing aggregation, using artist ids will ensure you get the correct results. One example entry in the rank list is 9|Benj Pasek|Justin Paul|27 12345678910111213141516171819202122232425262728293031323334353637383940# 查询和 Dr. Dre、Eminem 合作的艺术家 格式 [顺序]|name|name|[# of releases]# 条件：1960年后、 与 Dr. Dre、Eminem 合作，release:英语、艺术家：独唱艺术家（Person）、升序with duos_list (id1, id2, count) as ( select a1.artist as id1, a2.artist as id2, count(*) as c from artist_credit_name a1 inner join artist_credit_name a2 on a1.artist_credit = a2.artist_credit inner join release r on a2.artist_credit = r.artist_credit inner join artist a3 on a1.artist = a3.id inner join artist a4 on a2.artist = a4.id inner join artist_type a5 on a3.type = a5.id inner join artist_type a6 on a4.type = a6.id inner join language l on r.language = l.id where a3.name &lt; a4.name and a5.name = &quot;Person&quot; and a6.name = &quot;Person&quot; and l.name = &#x27;English&#x27; and a3.begin_date_year &gt; 1960 and a4.begin_date_year &gt; 1960 group by a1.artist, a2.artist)select *from ( select row_number () over ( order by count desc, a1.name, a2.name ) as rank, a1.name as name1, a2.name as name2, count from duos_list d inner join artist a1 on d.id1 = a1.id inner join artist a2 on d.id2 = a2.id )where name1 = &#x27;Dr. Dre&#x27; and name2 = &#x27;Eminem&#x27;; Q10 [15 POINTS] (Q10_AROUND_THE_WORLD):Concat all dubbed names of The Beatles using comma-separated values(like “Beetles, fab four“). Details: Find all dubbed names of artist “The Beatles“ in artist_alias and order them by id (ascending). Print a single string containing all the dubbed names separated by commas. 12345678910111213141516171819202122232425with c as ( select row_number() over ( order by c.id asc ) as seqnum, c.name as name from artist_alias c join artist on c.artist = artist.id where artist.name = &#x27;The Beatles&#x27;),flattened as ( select seqnum, name as name from c where seqnum = 1 union all select c.seqnum, f.name || &#x27;, &#x27; || c.name from c join flattened f on c.seqnum = f.seqnum + 1)select namefrom flattenedorder by seqnum desclimit 1;","raw":null,"content":null,"categories":[{"name":"CMU","slug":"CMU","permalink":"https://fan-yu-feng.github.io/categories/CMU/"}],"tags":[{"name":"CMU","slug":"CMU","permalink":"https://fan-yu-feng.github.io/tags/CMU/"}]},{"title":"cmu 环境搭建","slug":"CMU/CMU-Lab0","date":"2021-12-29T01:48:36.000Z","updated":"2022-01-25T08:05:37.322Z","comments":true,"path":"2021/12/29/CMU/CMU-Lab0/","link":"","permalink":"https://fan-yu-feng.github.io/2021/12/29/CMU/CMU-Lab0/","excerpt":"\n前言 这里开始记录学习 CMU15-445 实现数据库的过程。学习数据库的实现过程，扩宽自己的知识面。\n 期望：学习完该课程，期望能对数据库有个比较深入的了解，同时，对 C++ 也有个比较全面的认识。","text":"前言 这里开始记录学习 CMU15-445 实现数据库的过程。学习数据库的实现过程，扩宽自己的知识面。 期望：学习完该课程，期望能对数据库有个比较深入的了解，同时，对 C++ 也有个比较全面的认识。 以下是课程地址，有 note 和 homework 以及实验的 pdf 等资料。 课程地址 2020 课程地址 2019 Github 地址 环境搭建个人需求 由于公司和自己电脑是不同的环境，期望搭建一个线上的环境进行实现，方便在不同电脑上进行同步的环境进行实验，这里我使用 Docker 来进行线上环境的搭建，个人开发者可以直接上传个性化的容器。 仓库搭建1、在 Github 上创建名为 bustub-private 的仓库，并设置该仓库为 Private 2、拉取代码到本地，名为 bustub-public 1git clone --bare https://github.com/cmu-db/bustub.git bustub-public 3、上传代码到你的 Github 仓库上 1234567$ cd bustub-public# student 为用户名# HTTPS 方式$ git push --mirror https://github.com/student/bustub-private.git# SSH 方式$ git push --mirror git@github.com:student/bustub-private.git 4、删除本地仓库，拉取自己账号的仓库 1234567 rm -rf bustub-public# HTTPS$ git clone https://github.com/student/bustub-private.git# SSH$ git clone git@github.com:student/bustub-private.git 5、添加 CMU 仓库为远程仓库 123456789git remote add public https://github.com/cmu-db/bustub.git# 验证一下远程是否添加成功git remote -vorigin https://github.com/student/bustub-private.git (fetch)origin https://github.com/student/bustub-private.git (push)public https://github.com/cmu-db/bustub.git (fetch)public https://github.com/cmu-db/bustub.git (push) 6、从远程仓库更新代码 1git pull public master Docker 环境配置没下载的在官网下载。 docker 下载 切换到本地仓库目录 1234567891011121314151617# 创建镜像文件docker build . -t bustub# 配置目录 其中 /D:/CMU/bustub-private 为 windows 本地仓库目录docker create -t -i --name bustub -v /D:/CMU/bustub-private:/bustub bustub bash# 如果系统为 linux 或 mac 可以切换到仓库目录运行以下命令docker create -t -i --name bustub -v $(pwd):/bustub bustub bash# 运行 bustub 镜像容器docker start -a -i bustub# 或者可以直接运行挂载目录:将本地的 /D:/CMU/bustub-private 目录和 ubuntu 下的 /bustub 目录进行绑定docker run -itd -v /D:/CMU/bustub-private:/bustub --name=bustub-lab -p 3316:22 fanyufeng/bustub:0.1# 进入容器docker exec -t -i bustub-lab /bin/bash 安装工具12345678910# 先执行apt-get update# ssh-clientapt-get install openssh-client#openssh-serverapt-get install openssh-server# sudoapt-get install sudo# vimapt-get install vim 运行 package.sh 安装环境我运行该文件出现如下错误。 $’\\r’:command not found : not found: 2: packages.sh: : not found: 13: packages.sh: 如图，运行脚本均报错，由于是 window 下文本使用的格式是 dos 命令行，和 unix 不一样，导致解析出错。我明明是 git clone 下来的仓库，不太明白为啥会错。 解决使用工具 dos2unix 文本转换工具，转换后运行既可 12apt-get install dos2unixdos2unix packages.sh 配置文件环境12345# 运行以下命令既可$ mkdir build$ cd build$ cmake ..$ make 完成操作后，既可在本地编辑代码，然后再容器上运行我们的代码 上传容器至个人账户123456# 查看容器 iddocker ps# 提交容器镜像docker commit -m=&quot;CMU实验环境初始化&quot; -a=&quot;fanyufeng&quot; 58afd1af2086 fanyufeng/bustub-lab:0.1# 推送到 docker 的个人账户docker push fanyufeng/ubuntu-cmu:1.0 参数说明 -m: 提交的描述信息 -a: 指定镜像作者 58afd1af2086：容器 id fanyufeng/bustub-lab:0.1 指定要创建的目标镜像名 ssh 连接容器安装 ssh-client 命令1apt-get install openssh-client 等待，输入 Y 就可以了 安装 ssh-server 命令1apt-get install openssh-server 等待，输入 Y 就可以了 安装完成后，先启动服务#1&#x2F;etc&#x2F;init.d&#x2F;ssh start 查看是否正确启动 1ps -e|grep ssh 编辑 sshd_config 文件需要先安装 vim 编辑器1apt-get install vim 编辑 sshd_config 文件123vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config# 添加PermitRootLogin yes 保存退出 ESC + : + WQ 重启 ssh 服务1service ssh restart 设置 ssh 密码1passwd root 查看容器的 IP先安装 net-tools 工具包1apt-get install net-tools 查看 IP1ifconfig 连接运行钱 映射的断开 3316 映射到 容器的 22 端口，如图，进行连接既可。 然后连接就可以了","raw":null,"content":null,"categories":[{"name":"CMU","slug":"CMU","permalink":"https://fan-yu-feng.github.io/categories/CMU/"}],"tags":[{"name":"CMU","slug":"CMU","permalink":"https://fan-yu-feng.github.io/tags/CMU/"}]},{"title":"JDK 1.7 升级 到 1.8 出现跨域问题","slug":"踩坑日记/update-jdk1-8","date":"2021-12-28T10:05:27.000Z","updated":"2021-12-31T09:18:57.470Z","comments":true,"path":"2021/12/28/踩坑日记/update-jdk1-8/","link":"","permalink":"https://fan-yu-feng.github.io/2021/12/28/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/update-jdk1-8/","excerpt":"​    前后端联调时，在未修改跨域请求处理的代码的情况下，出现  been blocked by CORS policy: No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource 的异常。请求不到后端的接口，导致请求失败，初步判断是升级 JDK 导致的。","text":"​ 前后端联调时，在未修改跨域请求处理的代码的情况下，出现 been blocked by CORS policy: No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource 的异常。请求不到后端的接口，导致请求失败，初步判断是升级 JDK 导致的。 过程排查问题在经过 debug 后，spring 接收到请求后，原本是 POST 请求的被转化为 OPTIONS 请求。导致出现跨域异常。 解决​ 由于当时使用的容器为 Jetty6.4.x 和 tomcat 1.7，均为较低版本的容器（均为JDK1.8出现之前），所以定位问题到 Jetty 和 tomcat 容器版本比较低和升级后的 JDK1.8、spring4.x 不兼容导致。在将容器 Jetty 升级为 9.4.x 和 Tocat 升级为 1.8 后该问题解决。","raw":null,"content":null,"categories":[],"tags":[{"name":"bug","slug":"bug","permalink":"https://fan-yu-feng.github.io/tags/bug/"}]},{"title":"jackson 从1.8 升级到 2.9踩坑记录","slug":"踩坑日记/bug-jackson","date":"2021-12-28T08:00:39.000Z","updated":"2021-12-31T09:18:44.028Z","comments":true,"path":"2021/12/28/踩坑日记/bug-jackson/","link":"","permalink":"https://fan-yu-feng.github.io/2021/12/28/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/bug-jackson/","excerpt":"​    JDK1.7 升级到 JDK 1.8，spring 3.x 升级到 spring4.3.x ，SpringMVC 默认使用的 JSON 解析器就是 Jackson，因此 原来版本的 Jackson1.8.x 升级到 2.9.x 踩坑记录。\n​    问题：在没改动前端代码的情况下，Post 请求失败。","text":"​ JDK1.7 升级到 JDK 1.8，spring 3.x 升级到 spring4.3.x ，SpringMVC 默认使用的 JSON 解析器就是 Jackson，因此 原来版本的 Jackson1.8.x 升级到 2.9.x 踩坑记录。 ​ 问题：在没改动前端代码的情况下，Post 请求失败。 过程​ 发现问题：在 debug 的过程中，发现 spring 的 dispacherServlet 捕获到了异常：JSON parse error: Cannot deserialize instance of java.util.String out of START_OBJECT token，该异常为 JSON 转化异常。在处理请求参数后，直接抓到该异常。 ​ 在前端发现，请求的携带参数为多重嵌套的对象，和后端接口中的 @RequestBody 中对象的成员变量不一一对应。。也就是前后端传递数据时，出现的 JSON 格式转化错误，导致前端请求不到后端接口。 ​ 该错误在我使用 Jsckson1.8 版本时没有出现，后面升级才出现该问题。 Jackson1.8 说明 Jackson2.9.4 说明 Jackson 使用教程 解决​ 我的处理方式将前端多重嵌套的对象转化 JSON 格式的字符串传递参数。即通过 JSON.stringify 转化。 其余方式（参考） 通过 map&lt;String,Object&gt; 来获取数据，也就是 @RequestBody Map&lt;String, Object&gt; data 通过定义对应的对象类型来获取数据。","raw":null,"content":null,"categories":[],"tags":[{"name":"bug","slug":"bug","permalink":"https://fan-yu-feng.github.io/tags/bug/"}]},{"title":"hexo-进阶配置","slug":"Hexo搭建/hexo-advanced-setting","date":"2021-11-27T16:24:59.000Z","updated":"2022-01-04T03:29:47.817Z","comments":true,"path":"2021/11/28/Hexo搭建/hexo-advanced-setting/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/28/Hexo%E6%90%AD%E5%BB%BA/hexo-advanced-setting/","excerpt":"这里记录 有关 Next 8.8 版本的一些进阶配置，有关自定义样式和自定义 JS 相关的内容。\n具体参考 Next-Advanced-Setting\n自定义文件这部分内容参考 Next 自定义文件配置","text":"这里记录 有关 Next 8.8 版本的一些进阶配置，有关自定义样式和自定义 JS 相关的内容。 具体参考 Next-Advanced-Setting 自定义文件这部分内容参考 Next 自定义文件配置 前提在之前，要自定义页面样式等操作需要修改 Next 主题的配置文件，去修改样式或模板渲染的文件等。而在之后的代码合并提交或者更新时就会出现冲突的情况。因此官方推荐使用自定义文件和主题配置文件分离的形式，进行自定义的网址设置。在站点配置文件目录下，创建_data/xxx.xxx文件夹，修改对应的配置，然后再主题配置文件 _config.next.yml 中启用对应的文件既可。 自定义配置文件路径： 1234567891011custom_file_path: head: source/_data/head.njk #header: source/_data/header.njk #sidebar: source/_data/sidebar.njk #postMeta: source/_data/post-meta.njk #postBodyEnd: source/_data/post-body-end.njk #footer: source/_data/footer.njk #bodyEnd: source/_data/body-end.njk #variable: source/_data/variables.styl #mixin: source/_data/mixins.styl style: source/_data/styles.styl 修改样式自定义修改文章样式可以在 source/_data/styles.styl 文件夹下进行自定义。 1、找到对应的样式 class，如 header-inner，个人的信息样式设置，以及背景图文章内容等样式均可找到。 找到样式后在 source/_data/styles.styl 新增样式类 123456// 侧边、分页 rgba(255, 255, 255, 1); 0 和 1 是样式透明度.header-inner&#123; background-color: rgba(255, 255, 255, 1); border-radius: 30px 30px 30px 30px; box-shadow: 8px 7px 2px 0 rgba(0,0,0,0.12), 7px 4px 1px -2px rgba(0,0,0,0.06), 0 1px 5px 0 rgba(0,0,0,0.12); &#125; 其他样式也是差不多原理，下面是一些常用的样式。 123456789101112131415161718192021222324252627282930313233343536373839404142// 隐藏继续努力.archive .collection-title &#123;// display: none !important;&#125;// 文章块样式 .post-block&#123; background-color: rgba(255, 255, 255, 1); margin-bottom: 24px !important; border-radius: 30px 30px 30px 30px !important; box-shadow: 8px 7px 2px 0 rgba(0,0,0,0.12), 7px 4px 1px -2px rgba(0,0,0,0.06), 0 1px 5px 0 rgba(0,0,0,0.12) !important;&#125;// 背景图body &#123; background-image:url(/images/background.jpg); background-repeat: no-repeat; background-attachment: fixed; //不重复 background-size: cover; //填充 background-position: 100% 100%;&#125;// sidebar侧边个人头像样式.sidebar&#123; // 动画过渡时间 transition-duration: 0.4s; // 透明度 opacity: 1&#125;// 标题.posts-expand .post-title-link &#123; // 设置字体颜色 color: #222;&#125;// 文章列表样式.main-inner &#123; background-color: rgba(255, 255, 255, 0); padding: 0px 40px 40px 40px;&#125;// 侧边、分页 rgba(255, 255, 255, 1); 0 和 1 是样式透明度.header-inner, .sidebar-inner,.pagination&#123; background-color: rgba(255, 255, 255, 1); border-radius: 30px 30px 30px 30px !important; box-shadow: 8px 7px 2px 0 rgba(0,0,0,0.12), 7px 4px 1px -2px rgba(0,0,0,0.06), 0 1px 5px 0 rgba(0,0,0,0.12) !important; &#125; ! tips 如果样式未生效，可以加上 !important 提高自定义样式的优先级。","raw":null,"content":null,"categories":[{"name":"blog","slug":"blog","permalink":"https://fan-yu-feng.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://fan-yu-feng.github.io/tags/hexo/"}]},{"title":"代码格式化","slug":"code-format","date":"2021-11-24T07:35:52.000Z","updated":"2021-12-24T03:26:59.064Z","comments":true,"path":"2021/11/24/code-format/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/24/code-format/","excerpt":"书写代码的规范无论对团队还是个人来说都是至关重要的，写代码的过程中，有时候多余的空格、符号等需要修改，有时候心有余而力不足，大量的空格和缩进会消耗你的耐心。这时候可以通过 Idea 插件的相关配置来进行自动化的配置。\n代码规范具体可以查看 《阿里巴巴开发手册》","text":"书写代码的规范无论对团队还是个人来说都是至关重要的，写代码的过程中，有时候多余的空格、符号等需要修改，有时候心有余而力不足，大量的空格和缩进会消耗你的耐心。这时候可以通过 Idea 插件的相关配置来进行自动化的配置。 代码规范具体可以查看 《阿里巴巴开发手册》 注释一开始使用快捷键注释时，总是在行首时进行注释 //，需要进行调整，显得很麻烦，如图，在 setting -&gt; code style -&gt; java -&gt; Code Generation 设置。然后注释时按下快捷键 ctrl+/就可以了。 代码保存格式化（插件的形式）安装 google-java-format setting -&gt; plugin 搜索 google-java-format 在 idea 中的插件中心搜索 google-java-format, 安装。安装好，如下图所示，启用该代码格式化工具。 安装 save-action setting -&gt; plugin 搜索 save-action 启用该工具。保存时自动格式化，将没用的import 语句删除 进行配置优化自动导入 setting -&gt; Editor-&gt;General -&gt; Auto Import 行分隔符需要统一，不要使用 windows 的字符解析 setting -&gt; Editor-&gt; Code Style 检查缩进，统一代码缩进。 setting -&gt; Editor-&gt; Code Style -&gt; Java 启动安装的配置 1、google-java-format-settings setting -&gt; others settings -&gt; google-java-format-settings 找到该配置启用既可 2、save-action setting -&gt; others settings -&gt; save-action","raw":null,"content":null,"categories":[{"name":"格式化","slug":"格式化","permalink":"https://fan-yu-feng.github.io/categories/%E6%A0%BC%E5%BC%8F%E5%8C%96/"}],"tags":[{"name":"代码格式化","slug":"代码格式化","permalink":"https://fan-yu-feng.github.io/tags/%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%E5%8C%96/"}]},{"title":"并发编程-线程池","slug":"JUC/JavaThreadPool","date":"2021-11-23T08:40:11.000Z","updated":"2021-12-24T03:26:59.052Z","comments":false,"path":"2021/11/23/JUC/JavaThreadPool/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/23/JUC/JavaThreadPool/","excerpt":"1. 概念与设计\n参考技术文章 参考链接\n《Java 并发编程的艺术 》\n本节通过学习理论知识，并通过相关的源代码实现进行学习。\n\n1.1 线程池的概念线程池是一种基于池化思想的线程管理工具。","text":"1. 概念与设计 参考技术文章 参考链接 《Java 并发编程的艺术 》 本节通过学习理论知识，并通过相关的源代码实现进行学习。 1.1 线程池的概念线程池是一种基于池化思想的线程管理工具。 线程过多会带来额外的开销，其中包括线程销毁、创建、调度等，降低了计算机的性能。线程管理者管理和维护线程，等待使用者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。 池化技术现在已经屡见不鲜了，如线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。 线程池的作用： 降低了资源消耗，通过线程池管理可以重复利用已经创建好的线程，无需重复创建和销毁，降低了系统资源的消耗。 提高响应速度，任务到达后，无需等待线程创建既可执行 提高线程的可管理性，使用线程池可以统一的分配、调优和监控线程 线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定行。 1.2 Java中的线程池实现类Java中的线程池核心实现类是ThreadPoolExecutor,该类在Java中的继承关系如下图所示。 ThreadPoolExecutor 实现的顶层接口是 Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。ExecutorService 接口增加了一些能力：（1）扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法；（2）提供了管控线程池的方法，比如停止线程池的运行。AbstractExecutorService 则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。最下层的实现类ThreadPoolExecutor 实现最复杂的运行部分，ThreadPoolExecutor 将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。 线程池在内部实际上构建了一个生产者消费者模型，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。线程池的运行主要分成两部分：任务管理、线程管理。任务管理部分充当生产者的角色，当任务提交后，线程池会判断该任务后续的流转：（1）直接申请线程执行该任务；（2）缓冲到队列中等待线程执行；（3）拒绝该任务。线程管理部分是消费者，它们被统一维护在线程池内，根据任务请求进行线程的分配，当线程执行完任务后则会继续获取新的任务去执行，最终当线程获取不到任务的时候，线程就会被回收。 那么线程运行的机制主要有三点， 1、线程池自身的状态维护； 2、线程池的任务维护； 3、线程池的线程维护； 查看 ThreadPoolExecutor 的构造方法可以看出，线程池由7个核心的参数来决定。 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; corePoolSize 核心线程数 maximumPoolSize 最大线程数 keepAliveTime 存活时间 unit 时间单位 BlockingQueue 阻塞队列 defaultThreadFactory 线程工厂 defaultHandler 线程处理策略 线程池状态ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量，ThreadPoolExecutor 类中的线程状态变量如下： 1234567891011121314// Integer.Size 的值为 32private static final int COUNT_BITS = Integer.SIZE - 3;// 高三位为 111 表示接收新任务，同时处理任务队列中的任务private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;// 高三为为 000 表示不接收新任务，但是处理队列中的任务private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;// 高三位为 001 表示中断正在执行的任务，同时抛弃阻塞队列中的任务private static final int STOP = 1 &lt;&lt; COUNT_BITS;// 高三位为 010 表示任务执行完毕，活动线程为 0 时，即将进入终结阶段private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;// 高三位为011 表示终结状态private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 线程池状态和线程池中线程的数量由一个原子整型 ctl 来共同表示。使用一个数来表示两个值的主要原因是：可以通过一次 CAS 同时更改两个属性的值。 1234567891011// 原子整数，前 3 位保存了线程池的状态，剩余位保存的是线程数量private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));// 但是有个问题就是 并不是所有平台的 int 都是 32 位。// 去掉前三位保存线程状态的位数，剩下的用于保存线程数量// 高3位为0，剩余位数全为1private static final int COUNT_BITS = Integer.SIZE - 3;// 2^COUNT_BITS次方，表示可以保存的最大线程数 也就是 Int.Size()-3// CAPACITY 的高3位为 0 ；操作左移相应的位数 再减一private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; 获取线程池状态、线程数量以及合并两个值的操作： 12345678910//Packing and unpacking ctl// 获取运行状态// 该操作会让除高3位以外的数全部变为0 与非操作private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 获取运行线程数// 该操作会让高3位为0 与操作private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;// 计算ctl新值// 或运算 合并两个值private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 上述代码均在 ThreadPoolExcutor 中 线程池状态转化如下图所示： 任务运行任务调度规则任务调度是线程池的核心运行机制。所有的调度任务都由 Execute 完成。可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。 execute()方法用于提交不需要返回值的任务，而 submit() 方法用于提交需要返回值的任务。这部分完成的工作时：检查线程池的运行状态、运行数线程、决定接下来的任务运行流程，是运行该任务、缓存到队列中或者是拒绝任务。 其执行过程如下： 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。 如果 workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务。 如果 workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。 如果 workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。 如果 workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。 1234567891011121314151617181920212223242526272829public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * 1. 首先检查线程池的状态是否为 running，如果不是则拒绝任务加入。否则进行 2 * 2. 如果工作线程小于核心线程数，那么将尝试新建一个线程分配给任务 * 3. 如果工作线程大于核心线程数，且工作线程小于最大线程数、工作队列已满， * 那么则新建线程执行任务，工作队列未满则加入队列。 * 4. 如果工作线程数量大于最大线程数，且工作任务队列已满，那么则根据拒绝策略拒绝该任务。 */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 任务缓存队列任务缓存是线程池管理任务的核心部分。当任务生产者生产任务过多时，为防止任务丢失，需要以队列的形式将任务存放，等待线程消费者进行消费。线程池使用的是阻塞队列来实现缓存任务。 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 下图中展示了线程1往阻塞队列中添加元素，而线程2从阻塞队列中移除元素： 阻塞队列保证，无论并发多高，任意时刻都是线程安全的：即保证只有一个线程入队或出对。JUC中为线程池创建提供了多种阻塞队列供使用。 查看一下阻塞队列的实现队列，如图所示。 ​ 相关队列的具体介绍。 任务申请获取任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。 线程需要从任务缓存模块中不断地取任务执行，帮助线程从阻塞队列中获取任务，实现线程管理模块和任务管理模块之间的通信。这部分策略由 getTask 方法实现，其执行流程如下图所示： 任务拒绝策略当任务队列满、线程数量大于最大线程数量时，那么线程池就会根据拒绝策略进行拒绝。保护线程池。 拒绝策略的接口如下。 123public interface RejectedExecutionHandler &#123; void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; 该接口有四个实现类，也就是四种拒绝策略。具体如下图所示。 这里比较有意思的就是第四种 CallerRunsPolicy ，会执行所有的任务。查看该源码，发现重写的拒绝策略，只要线程池状态为不为 shutdown，那么就又该线程去处理。 12345public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125;&#125; 线程管理工作线程 WorkerWorker这个工作线程，实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。 1234private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; final Thread thread;//Worker持有的线程 Runnable firstTask;//初始化的任务，可以为null&#125; thread是在调用构造方法时通过ThreadFactory来创建的线程，可以用来执行任务；firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。 Worker执行任务的模型如下图所示： 线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张 Hash 表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。 Worker是通过继承 AQS( AbstractQueuedSynchronizer )，使用 AQS 来实现独占锁这个功能。没有使用可重入锁 ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。 lock方法一旦获取了独占锁，表示当前线程正在执行任务中。 如果正在执行任务，则不应该中断线程。 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。 线程池在执行 shutdown 方法或 tryTerminate 方法时会调用 interruptIdleWorkers 方法来中断空闲的线程，interruptIdleWorkers 方法会使用 tryLock 方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。 在线程回收过程中就使用到了这种特性，回收过程如下图所示： 增加线程增加线程是通过线程池中的addWorker方法，该方法的功能就是增加一个线程，该方法不考虑线程池是在哪个阶段增加的该线程，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。addWorker方法有两个参数：firstTask、core。firstTask参数用于指定新增的线程执行的第一个任务，该参数可以为空；core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize，其执行流程如下图所示： 线程回收线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。 1234567try &#123; while (task != null || (task = getTask()) != null) &#123; //执行任务 &#125;&#125; finally &#123; processWorkerExit(w, completedAbruptly);//获取不到任务时，主动回收自己&#125; 线程回收的工作是在processWorkerExit方法完成的。 事实上，在这个方法中，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程。 执行工作在 Worker 类中的 run方法调用了 runWorker 方法来执行任务，runWorker 方法的执行过程如下： while 循环不断地通过getTask() 方法获取任务。 getTask() 方法从阻塞队列中取任务。 如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态。 执行任务。 如果 getTask 结果为 null 则跳出循环，执行 processWorkerExit() 方法，销毁线程。 执行流程如下图所示：","raw":null,"content":null,"categories":[{"name":"JUC","slug":"JUC","permalink":"https://fan-yu-feng.github.io/categories/JUC/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"https://fan-yu-feng.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"JVM-Tool","slug":"JVM/JVM-Tool","date":"2021-11-22T10:27:17.000Z","updated":"2021-12-24T03:26:59.060Z","comments":false,"path":"2021/11/22/JVM/JVM-Tool/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/22/JVM/JVM-Tool/","excerpt":"Java 虚拟机性能监控和故障处理工具使用 Java 虚拟机的性能处理工具可以方便的去分析内存数据、定位故障问题。本篇是个人学习 JVM 的知识笔记。参考资料来自周志明的\n\n《深入理解Java虚拟机: JVM高级特性与最佳实践（第3版）》\n","text":"Java 虚拟机性能监控和故障处理工具使用 Java 虚拟机的性能处理工具可以方便的去分析内存数据、定位故障问题。本篇是个人学习 JVM 的知识笔记。参考资料来自周志明的 《深入理解Java虚拟机: JVM高级特性与最佳实践（第3版）》 Java 虚拟机提供的工具全都在 Java/bin 目录下，本次使用的工具是基于 Java1.8 的性能处理工具，使用的是 HotSpot 虚拟机。 命令行工具jps: 虚拟机进程状态工具jps: JVM Process Status Tool，虚拟机状态进程工具。可以列出正在运行的虚拟机进程，并显示虚拟机执行主类名称以及这些进程的本地虚拟机唯一ID（LVMID，Local Virtual Machine Identifier）。虽然功能比较单一，但它绝对是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到的 LVMID 来确定要监控的是哪一个虚拟机进程。对于本地虚拟机进程来说，LVMID 与操作系统的进程 ID（PID，Process Identifier）是一致的，使用 Windows 的任务管理器或者 UNIX 的 ps 命令也可以查询到虚拟机进程的 LVMID，但如果同时启动了多个虚拟机进程，无法根据进程名称定位时，那就必须依赖 jps 命令显示主类的功能才能区分了。 jps 命令格式 ，如果不指定 hostid 就默认为当前的主机或服务器。 1jps [ options ] [ hostid ] 主要选项 1234-q: 输出虚拟机唯一ID，不输出类名、Jar名和传入main方法的参数-m: 输出传入main方法的参数-l: 输出main类或Jar的全名-v: 输出虚拟机进程启动时JVM的参数 jstat: 虚拟机显示信息监视工具jstat: JVM Statistics Monintoring Tool，用于监视虚拟机各种运行状态信息的命令行工具。用于显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据。它是运行时期定位虚拟机性能问题的常用工具。 jstat 命令格式 jstat [ option vmid [interval [s | ms] [count] ] ] jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数] 说明: 如果是本地虚拟机进程，VMID和LVMID是一样的，如果是远程虚拟机进程，那VMID格式应该是: [protocol:][ // ] lvmid [@hostname [:port] /servername ] 参数interval和count代表查询间隔和次数，如果省略这2个参数，说明只查询一次。假设需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是 主要选项 12345678910111213141516171819202122# 类加载class: 监视类装载、卸载数量、总空间以及类装载所耗费的时间# 垃圾收集gc: 监视Java堆状况，包括Eden区、两个Survivor区、老年代等容量、已用空间、GC时间合计等信息# 编译compiler: 输出JIT编译器编译过的方法、耗时等信息# 堆内存gccapacity: 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间# 新生代垃圾回收gcnew: 监视新生代GC状况# 新生代内存gcnewcapacity: 监视内容与-gcnew基本相同，主要输出使用到的最大、最小空间 # 老年代垃圾回收gcold: 监视老年代GC情况# 老年代内存gcoldcapacity: 监视内容与-gcold基本相同，主要输出使用到的最大、最小空间# 元数据空间gcmetacapacity: 监视元数据空间内存情况（jdk1.8之后）# 垃圾回收统计gcutil: 统计所有垃圾回收的数据# 编译方法printcompilation: 输出已经被JIT编译的方法 -class监视类装载、卸载数量、总空间以及类装载所耗费的时间 123$ jstat -class 46416Loaded Bytes Unloaded Bytes Time 12896 24288.0 6 9.4 8.92 字段说明 12345Loaded: 加载class的数量Bytes: 所占用空间大小Unloaded: 未加载数量Bytes: 未加载占用空间Time: 时间 -gc jstat -gc 46416250 20 查询进程 46416 进程每2000毫秒 查询一次 gc 情况，共20次。 基本字段的含义 12345678910111213141516S0C: 第一个幸存区的大小S1C: 第二个幸存区的大小S0U: 第一个幸存区的使用大小S1U: 第二个幸存区的使用大小EC: 伊甸园区的大小EU: 伊甸园区的使用大小OC: 老年代大小OU: 老年代使用大小MC: 方法区大小MU: 方法区使用大小CCSC: 压缩类空间大小CCSU: 压缩类空间使用大小YGC: 年轻代垃圾回收次数YGCT: 年轻代垃圾回收消耗时间FGC: 老年代垃圾回收次数GCT: 垃圾回收消耗总时间 -compiler 输出JIT编译器编译过的方法、耗时等信息 123$ jstat -compiler 46416Compiled Failed Invalid Time FailedType FailedMethod 7650 0 0 1.44 0 字段说明 123456Compiled: 编译数量。Failed: 失败数量Invalid: 不可用数量Tim: 时间FailedType: 失败类型FailedMethod: 失败的方法 -gcnew 监视新生代GC状况 123$ jstat -gcnew 46416 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT3072.0 23552.0 2624.0 0.0 4 15 23552.0 353792.0 155021.4 14 0.088 字段说明(已介绍的参数不再重复) 1234567891011S0C: 第一个幸存区大小S1C: 第二个幸存区的大小S0U: 第一个幸存区的使用大小S1U: 第二个幸存区的使用大小TT:对象在新生代存活的次数MTT:对象在新生代存活的最大次数DSS:期望的幸存区大小EC: 伊甸园区的大小EU: 伊甸园区的使用大小YGC: 年轻代垃圾回收次数YGCT: 年轻代垃圾回收消耗时间 -gcnewcapacity:监视内容与-gcnew基本相同，主要输出使用到的最大、最小空间 123$ jstat -gcnewcapacity 46416NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC86528.0 1387008.0 487936.0 462336.0 3072.0 462336.0 23552.0 1385984.0 353792.0 14 3 字段说明 1234567891011NGCMN: 新生代最小容量NGCMX: 新生代最大容量NGC: 当前新生代容量S0CMX: 最大幸存1区大小S0C: 当前幸存1区大小S1CMX: 最大幸存2区大小S1C: 当前幸存2区大小ECMX: 最大伊甸园区大小EC: 当前伊甸园区大小YGC: 年轻代垃圾回收次数FGC: 老年代回收次数 -gcold:监视老年代GC情况 123$ jstat -gcold 46416 MC MU CCSC CCSU OC OU YGC FGC FGCT GCT 72024.0 67356.9 9600.0 8718.7 188416.0 45162.0 14 3 0.179 0.268 字段说明 12345678910MC: 方法区大小MU: 方法区使用大小CCSC: 压缩类空间大小CCSU: 压缩类空间使用大小OC: 老年代大小OU: 老年代使用大小YGC: 年轻代垃圾回收次数FGC: 老年代垃圾回收次数FGCT: 老年代垃圾回收消耗时间GCT: 垃圾回收消耗总时间 -gcoldcapacity:监视内容与-gcold基本相同，主要输出使用到的最大、最小空间 123$ jstat -gcoldcapacity 46416 OGCMN OGCMX OGC OC YGC FGC FGCT GCT 173568.0 2774528.0 188416.0 188416.0 15 3 0.179 0.271 字段说明 12345678OGCMN: 老年代最小容量OGCMX: 老年代最大容量OGC: 当前老年代大小OC: 老年代大小YGC: 年轻代垃圾回收次数FGC: 老年代垃圾回收次数FGCT: 老年代垃圾回收消耗时间GCT: 垃圾回收消耗总时间 -gcmetacapacity:监视元数据空间内存情况（jdk1.8之后） 123$ jstat -gcmetacapacity 46416MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC FGCT GCT0.0 1112064.0 72024.0 0.0 1048576.0 9600.0 15 3 0.179 0.271 字段说明 12345678910MCMN: 最小元数据容量MCMX: 最大元数据容量MC: 当前元数据空间大小CCSMN: 最小压缩类空间大小CCSMX: 最大压缩类空间大小CCSC: 当前压缩类空间大小YGC: 年轻代垃圾回收次数FGC: 老年代垃圾回收次数FGCT: 老年代垃圾回收消耗时间GCT: 垃圾回收消耗总时间 -gcutil 统计所有垃圾回收的数据 123$ jstat -gcutil 46416 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 84.38 28.83 23.97 93.71 90.82 15 0.092 3 0.179 0.271 字段说明 12345678910S0: 幸存1区当前使用比例S1: 幸存2区当前使用比例E: 伊甸园区使用比例O: 老年代使用比例M: 元数据区使用比例CCS: 压缩使用比例YGC: 年轻代垃圾回收次数FGC: 老年代垃圾回收次数FGCT: 老年代垃圾回收消耗时间GCT: 垃圾回收消耗总时间 -printcompilation:输出已经被JIT编译的方法 123$ jstat -printcompilation 46416Compiled Size Type Method 7728 5 1 com/alibaba/druid/sql/ast/SQLOrderBy getItems 字段说明 1234Compiled: 最近编译方法的数量Size: 最近编译方法的字节码数量Type: 最近编译方法的编译类型。Method: 方法名标识。 jinfo: Java配置信息工具jinfo: Configuration Info for Java，能实时地查看和调整虚拟机各项参数。 命令格式： jinfo [option] pid 说明：如果不传入参数，则输出该进程的所有配置信息 jmap：Java内存映像工具Java内存映像工具，用于生成堆存储快照（一般称为heapdump或dump文件），还可以查询finalize执行队列、Java堆的详细信息，如空间使用率、当前用的是哪种收集器等。如果不适用jmap命令，可以使用-XX:+HeapDumpOnOutOfMemoryError参数，当虚拟机发生内存溢出的时候可以产生快照。或者使用kill -3 pid也可以产生 jmap命令格式： jmap [option] vmid 12345678-dump: [live,]format=b,file=&lt;filename&gt; 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件.-finalizerinfo: 打印正等候回收的对象的信息.-heap: 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况.-histo[:live]: 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live 子参数加上后,只统计活的对象数量.-permstat: 打印classload和jvm heap长久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader 和加载的 class 数量. 另外,内部 String 的数量和占用内存数也会打印出来.-F: 强迫.在pid没有相应的时候使用-dump或者-histo参数. 在这个模式下,live子参数无效.-h: | -help 打印辅助信息-J: 传递参数给jmap启动的jvm. jhat：虚拟机堆转储快照分析工具JDK提供jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。 jstack：Java堆栈跟踪工具jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的目的通常是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂起等，都是导致线程长时间停顿的常见原因。线程出现停顿时通过jstack来查看各个线程的调用堆栈，就可以获知没有响应的线程到底在后台做些什么事情，或者等待着什么资源。 jstack命令格式： jstack [option] vmid 123-F: 当正常输出的请求不被响应时，强制输出线程堆栈-l: 除堆栈外，显示关于锁的附加信息-m: 如果调用到本地方法的话，可以显示C/C++的堆栈 如图 可视化工具JDK除了提供上面所讲的几个强大命令行工具外，还提供了一些可视化工具，可以方便的实时监控正在运行的Java程序。有如下：JHSDB（基于服务性代理的调试工具）、JConsole（Java监视与管理控制台）、VisualVM（多合-故障处理工具）、Java Mission Control（可持续在线的监控工具）。 JConsole在 bin 目录下的 exe 文件中能找到，连接使用即可。 VisualVM在 bin 目录下的 jvisualvm.exe， 点击即可运行 jvisualvm同jconsole都是一个基于图形化界面的、可以查看本地及远程的JAVA GUI监控工具，Jvisualvm同jconsole的使用方式一样，jvisualvm界面更美观一些，数据更实时。 Java Mission Control在 bin 目录下的 jmc.exe，具体没有用过，可自行了解， JHSDB未使用过，TODO，使用了在更新。","raw":null,"content":null,"categories":[{"name":"JVM","slug":"JVM","permalink":"https://fan-yu-feng.github.io/categories/JVM/"}],"tags":[{"name":"虚拟机","slug":"虚拟机","permalink":"https://fan-yu-feng.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"hexo-搭建博客-常见问题(4)","slug":"Hexo搭建/hexo-problem-4","date":"2021-11-22T03:01:25.000Z","updated":"2021-12-31T06:46:18.179Z","comments":true,"path":"2021/11/22/Hexo搭建/hexo-problem-4/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/22/Hexo%E6%90%AD%E5%BB%BA/hexo-problem-4/","excerpt":"这里记录，搭建博客中出现的一些问题。","text":"这里记录，搭建博客中出现的一些问题。 配置文件 在 hexo 的配置和设置文件中，在冒号后面没留空格会导致出问题。 Hexo 中的图标使用的是 Font Awesome ，所以，我们的博客已经自带了 Font Awesome 中的所有图标，基本可以满足我们的所有需求，我们可以去 Font Awesome 中查找我们想要使用的图标。&lt;i class=&quot;fa fa-github&quot;&gt;&lt;/i&gt;&lt;i class=&quot;fa fa-github fa-lg&quot;&gt;&lt;/i&gt;&lt;i class=&quot;fa fa-github fa-2x&quot;&gt;&lt;/i&gt; 设置阅读全文 没有阅读全文标志来进行截面，导致页面过长：在 md 文档中添加 &lt;!--more--&gt; 进行截取文章。 标题居中我此时的 Next 主题样式为 Mist，先看一下页面的样式。 标题的 class=&quot;post-title&quot; 添加了 style=&quot;center&quot;后居中。 然后再配置文件中修改，则是需要在Hexo\\themes\\next\\source\\css\\_schemes\\Mist目录下，这里Hexo为安装时自定义的目录名。首先得让博客内容居中，找到此目录下_posts-expanded.styl文件用文本编辑器打开， 找到 .post-title 在 text-align 添加 center 1234567.post-title,.post-meta &#123; text-align: $site-meta-text-align, center; + mobile() &#123; text-align: center; &#125;&#125; 设置 Next 背景 3D 动画将依赖下载到 Next 的文件夹下。 12cd themes/nextgit clone https://github.com/theme-next/theme-next-three source/lib/three 在主题配置文件中，设置其中一个为 true 1234three: three_waves: false canvas_lines: false canvas_sphere: false 设置统计字数时长等需要安装 这个 next 集成的功能插件 hexo-symbols-count-time。 1$ npm install hexo-symbols-count-time 在站点配置文件中设置相应的设置 123456# 统计symbols_count_time: symbols: true #是否统计字数 time: false #是否统计阅读时长 total_symbols: true #是否统计总字数 total_time: false #是否统计总阅读时长 设置访问人数如果没有安装 Next 主题的话，那么请参照该 链接进行设置 因为 Next 集成了 不蒜子 这个统计插件。在主题配置文件下搜索 busuanzi 设置为 true 在 footer 下 添加counter: true就可以了。 123456789101112busuanzi_count: enable: true total_visitors: true total_visitors_icon: fa fa-user total_views: true total_views_icon: fa fa-eye post_views: true post_views_icon: fa fa-eyefooter: # 添加阅读统计 counter: true 需要修改，访问人数的具体内容的，可修改 themes\\next\\layout\\_third-party\\statistics\\busuanzi-counter.swig该文件下的内容。如添加访客数文字。 1234567891011&#123;%- if theme.busuanzi_count.total_visitors %&#125; &lt;span class=&quot;post-meta-item&quot; id=&quot;busuanzi_container_site_uv&quot; style=&quot;display: none;&quot;&gt; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;&#123;&#123; theme.busuanzi_count.total_visitors_icon &#125;&#125;&quot;&gt;&lt;/i&gt; &lt;span&gt;访客数：&lt;/span&gt; &lt;/span&gt; &lt;span class=&quot;site-uv&quot; title=&quot;&#123;&#123; __(&#x27;footer.total_visitors&#x27;) &#125;&#125;&quot;&gt; &lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt; &lt;/span&gt; &lt;/span&gt;&#123;%- endif %&#125; 设置页脚、页面样式设置页面、标题居中、样式等，可以在对应的主题文件进行修改， 如我修改页脚的居中样式，则修改themes\\next\\source\\css\\_schemes\\Mist下的 layout.styl文件中的内容。 123.footer-inner &#123; text-align: center;&#125; 同理，如果需要设置其他内容，可以修改其他的文件。 修改查看使用:hexo g -w 来 r 进行调试。 升级 Next 主题 版本 年份 仓库 v5.1.4 或更低 2014 ~ 2017 https://github.com/iissnan/hexo-theme-next v6.0.0 ~ v7.8.0 2018 ~ 2019 https://github.com/theme-next/hexo-theme-next v8.0.0 或更高 2020 https://github.com/next-theme/hexo-theme-next 升级注意事项跨版本的升级可能并不顺滑（例如由 v5.1.4 或 v7.8.0 升级至 v8.0.0），请备份配置文件及修改过的文件（例如自定义模板文件）后，重新安装新的主题。具体操作请阅读文档： https://theme-next.js.org/docs/getting-started/upgrade.html v7.4.2 Nunjucks 引擎鉴于 swig 缺乏维护，NexT 自 7.4.2 版本开始，使用 Nunjucks 代替 swig 作为模版引擎。如果此前根据 swig 的语法写过自定义内容，请在更新前确认它们是与 Nunjucks 兼容的，否则会报错，且生成的页面为空白。例如， Nunjucks 只支持 and 运算符，需要替换掉 swig 中的 &amp;&amp;。见 http://mozilla.github.io/nunjucks/getting-started.html Hexo 5.0 版本移除了对于 swig 模版的支持，改为独立的 hexo-renderer-swig 插件。如果你发现 Hexo 生成的 html 中输出了 NexT 模版源码，说明你正在使用旧版本的 NexT，请根据前面「Hexo 与 NexT 兼容性」部分的内容升级 NexT。 主题配置文件设置（推荐） 我们习惯的方式是站点配置文件和主题配置文件分别存放不同的配置，这个方式很好，但是不适用升级 Next 主题或者提交 Merge，因此官方推荐使用新的配置文件，来放到同站点配置文件同目录下，并命名为新的配置文件 _config.[themeName].yml，themeName 就是你的主题名字，Hexo 灵活配置说明 ，而原来的 主题配置文件就不用修改了，修改自己的配置文件就行了。 操作 在刚下载安装 Next 的时候，复制如下操作，并将 _config.next.yml 文件放置到 站点配置文件同目录下。 cp themes/next/_config.yml _config.next.yml 重新生成 public 文件即可。 参考 Next 配置 评论有多种评论生成的方式，Disqus、ChangYan、GitTalk 等，具体需求可参考评论生成文档 我换成了 GitTalk Gitalk 是一个基于 Github Issue 的评论插件，使用 Github 帐号登录，界面干净整洁，最喜欢的一点是支持 MarkDown 语法，在个人博客里添加了之后就可以很简便的进行评论和回复了。 1. 创建 Github 仓库需要在自己的 Github 账号下创建一个仓库来存放评论，创建的仓库只要 public 就行，其余没要求。 2. 创建 Github Application需要创建一个 Github Application 用来授权登录，如果没有 点击这里申请，Authorization callback URL 填写你主页地址。其他的不用在意，没有用到就随意填。不知道怎么创建，请看 这里 3. 修改配置安装 gittalk npm i --save gitalk 创建好 github app 后会生成 client_id 和 client_secret，填入即可，同时，需要你存放评论的仓库也一同放下去。 123456789gitalk: enable: true github_id: repo: client_id: client_secret: admin_user: distraction_free_mode: true language: zh-CN 出现 Error: Bad credentials.按 F12 查看请求的链接地址,之前错误的网址不见了，只好贴这个成功的示例，之前的链接是https://api.github.com/repos/github_id/Fan-Yu-Feng.github.io 我以为 github_id 是去查看自己 github 的用户 id，填了 Github 的用户 id，在 next 主题配置文件中填入了自己的 github id，一直报这个错误，","raw":null,"content":null,"categories":[{"name":"blog","slug":"blog","permalink":"https://fan-yu-feng.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://fan-yu-feng.github.io/tags/hexo/"}]},{"title":"hexo-搭建博客-博客配置(3)","slug":"Hexo搭建/hexo-config-3","date":"2021-11-22T01:55:14.000Z","updated":"2021-12-31T06:45:25.913Z","comments":true,"path":"2021/11/22/Hexo搭建/hexo-config-3/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/22/Hexo%E6%90%AD%E5%BB%BA/hexo-config-3/","excerpt":"在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。\n为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。","text":"在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。 为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。 这里主题推荐 yilia 和 next 两种，比较简约。 需要将主题下载到 themes 文件夹下。 yilia 下载安装 1234$ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia# 更新 cd themes/yiliagit pull next 下载安装。 12$ cd hexo$ git clone https://github.com/theme-next/hexo-theme-next themes/next 配置：需要去站点配置文件 _config.yml 修改 theme: yilia 或者 theme: yilia 下面是 next 的几个版本仓库 5.14 或更低 6~7 8以上 hexo 命令这里介绍几个比较好用的命令 新建文章和草稿等 123456# 新建文章hexo new post &quot;titleName&quot;# 新建草稿hexo new draft &quot;titleName&quot;# 新建页面 对于独立页面来说，Hexo 会创建一个以标题为名字的目录，并在目录中放置一个 index.md 文件。hexo new page &quot;pageName&quot; 生成静态文件 12# 生成 静态文件 其中 -d 表示部署 -w 表示监控文件的改动，并生成静态文件。hexo generate -d -w 其中 -d 需要在站点配置文件中 配置部署的链接及分支等。 -w 则是可以在你修改文件时，生成对应的静态文件，不需要重新启动，十分方便。 启动并监控 12# 启动 debug 在运行的过程中，查看应用情况hexo s --debug 删除生成的静态文件 1234# 删除静态文件 public 下的文件hexo clean # 删除并重新生成hexo clean -g 以上是我常用的命令，更多命令查看： hexo commands 博客配置修改配置的修改看配置文档比较详细。 Hexo 配置文档 Next 文档 8.x","raw":null,"content":null,"categories":[{"name":"blog","slug":"blog","permalink":"https://fan-yu-feng.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://fan-yu-feng.github.io/tags/hexo/"}]},{"title":"hexo-搭建博客-博客图床 picgo（2）","slug":"Hexo搭建/hexo-搭建博客-博客图床 picgo（2）","date":"2021-11-19T08:34:11.000Z","updated":"2021-12-24T03:26:59.022Z","comments":true,"path":"2021/11/19/Hexo搭建/hexo-搭建博客-博客图床 picgo（2）/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/19/Hexo%E6%90%AD%E5%BB%BA/hexo-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2-%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%20picgo%EF%BC%882%EF%BC%89/","excerpt":"记录一下，以防以后踩坑。\n使用 blog 写文章的时候需要上传一些图片，不然只能在本地看。这时候就需要图床来保存博客中的图片。\n我使用的是 typora + picgo 的方式。","text":"记录一下，以防以后踩坑。 使用 blog 写文章的时候需要上传一些图片，不然只能在本地看。这时候就需要图床来保存博客中的图片。 我使用的是 typora + picgo 的方式。 前提准备picgo 下载在GitHub上有安装包。或者打开阿里云盘吧，有 windows 64bit 的安装包。 PicGo官网 阿里云盘 还有就是下载 Typora 配置 picgo下载安装完后，需要安装上传插件 gitee，有三种，任意下一种，不同的配置不一样的。 然后再gitee 上进行配置再验证上传就好了，配置如下。刚开始路径写错了导致不成功，所以可以注意一下路径。 owner 是你的账号名，repo 是仓库，token是码云私人令牌。私人令牌申请 Typora 配置最后在 Typora 中配置一下 picgo 的安装路径的exe文件和验证上传就可以了。","raw":null,"content":null,"categories":[{"name":"blog","slug":"blog","permalink":"https://fan-yu-feng.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://fan-yu-feng.github.io/tags/hexo/"}]},{"title":"Linux-日志查看","slug":"Linux/Linux-日志查看","date":"2021-11-19T04:45:16.000Z","updated":"2021-12-24T03:26:59.061Z","comments":true,"path":"2021/11/19/Linux/Linux-日志查看/","link":"","permalink":"https://fan-yu-feng.github.io/2021/11/19/Linux/Linux-%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/","excerpt":"","text":"","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://fan-yu-feng.github.io/categories/Linux/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://fan-yu-feng.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"并发编程-基础","slug":"JUC/juc-base","date":"2021-08-04T09:58:04.000Z","updated":"2021-12-24T03:26:59.054Z","comments":false,"path":"2021/08/04/JUC/juc-base/","link":"","permalink":"https://fan-yu-feng.github.io/2021/08/04/JUC/juc-base/","excerpt":"\n该篇是学习并发编程相关的基础知识\n参考 《Java 并发编程的艺术 》 参考博客\n万丈高楼平地起，唯有基础扎实才能筑起筑起属于自己的高楼大厦。\n","text":"该篇是学习并发编程相关的基础知识 参考 《Java 并发编程的艺术 》 参考博客 万丈高楼平地起，唯有基础扎实才能筑起筑起属于自己的高楼大厦。 进程和线程概念线程：线程是 CPU 调度的最小单位也叫轻量级进程（Light Weight Process），在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。处理器在这些线程上高速切换，让使用者感觉到这些线程在同时执行。 进程：进程是程序的一次执行过程，是 CPU 资源分配的最小单位，每个进程都有自己的独立空间，一个进程可以有多个线程。 区别 根本区别：进程是操作系统资源分配的基本单位。线程是处理器任务调度和执行的基本单位 资源开销：每个进程都有独立的代码和数据空间。程序之间的切换有比较大的开销。线程可以看做是轻量级的进程，同一类线程共享堆和方法区，每个线程有自己的程序计数器、虚拟机栈、本地方法栈，线程之间切换开销比较小。 包含关系：一般一个进程内有多个线程，执行过程不是一条线的，而是由多个线程共同完成；线程是进程的一部分，所以被称为轻量级进程 影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃可能导致整个进程都死掉。所以多进程要比多线程健壮。 并行和并发有什么区别？ 并行是指两个或者多个事件在同一时刻发生 并发是指两个或多个事件在同一时间间隔发生 生命周期当线程创建后，并不是启动就进入执行状态，也不是一直处于执行状态。在线程的生命周期中，它要经过新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocaked）和死亡（Dead）5种状态。尤其是当线程启动后，不能一直独占 CPU，CPU 需要在多线程之间切换，于是线程会在运行、阻塞之间切换。 新建状态（New）当程序使用 new 关键字创建了一个线程之后，该线程就处于新建状态，虚拟机为其分配内存，并初始化成员变量的值。 就绪状态（Runnable）当调用了线程的 start 方法后，该线程处于就绪状态，Java 虚拟机会为其创建方法调用栈和程序计数器，等待调度运行。 运行状态（Running）如果处于就绪状态的线程获得了 CPU 分配时间，开始执行 run 方法中的线程执行体，则该线程处于运行状态。 阻塞状态（Blocked）阻塞状态是指线程因为某种原因放弃了 CPU 的使用权，让出 CPU 时间片，暂停停止运行，知道线程进入到就绪（Runnable）状态，才有机会再次获得时间片进入运行状态。阻塞的情况分为三种： 等待阻塞（0.wait -&gt; 等待队列）：运行中的线程执行 o.wait 方法，JVM 会把线程放入等待队列中 同步阻塞（lock-&gt; 锁池）：运行中的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线程放入锁池中（ lock pool） 其他阻塞（sleep、Join）：运行中的线程执行 Thread.sleep(long ms) 或 t.join()方法，或者发出了 I/O 请求时，JVM 会把线程置为阻塞状态，当 sleep() 方法超时，join() 等待线程终止或者超时，或者 I/O 处理完毕时，线程重新转入可运行状态。 线程死亡线程以下面三种方式结束，结束后就是死亡状态 正常结束：run() 或 call() 方法执行完成，线程正常结束。 异常结束：线程抛出一个未捕获的 Exception 或 Error。 调用 stop: 直接调用 stop 方法来结束线程，该方法容易导致死锁。 Java 线程的创建创建线程的方式有很多种，主要有以下四种，代码实现多种多样，我只列举我的仅供参考。 继承 Thread 类Thread 类本质上是实现了 Runnable 接口的一个实例。代表一个线程的实例。启动线程的唯一方法就是通过 Thread 类的 start()实例方法。start()方法调用了 native 方法，它将启动一个新线程，并执行 run()方法。 1234567891011public class ThreadDemo extends Thread &#123; public void run() &#123; System.out.println(&quot;MyThread run!&quot;); &#125; public void threadRun() &#123; ThreadDemo threadDemo = new ThreadDemo(); threadDemo.start(); &#125;&#125;// start 方法调用的 native 方法private native void start0(); 实现 Runnable 接口如果一个类已经继承了其他的类，那么就无法继承 Thread 接口，此时可以实现 Runnable 接口，重写其中的 run 方法。 12345678public class ThreadDemo extends otherClass implements Runnable &#123; public void run() &#123; System.out.println(&quot;MyThread run!&quot;); &#125;&#125;// 运行ThreadDemo threadDemo = new ThreadDemo();Thread thread = new Thread(threadDemo,&quot;thread&quot;); Callable有返回值线程有返回值的任务必须实现 Callable 接口，执行Callable 任务后，可以获取一个 Future 的对象，在该对象上调用 get 就可以获取到 Callable 任务返回的 Object 了，再结合线程池接口 ExecutorService 就可以实现传说中有返回结果的多线程了 123456789101112131415161718public class MyCallable implements Callable&lt;String&gt; &#123; @Override public String call() &#123; System.out.println(Thread.currentThread().getName() + &quot; 执行callable的call方法&quot;); return &quot;result&quot;; &#125; public static void main(String[] args) &#123; // 1.创建callable对象 Callable&lt;String&gt; myCallable = new MyCallable(); // 2.由上面的callable对象创建一个FutureTask对象 FutureTask&lt;String&gt; oneTask = new FutureTask&lt;String&gt;(myCallable); // 3.由FutureTask创建一个Thread对象 Thread t = new Thread(oneTask); // 4.开启线程 t.start(); &#125;&#125; 线程池创建123456789101112131415// 创建线程池ExecutorService threadPool = Executors.newFixedThreadPool(10);while(true) &#123; threadPool.execute(new Runnable() &#123; // 提交多个线程任务，并执行 @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; is running ..&quot;); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;);&#125; &#125; Runnable 和 Callable 的区别相同点：都是接口、可以编写多线程程序且都才用 Thread.start() 启动线程。 区别：Runnable 接口的 run 方法无返回值；Callable 的 call 方法有返回值，且支持返回泛型，允许抛出异常，返回的结果支持 Furture 的 get 方法异步获取结果。 线程的 run 和 start 的区别start() 方法用于启动线程，run() 方法用于执行线程的运行时代码。run() 可以重复调用，而 start() 只能调用一次。 多次调用会抛出 java.lang.IllegalThreadStateException 异常 new 一个 Thread，线程进入了新建状态。调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 sleep 和 wait 的区别 sleep 属于 Thread 中的，wait 属于 Object 类中的， sleep 方法导致程序暂停指定时间，让出 CPU 给其他线程，但是他的监控状态依然保持着，当指定时间结束又会恢复到运行状态。 当调用 sleep 方法的过程中，线程不会释放对象锁。 当调用 wait 方法的时候，线程会放弃对象锁，进入等待此对象的等待锁池，只有针对此对象的调用 notify 方法后，本线程才进入对象锁池准备获取对象锁进入运行状态。 守护线程 守护线程是 Java 的后台线程，也称为“服务线程”，为用户线程提供公共服务。在没有用户线程可服务时，会自动离开。 优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。 设置：通过 setDaemon(true)来设置线程为“守护线程”；将一个用户线程设置为守护线程 的方式是在 线程对象创建 之前 用线程对象的 setDaemon 方法。 在 Daemon 线程中产生的新线程也是 Daemon 的。 线程则是 JVM 级别的，以 Tomcat 为例，如果你在 Web 应用中启动一个线程，这个线程的生命周期并不会和 Web 应用程序保持同步。也就是说，即使你停止了 Web 应用，这个线程依旧是活跃的。 example: 垃圾回收线程就是一个经典的守护线程，当我们的程序中不再有任何运行的Thread,程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是 JVM 上仅剩的线程时，垃圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统中的可回收资源。 生命周期：守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端，但是依赖于系统，与系统“同生共死”。当 JVM 中所有的线程都是守护线程的时候，JVM 就可以退出了；如果还有一个或以上的非守护线程则 JVM 不会退出。 并发存在的问题上下文切换多线程执行代码，避免不了线程之间的上下文切换。CPU 通过给每个线程分配 CPU 时间片来实现多线程执行代码，而时间片非常短，所以 CPU 通过不停的切换线程执行，让我们感觉到多个线程是同步执行的。 在线程切换前会保存上一个任务的状态，这个信息由线程的 PC、虚拟机栈等私有内存。因此在每次切换线程都需要保存上一个任务的信息以及读取下一个任务的状态，是影响 CPU 的效率和多线程的执行速度的。 使用多线程可能会带来内存泄漏、死锁、线程不安全等等问题，这些都是需要去解决的。 如何减少上下文切换减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一 些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这 样会造成大量线程都处于等待状态。 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 死锁何为死锁，就是多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。 产生死锁的原因主要是：（1） 因为系统资源不足。 （2） 进程运行推进的顺序不合适。 （3） 资源分配不当等。 如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。 产生死锁的四个必要条件：（1） 互斥条件：一个资源每次只能被一个进程使用。 （2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 （3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。 （4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。 Java 锁锁的状态锁的状态共有4种，无锁状态、偏向锁、轻量级锁和重量级锁。将锁进一步的细化，有助于提升程序并发性能。 偏向锁Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁，。偏向锁的目的是在某个线程获得锁之后，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。（该线程在进入和退出同步块时不需要花费 CAS 操作来加锁和解锁，而只需简单的测试一下对象头的 Mark Word（对象头的一个标志） 里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下 Mark Word 中偏向锁的标识是否设置成 1（表示当前是偏向锁），如果没有设置，则使用 CAS 竞争锁，如果设置了，则尝试使用 CAS 将对象头的偏向锁指向当前线程。 偏向锁也是JDK 6中引入的一项锁优化措施，它的目的是消除数据在无竞争情况下的同步原语， 进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互 斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不去做了。 偏向锁中的“偏”，就是偏心的“偏”、偏袒的“偏”。它的意思是这个锁会偏向于第一个获得它的线 程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需 要再进行同步。 （摘自 《深入理解 Java 虚拟机》） 重量级锁和轻量级锁轻量级锁 “轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀（互斥）。为重量级锁。轻量级锁是通过 虚拟机中栈帧标志位 Lock Record 实现的，具体参考《深入Java虚拟机》13章锁优化。而传统的重量级锁使用到了操作系统的互斥变量来实现，消耗资源比较大。 重量级锁（Mutex Lock） Synchronized 是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为“重量级锁”。JDK 中对 Synchronized 做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6 以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。 锁升级随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级到重量级锁（锁升级的方式是单向的，不会出现降级的情况），这个问题也困扰了我一段时间，尤其是锁是在什么时候会升级。 可以将偏向锁、轻量级锁认为是乐观锁，重量级锁是悲观锁，以下是我对锁升级的理解 在一个对象实例化后，如果没有线程访问这个对象时，首先锁会偏向于第一个获取它的线程，如果在接下来的执行过程中，没有其他线程竞争该锁，那么就偏向第一个线程；则这个线程修改对象头称为偏向锁的标志使用 CAS 操作，将对象头的 ID 改成这个线程ID，之后访问该对象的时候，只需要比较线程ID，而不需要进行 CAS 操作。 一旦有第二个线程来访问该锁，第二个锁会查看该锁的偏向状态，检查原来持有该偏向锁的线程的状态。 如果第一个线程挂了，那么该对象为无锁状态，重新偏向新的线程 如果第一个线程依然存活，则检查该线程的操作栈，检查其是否继续持有偏向锁，如果持有则升级为轻量级锁，如果不持有则重新偏向。 轻量级锁认为竞争存在，但是很低，对一个锁的操作会错开或者说可以通过自旋锁的操作进行等待一阵子，另一个锁就会释放锁。该锁就为轻量级锁。 如果线程自旋超过一定时间，或者此时一个线程在持有轻量级锁、另一个在自旋操作，又有第三个线程来访时，那么轻量级锁就会膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。 锁的种类乐观锁和悲观锁乐观锁是一种乐观思想，任务读多写少，遇到并发写的可能性很低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样更新，如果不一样则要重复读-比较-写的操作）。 java 中的乐观锁基本都是通过 CAS 操作实现的，CAS 是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。 悲观锁的思想则和乐观锁的思想相反，为悲观思想，认为写多读少，遇到并发写的可能性高，每次去拿数据的时候认为别人都会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会 block 直到拿到锁，Java 悲观锁就是 Synchronized，AQS 框架下的锁则是先尝试 cas 乐观锁去获取锁，获取不到，才会转化为悲观锁，如 RetreenLock。 自旋锁自旋锁则是表示如果持有锁的线程在很短的时间内释放资源，那么等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，他们只需要等一等（自旋），等待有锁的线程释放锁后既可立即获得锁。这样就避免了用户线程和内核之间的切换。 线程自旋是需要消耗 CPU 的，说白了就是让 CPU 在做无用功，如果一直获取不到锁，那线程也不能一直占用 CPU 自旋做无用功，所以需要设定一个自旋等待的最大时间。如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。 公平锁和非公平锁公平锁：加锁钱检查是否有排队等待的线程，优先排队等待的线程，先来先得 非公平锁：加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待。 非公平锁性能比公平锁搞 5~10倍，因为公平锁需要在多核的情况下维护一个队列。 Java 中的 synchronized 是非公平锁。ReentrantLock 默认的 lock() 方法采用的是非公平锁。 分段锁分段锁也是一种锁的思想，意为将数据分段上锁。 具体应用如下：HashTable 容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问 HashTable 的线程都必须竞争同一把锁，假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效提高并发访问效率，这就是 ConcurrentHashMap 所使用的锁分段技术。首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 读写锁为了提高性能，Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由 jvm 自己控制的，你只要上好相应的锁即可。 读锁 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁 写锁 如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁 Java 中 读 写 锁 有 个 接 口 java.util.concurrent.locks.ReadWriteLock ， 也 有 具 体 的 实 现ReentrantReadWriteLock。 读写锁可参考《现代操作系统》中的PV操作-读者写者问题。参考 共享锁和独占锁Java 并发包提供的加锁模式分为独占锁和共享锁。 独占锁 独占锁模式下，每次只能有一个线程持有锁，ReentrantLock 就是以独占的方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他的读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。 共享锁 共享锁则允许多个线程同时获取锁，并发访问共享资源，如 ReadWriteLock，共享锁则是一种乐观锁，放宽了加锁政策，允许多个执行读操作的线程同时访问共享资源。 AQS 的内部类 Node 定义了两个常量 SHARED 和 EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。 Java 的并发包中提供了 ReadWriteLock，读-写锁。它允许一个资源被多个读操作一起访问或者一个写操作访问，但是两者不能同时进行。 可重入锁本文里面讲的是广义上的可重入锁，而不是单指 JAVA 下的 ReentrantLock。可重入锁，也叫做递归锁，指的是同一线程外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，,但不受影响，简单来说就是可以重复获取同一把锁。在 JAVA 环境下 ReentrantLock 和 synchronized 都是 可重入锁。 java线程是基于“每线程（per-thread）”，而不是基于“每调用的（per-invocation）”的，也就是说java为每个线程分配一个锁，而不是为每次调用分配一个锁。最大的作用是避免死锁。在很多情况下线程需要多次进入锁内执行任务。 Java 锁的使用Synchronize 同步锁synchronized 它可以把任意一个非 NULL 的对象当作锁。他属于独占式的悲观锁，同时属于可重入锁。 作用范围 实例方法：作用于方法时，锁住的是对象的实例(this)。 静态方法：作用于静态方法时，锁住的是 Class 实例，又因为 Class 的相关数据都存在永久代 PermGen 中（jdk1.8之后则是 metaspace ），永久代是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程 同步代码块：作用于一个实例时，锁住的是所有以该对象为锁的代码块。它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储到不同的容器中。 Synchronized 作用范围详解参考 核心组件 Wait Set：哪些调用 wait 方法被阻塞的线程被放置在这里； Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List 中那些有资格成为候选资源的线程被移动到 Entry List 中； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为 OnDeck； Owner：当前已经获取到所资源的线程被称为 Owner； !Owner：当前释放锁的线程。 synchnized 实现 JVM 每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争，JVM 会将一部分线程移动到 EntryList 中作为候选竞争线程。 Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList 中的某个线程为 OnDeck 线程（一般是最先进去的那个线程）。 Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck，OnDeck 需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM 中，也把这种选择行为称之为“竞争切换”。 OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList中。如果 Owner 线程被 wait 方法阻塞，则转移到 WaitSet 队列中，直到某个时刻通过 notify。 处于 ContentionList、EntryList、WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux 内核下采用 pthread_mutex_lock 内核函数实现的）。 Synchronized 是非公平锁。 Synchronized 在线程进入 ContentionList 时，等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁资源。 每个对象都有个 monitor 对象，加锁就是在竞争 monitor 对象，代码块加锁是在前后分别加上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个标记位来判断的 synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。 Java1.6，synchronized 进行了很多的优化，有适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等，效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中，均对该关键字的实现机理做了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀； JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:UseBiasedLocking 来禁用偏向锁。 锁实现参考 ReentrantLockAQSSemaphare 信号量AtomicInteger 原子操作锁优化","raw":null,"content":null,"categories":[{"name":"JUC","slug":"JUC","permalink":"https://fan-yu-feng.github.io/categories/JUC/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://fan-yu-feng.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"Linux集群搭建","slug":"Linux/Linux集群搭建","date":"2020-08-17T04:45:16.000Z","updated":"2021-12-24T03:26:59.063Z","comments":true,"path":"2020/08/17/Linux/Linux集群搭建/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/17/Linux/Linux%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"部署Linux集群最近开始搞linux集群搭建，方便项目部署集群到linux服务器上，我选择安装的是centos7 （据说大多数企业使用的都是这个）\n虚拟机比较方便，就算炸了重新安装就好了。\ncentos下载：\n访问其官网，官网            点击Get CentOS Now，点击alternative downloads，点击CentOS 7列表中的x86_64，点击\nhttp://mirrors.163.com/centos/7/isos/x86_64/\n里边有几个不同的版本。其中这两个比较常用。其他的可以查看0_README.txt中查看各版本的区别。\n阿里云站点进行下载\nActual Country 国内资源          Nearby Countries 周边国家资源\n阿里云站点\n每个链接都包括了镜像文件的地址、类型及版本号等信息\n选择当前国家资源区站点下载，获取资源速度比较快","text":"部署Linux集群最近开始搞linux集群搭建，方便项目部署集群到linux服务器上，我选择安装的是centos7 （据说大多数企业使用的都是这个） 虚拟机比较方便，就算炸了重新安装就好了。 centos下载： 访问其官网，官网 点击Get CentOS Now，点击alternative downloads，点击CentOS 7列表中的x86_64，点击 http://mirrors.163.com/centos/7/isos/x86_64/ 里边有几个不同的版本。其中这两个比较常用。其他的可以查看0_README.txt中查看各版本的区别。 阿里云站点进行下载 Actual Country 国内资源 Nearby Countries 周边国家资源 阿里云站点 每个链接都包括了镜像文件的地址、类型及版本号等信息 选择当前国家资源区站点下载，获取资源速度比较快 在安装时有个三个网络模式不太懂，参考这位博客答主的讲解 虚拟机网络模式网络模式参考链接 无论是vmware,virtual box,virtual pc等虚拟机软件，一般来说，虚拟机有三种网络模式: 1.桥接 2.NAT 3.Host-Only 桥接 桥接网络是指本地物理网卡和虚拟网卡通过VMnet0虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位，那么物理网卡和虚拟网卡就相当于处于同一个网段，虚拟交换机就相当于一台现实网络中的交换机,所以两个网卡的IP地址也要设置为同一网段。 所以当我们要在局域网使用虚拟机，对局域网其他pc提供服务时，例如提供ftp，提供ssh，提供http服务，那么就要选择桥接模式。 例如大学宿舍里有一个路由器，宿舍里四个人连接这个路由器，路由器的wanip就不理会了，这个ip是动态获取的，而lanip默认是192.168.1.1,子网掩码是255.255.255.0。而其他四个人是自动获取ip，假设四个人的ip是: A:192.168.1.100/255.255.255.0, B:192.168.1.101/255.255.255.0, C:192.168.1.102/255.255.255.0, D:192.168.1.103/255.255.255.0 那么虚拟机的ip可以设置的ip地址是192.168.1.2-192.168.1.99,192.168.1.104-192.168.1.254(网络地址全0和全1的除外，再除去ABCD四个人的ip地址) 那么虚拟机的ip地址可以设置为192.168.1.98/255.255.255.0,设置了这个ip地址，ABCD这四个人就可以通过192.168.1.98访问虚拟机了，如果虚拟机需要上外网，那么还需要配置虚拟机的路由地址，就是192.168.1.1了，这样，虚拟机就可以上外网了，但是，上网我们一般是通过域名去访问外网的，所以我们还需要为虚拟机配置一个dns服务器，我们可以简单点，把dns服务器地址配置为google的dns服务器:8.8.8.8,到此，虚拟机就可以上网了。 NATNAT模式中，就是让虚拟机借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。 NAT模式中，虚拟机的网卡和物理网卡的网络，不在同一个网络，虚拟机的网卡，是在vmware提供的一个虚拟网络。 NAT和桥接的比较: (1) NAT模式和桥接模式虚拟机都可以上外网。 (2) 由于NAT的网络在vmware提供的一个虚拟网络里，所以局域网其他主机是无法访问虚拟机的，而宿主机可以访问虚拟机，虚拟机可以访问局域网的所有主机，因为真实的局域网相对于NAT的虚拟网络，就是NAT的虚拟网络的外网，不懂的人可以查查NAT的相关知识。 (3) 桥接模式下，多个虚拟机之间可以互相访问；NAT模式下，多个虚拟机之间也可以相互访问。 如果你建一个虚拟机，只是给自己用，不需要给局域网其他人用，那么可以选择NAT，毕竟NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，只要虚拟机的网路配置是DHCP，那么你不需要进行任何其他的配置，只需要宿主机器能访问互联网即可，就可以让虚拟机联网了。 例如你想建多个虚拟机集群，作为测试使用，而宿主机可能是一个笔记本，ip不固定。这种应用场景，我们需要采用nat模式了，但是我们要考虑一个问题，虚拟机之间是需要互访的，默认采用dhcp，虚拟机的ip每次重启，ip都是不固定的，所以我们需要手工设置虚拟机的ip地址。 但是我们对虚拟机网卡所在的虚拟网络的信息还一无所知，例如虚拟机网络的路由地址，子网掩码，所以我们需要先查下nat虚拟网络的信息。 使用vmware,在Edit-&gt;Virtual Network Editor中配置好虚拟网络信息后看到下图所示，注意VMnet8，VMnet8相当于是本机的一个路由，虚拟机设置NAT后就通过这个路由进行上网的，可以查看其网络地址，路由地址，子网掩码。 选择VMnet8-&gt;NAT设置,可以看到子网ip显示为192.168.233.0，子网掩码是255.255.255.0，那路由地址呢，其实就是网关IP了，都是同个东西，这里是192.168.233.2。 接下来就好办了，在对应的虚拟机设置好ip，子网掩码，路由地址就可以上外网了，至于dns可以设置为8.8.8.8. Host-Only 在Host-Only模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。其实Host-Only网络和NAT网络很相似，不同的地方就是Host-Only网络没有NAT服务，所以虚拟网络不能连接到Internet。主机和虚拟机之间的通信是通过VMware Network Adepter VMnet1虚拟网卡来实现的。 Host-Only的宗旨就是建立一个与外界隔绝的内部网络，来提高内网的安全性。这个功能或许对普通用户来说没有多大意义，但大型服务商会常常利用这个功能。如果你想为VMnet1网段提供路由功能，那就需要使用RRAS，而不能使用XP或2000的ICS，因为ICS会把内网的IP地址改为192.168.0.1，但虚拟机是不会给VMnet1虚拟网卡分配这个地址的，那么主机和虚拟机之间就不能通信了。 综述 在VMware的3中网络模式中，NAT模式是最简单的，基本不需要手动配置IP地址等相关参数。至于桥接模式则需要额外的IP地址，如果是在内网环境中还很容易，如果是ADSL宽带就比较麻烦了，ISP一般是不会大方的多提供一个公网IP的。 安装centos7虚拟机点击新建，新建虚拟机，然后选择下载好的centos7安装包就好了。 设置分配内存的大小为20G 自定义硬件设置 内存建议至少1GB。处理器数量选择1，每个处理器的核心数量选择2，这样相当于1颗物理CPU，2颗逻辑CPU。网络适配器，选择NAT模式，这种网络模式是兼容性最好的。选择下载的ISO镜像文件。 网络部分我选择了桥接模式 桥接模式：这种模式下，虚拟机和物理机连的是同一个网络，虚拟机和物理机是并列关系，地位是相当的。比如，你家有路由器，那么你的电脑和你的手机同时连接这个路由器提供的Wi-Fi，那么它们的关系就是这种模式。 NAT模式：这种模式下，物理机会充当一个“路由器”的角色，虚拟机要想上网，必须经过物理机，那物理机如果不能上网，虚拟机也就不能上网了。之所以说这种模式兼容性最好，是因为物理机的网络环境变化时，虚拟机的网络并不会有影响，比如，上班时你把物理机连接在公司的网络环境中，下班后又把物理机连接在你家的路由器上。你公司的网段有可能和你家的网段是不同的。桥接模式下，虚拟机和物理机一样，都要自动获取IP才可以上网，而做实验的时候，是需要把虚拟机设置为静态IP的，这样就导致虚拟机网络不稳定。而设置为NAT模式，虚拟机的网络并不需要依赖你公司的网络环境或者你家的网络环境。 仅主机模式：这种模式下，相当于拿一根网线直连了物理机和虚拟机。 安装配置：按需选择。 安装位置：我选择自动安装 设置密码，也可以创建用户，我选择安装完之后在创建 安装完成后重启 同意协议后完成配置 设置用户： 安装完成，接下来配置网络 配置网络子网Ip设置 Nat设置 DHCP设置 打开控制中心的网络设置，再VMnet8中设置IP地址和网关 再设置界面中手动设置IP地址 还有手动配置网卡 试着ping一下外网和本机地址，发现都能测通，那就没问题了 这样网络就配置好了；也可以手动配置 cd /etc/sysconfig/network-scripts/vim ifcfg-ens33 1234567891011121314151617181920212223242526TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=static # 设置静态Ip地址 不然会自动分配（DHCP）DEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=2822479b-53eb-45cc-ba8e-78fe5b353ee4DEVICE=ens33ONBOOT=yesIPADDR=192.168.80.128 #手动指定Ip地址GETWAY=192.168.80.1 #网关NETMASK=255.255.255.0 #子网掩码DNS1=8.8.8.8DNS2=114.114.114.114HWADDR=00:0C:29:A2:87:C1 #网卡MAC地址PREFIX=24GATEWAY=192.168.80.1 #最后更新一下网络服务service network restart 配置完，刷新一下网络，然后就发现外网和主机都能ping通了 参考链接 ping通之后就可以ssh登录虚拟机来进行远程的操作， ps：如果没关防火墙记得关 1.查看状态：service iptables status2.关闭： service iptables stop3.查看启动：chkconfig iptables –list4.禁止启动：chkconfig iptables off 查看防火墙状态 1systemctl status firewalld 暂时关闭防火墙 123systemctl stop firewalldservice iptables stop 3.永久关闭防火墙 123systemctl disable firewalldchkconfig iptables off ​ 4:重启防火墙 123systemctl enable firewalldservice iptables restart 插件下载时间同步插件 yum -y install ntpdate 时间同步插件 ntpdate cn.pool.ntp.org # 同步时间 hwclock –systohc 将时间写入硬盘 克隆虚拟机在原有的虚拟机上右键点击克隆，完整克隆，在新的目录下保存就好了，这一步克隆好了没截图 这样另外两台虚拟主机就完成了，只需要将IP地址和主机MAC地址相应的修改一下就好了,对应关系 Centos01 192.168.80.128 Centos02 192.168.80.129 Centos03 192.168.80.130 然后测试一下相互之间的网络能通，这样一个linux的网络集群就搭建好了，接下来就是安装软件已经环境配置了，你们也可以先在一部虚拟机上安装好需要的软件和环境在克隆。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://fan-yu-feng.github.io/categories/Linux/"}],"tags":[{"name":"集群","slug":"集群","permalink":"https://fan-yu-feng.github.io/tags/%E9%9B%86%E7%BE%A4/"}]},{"title":"计算机网络-5-应用层","slug":"计算机网络/计算机网络-5-应用层","date":"2020-08-09T11:48:56.000Z","updated":"2021-12-24T03:26:59.288Z","comments":true,"path":"2020/08/09/计算机网络/计算机网络-5-应用层/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-5-%E5%BA%94%E7%94%A8%E5%B1%82/","excerpt":"6.应用层6.1 域名系统 DNS域名的作用：负责解析域名，将域名解析成IP地址\n\n许多应用层软件经常直接使用域名系统 DNS (Domain Name System)，但计算机的用户只是间接而不是直接使用域名系统。 \n\n因特网采用层次结构的命名树作为主机的名字，并使用分布式的域名系统 DNS。\n\n名字到 IP 地址的解析是由若干个域名服务器程序完成的。域名服务器程序在专设的结点上运行，运行该程序的机器称为域名服务器。  \n\n\n域名解析测试：\nnslookup www.91xueit.com","text":"6.应用层6.1 域名系统 DNS域名的作用：负责解析域名，将域名解析成IP地址 许多应用层软件经常直接使用域名系统 DNS (Domain Name System)，但计算机的用户只是间接而不是直接使用域名系统。 因特网采用层次结构的命名树作为主机的名字，并使用分布式的域名系统 DNS。 名字到 IP 地址的解析是由若干个域名服务器程序完成的。域名服务器程序在专设的结点上运行，运行该程序的机器称为域名服务器。 域名解析测试： nslookup www.91xueit.com 6.1.2 因特网的域名结构 因特网采用了层次树状结构的命名方法。 任何一个连接在因特网上的主机或路由器，都有一个唯一的层次结构的名字，即域名。 域名的结构由标号序列组成，各标号之间用点隔开： ​ … . 三级域名 . 二级域名 . 顶级域名 各标号分别代表不同级别的域名。 如www.baidu.com 顶级域名 TLD (Top Level Domain) (1) 国家顶级域名 nTLD：如: .cn 表示中国，.us 表示美国，.uk 表示英国，等等。 (2) 通用顶级域名 gTLD：最早的顶级域名是： .com （公司和企业） .net （网络服务机构） .org （非赢利性组织） .edu （美国专用的教育机构（） .gov （美国专用的政府部门） .mil （美国专用的军事部门） .int （国际组织） 因特网的域名空间 6.1.3 域名服务器域名的解析过程 安装自己的域名服务器（需求） 解析内网自己的域名 降低到Internet的域名解析流量 域环境 在打开的控制面板窗口，选择“网络和Internet项”图标，在打开的窗口中点击“查看网络状态和任务”快捷链接，点击“更改适配器设置”快捷链接，在打开的网络连接窗口，就可以看到电脑中本地连接的列表了，然后右键点击正在使用的本地链接，在弹出菜单中选择“属性”菜单项，在打开的本地连接属性窗口，找到“Internet协议4（TCP/IPV4）”项，双击该项，或是选择后点击“属性”按钮，在打开的属性设置窗口，选择“使用下面的IP地址”项，在下面输入你的IP地址、子网掩码及网关就可以了 DHCP协议- 动态主机配置 在dos命令行下，使用 （在本网段自动分配地址） ipconfig /release 释放Ip租约 ipconfig /renew 重新请求地址 跨网段自动分配地址使用到了DHCP中继代理， 并不是每个网络上都有 DHCP 服务器，这样会使 DHCP 服务器的数量太多。现在是每一个网络至少有一个 DHCP 中继代理，它配置了 DHCP 服务器的 IP 地址信息。 当 DHCP 中继代理收到主机发送的发现报文后，就以单播方式向 DHCP 服务器转发此报文，并等待其回答。收到 DHCP 服务器回答的提供报文后，DHCP 中继代理再将此提供报文发回给主机。 跨网段地址分配 ![跨网段地址分配](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/6-应用层/DHCP协议- 动态主机配置.png) 如图三个网段：192.168.1.0 、192.168.2.0 、192.168.3.0 只有一台DHCP服务器。可以更改如下配置使一台DHCP服务器给三个网段地计算机分配地址。 在DHCP服务器中创建三个网段：192.168.1 、 192.168.2 、 192.168.3 的作用域（地址池）。 在路由器的 6/1 和 6/0 端口分别配置如下命令： ip helper-address 192.168.1.9 这条命令便可实现跨网段的地址分配。注意要在路由器对应网段的端口处配置。192.168.1.9为DHCP服务器的地址。 配置了该命令的路由器也称为DHCP中继代理。 过程192.168.1网段的计算机通过广播的形式向DHCP服务器请求地址；通过配置路由器中连接其他网段的端口上述命令，这些网段中的计算机可通过单播的形式通过路由器转发向DHCP服务器请求地址。 DHCP服务器通过区分收到的请求地址信息是单播还是广播来判定是本网段计算机请求地址还是其他网段计算机请求地址。 最后DHCP服务器从三个网段的地址池中选出地址分别分配给三个网段。 DHCP服务器必须是静态地址 因为DHCP服务器是根据该静态地址为本网段的计算机分配地址的。 补充 可以发现计算机向本网段的DHCP服务器请求地址时采用的是广播的方式，相当于知道MAC地址请求IP地址。这与之前讲的ARP协议通过IP地址请求MAC地址正好相反，可以说是逆向ARP协议，即RARP（反向地址转换）协议。 6.2 文件传送协议（File Transfer Porofer Protocol）6.2.1 FTP 概述 文件传送协议 FTP (File Transfer Protocol) 是因特网上使用得最广泛的文件传送协议。 FTP 提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限。 6.2.2 FTP 的基本工作原理特点 文件传送协议 FTP 只提供文件传送的一些基本的服务，它使用 TCP 可靠的运输服务。 FTP 的主要功能是减少或消除在不同操作系统下处理文件的不兼容性。 FTP 使用客户服务器方式。一个 FTP 服务器进程可同时为多个客户进程提供服务。FTP 的服务器进程由两大部分组成：一个主进程，负责接受新的请求；另外有若干个从属进程，负责处理单个请求，主进程与从属进程的处理是并发地进行。 FTP传输模式 文本模式：ASCII模式，以文本序列传输数据； 二进制模式：Binary模式，以二进制序列传输数据； FTP 使用的两个 TCP 连接 第一个TCP连接为控制连接，客户端标准端口为21，用于发送FTP命令信息； 第二个TCP连接为数据连接， 服务器端标准端口为20，用于上传、下载数据。 数据连接的建立类型： 主动模式：服务器端从20端口主动向客户端发起连接； 被动模式：服务器端打开指定范围内的某个端口被动等待客户端发起连接。（此时服务器端不使用标准端口20） 客户进程使用**熟知端口(21)**与服务器进程建立控制连接；使用另一个端口建立数据连接。 服务器进程使用**熟知端口(20)**与客户进程所提供的端口建立数据传送连接；使用另一个端口与客户端进程建立控制连接。 由于 FTP 使用了两个不同的端口号，所以数据连接与控制连接不会发生混乱；在传输文件结束时客户端还可以利用控制连接发送请求终止传输信息。 FTP主动模式与被动模式主动模式下防护墙需要打开21和20端口。ftp客户端告诉ftp服务器使用什么端口监听，ftp服务器和客户端的这个端口建立什么连接 被动模式下ftp服务器只打开一个端口，等待ftp客户端的连接，ftp服务器，如果有防火墙，需要在防火墙开21和20的端口，使用主动模式进行数据连接。 6.2.3 简单文件传送协议 TFTP特点 (1) 每次传送的数据 PDU 中有 512 字节的数据，但最后一次可不足 512 字节。 (2) 数据 PDU 也称为文件块(block)，每个块按序编号，从 1 开始。 (3) 支持 ASCII 码或二进制传送。 (4) 可对文件进行读或写。 (5) 使用很简单的首部。 发送完一个文件块后就等待对方的确认，确认时应指明所确认的块编号。 发完数据后在规定时间内收不到确认就要重发数据 PDU。 发送确认 PDU 的一方若在规定时间内收不到下一个文件块，也要重发确认 PDU。这样就可保证文件的传送不致因某一个数据报的丢失而告失败。 在一开始工作时。TFTP 客户进程发送一个读请求 PDU 或写请求 PDU 给 TFTP 服务器进程，其熟知端口号码为 69。 TFTP 服务器进程要选择一个新的端口和 TFTP 客户进程进行通信。 若文件长度恰好为 512 字节的整数倍，则在文件传送完毕后，还必须在最后发送一个只含首部而无数据的数据 PDU。 若文件长度不是 512 字节的整数倍，则最后传送数据 PDU 的数据字段一定不满512字节，这正好可作为文件结束的标志。 6.3 远程终端协议 TELNET TELNET 是一个简单的远程终端协议，也是因特网的正式标准。 用户用 TELNET 就可在其所在地通过 TCP 连接注册（即登录）到远地的另一个主机上（使用主机名或 IP 地址）。 TELNET 能将用户的击键传到远地主机，同时也能将远地主机的输出通过 TCP 连接返回到用户屏幕。这种服务是透明的，因为用户感觉到好像键盘和显示器是直接连在远地主机上。 客户服务器方式 TELNET 也使用客户服务器方式。在本地系统运行 TELNET 客户进程，而在远地主机则运行 TELNET 服务器进程。 TELNET 使用网络虚拟终端 NVT 格式： 客户软件把用户的击键和命令转换成 NVT 格式，并送交服务器。 服务器软件把收到的数据和命令，从 NVT 格式转换成远地系统所需的格式。 向用户返回数据时，服务器把远地系统的格式转换为 NVT 格式，本地客户再从 NVT 格式转换到本地系统所需的格式。 其他应用可以使用telnet命令测试某计算机是否开启相应端口的服务，相当于端口扫描工具。 6.3.1 远程桌面RDP（Remote Desktop Protocol）通过mstsc客户端远程连接计算机，并对其进行管理等操作。 与TELNET的区别在于，TELNET显示的是远程计算机的命令行窗口，而RDP为该计算机的图形界面，这样显得更加直观。 RDP=TCP+3389端口。 在运行界面输入mstsc，打开远程桌面登录界面，输入相应信息即可连接远程计算机。 Server是多用户操作系统，启用远程桌面可以多用户同时使用服务器。而Window xp和Window7是单用户系统，不能多个用户同时使用。 6.4 万维网 WWW6.4.1 概述 万维网 WWW (World Wide Web)是一个大规模的、联机式的信息储藏所。 万维网用链接的方法能非常方便地从因特网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。 这种访问方式称为“链接”。 万维网提供分布式服务： 超媒体与超文本 万维网是分布式超媒体(hypermedia)系统，它是超文本(hypertext)系统的扩充。 一个超文本由多个信息源链接成。利用一个链接可使用户找到另一个文档。这些文档可以位于世界上任何一个接在因特网上的超文本系统中。超文本是万维网的基础。 超媒体与超文本的区别是文档内容不同。超文本文档仅包含文本信息，而超媒体文档还包含其他表示方式的信息，如图形、图像、声音、动画，甚至活动视频图像。 万维网的工作方式 万维网以客户服务器方式工作。 浏览器就是在用户计算机上的万维网客户程序。万维网文档所驻留的计算机则运行服务器程序，因此这个计算机也称为万维网服务器。 客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。 在一个客户程序主窗口上显示出的万维网文档称为页面(page)。 万维网必须解决的问题 1.怎样标志分布在整个因特网上的万维网文档？ 使用统一资源定位符 URL (Uniform Resource Locator)来标志万维网上的各种文档。 使每一个文档在整个因特网的范围内具有唯一的标识符 URL。 2.用什么协议实现万维网上各种超链的链接？ 在万维网客户程序与万维网服务器程序之间进行交互所使用的协议，是超文本传送协议 HTTP (HyperText Transfer Protocol)。 HTTP 是一个应用层协议，它使用 TCP 连接进行可靠的传送，一般使用80端口。 3.怎样使各种万维网文档都能在因特网上的各种计算机上显示出来，同时使用户清楚地知道在什么地方存在着超链？ 超文本标记语言 HTML (HyperText Markup Language)使得万维网页面的设计者可以很方便地用一个超链从本页面的某处链接到因特网上的任何一个万维网页面，并且能够在自己的计算机屏幕上将这些页面显示出来。 6.4.2 统一资源定位符 URL 统一资源定位符 URL 是对可以从因特网上得到的资源的位置和访问方法的一种简洁的表示。 URL 给资源的位置提供一种抽象的识别方法，并用这种方法给资源定位。 URL 的一般形式 由以冒号隔开的两大部分组成，并且在 URL 中的字符对大写或小写没有要求。 URL 的一般形式是： ![URL 的一般形式](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/6-应用层/URL 的一般形式.png) “http”——表示使用HTTP协议； “：//“——冒号和两个左斜杠是规定的格式； “&lt;主机&gt;”——表示主机的域名； “&lt;端口&gt;”——HTTP的默认端口号是80，通常可省略； “&lt;路径&gt;”——表示文件路径，若再省略文件的&lt;路径&gt;项，则 URL 就指到因特网上的某个主页(home page)。 6.4.3 超文本传送协议 HTTPHTTP 的操作过程 为了使超文本的链接能够高效率地完成，需要用 HTTP 协议来传送一切必须的信息。 从层次的角度看，HTTP 是面向事务的(transaction-oriented)应用层协议，它是万维网上能够可靠地交换文件（包括文本、声音、图像等各种多媒体文件）的重要基础。 HTTP 的报文结构HTTP 有两类报文： 请求报文——从客户向服务器发送请求报文。 响应报文——从服务器到客户的回答。 由于 HTTP 是面向正文的(text-oriented)，因此在报文中的每一个字段都是一些 ASCII 码串，因而每个字段的长度都是不确定的。 HTTP 请求报文的结构 报文由三个部分组成，即开始行、首部行和实体主体。在请求报文中，开始行就是请求行。 方法字段——对所请求的对象进行的操作，即一些命令。请求报文的类型是由它所采用的方法决定的； HTTP 请求报文的一些方法 OPTION：请求一些选项的信息； GET：请求读取由 URL所标志的信息； HEAD：请求读取由 URL所标志的信息的首部； POST：给服务器添加信息（例如，注释）； PUT：在指明的 URL下存储一个文档； DELETE：删除指明的 URL所标志的资源； TRACE：用来进行环回测试的请求报文； CONNECT：用于代理服务器； URL字段——所请求的资源的 URL； 版本字段——表示 HTTP 的版本； HTTP 响应报文的结构![HTTP 响应报文的结构](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/6-应用层/HTTP 响应报文的结构.png) 响应报文的开始行是状态行。状态行包括三项内容，即 HTTP 的版本，状态码，以及解释状态码的简单短语。 状态码 状态码都由三个数字组成： 1xx 表示通知信息的，如请求收到了或正在进行处理； 2xx 表示成功，如接受或知道了； 3xx 表示重定向，表示要完成请求还必须采取进一步的行动； 4xx 表示客户的差错，如请求中有错误的语法或不能完成； 5xx 表示服务器的差错，如服务器失效无法完成请求； 超链接的工作过程 用户点击”链接”后所发生的事件 : 浏览器分析”文本”超链指向页面的 URL； 浏览器向 DNS 请求解析 www.123.edu.cn 的 IP 地址； 域名系统 DNS 解析出服务器的 IP 地址； 浏览器与服务器建立 TCP 连接 浏览器发出取文件命令： GET /chn/yxsz/index.htm。 服务器给出响应，把文件 index.htm 发给浏览器。 TCP 连接释放。 浏览器显示“文本”文件 index.htm 中的所有文本。 请求一个万维网文档所需的时间 RTT表示数据包（报文）往返时间。 持续连接 (persistent connection) HTTP/1.1 协议使用持续连接。 万维网服务器在发送响应后仍然在一段时间内保持这条TCP连接，使同一个客户（浏览器）和该服务器可以继续在这条TCP连接上传送后续的 HTTP 请求报文和响应报文。 这并不局限于传送同一个页面上链接的文档，而是只要这些文档都在同一个服务器上就行。 持续连接的两种工作方式 非流水线方式：客户在收到前一个响应后才能发出下一个请求。与非持续连接相比节省了建立 TCP 连接所需的一个 RTT 时间。但服务器在发送完一个对象后，其 TCP 连接就处于空闲状态，浪费了服务器资源。 流水线方式：客户在收到 HTTP 的响应报文之前就能够接着发送新的请求报文。一个接一个的请求报文到达服务器后，服务器就可连续发回响应报文。使用流水线方式时，客户访问所有的对象只需花费一个 RTT时间，使 TCP 连接中的空闲时间减少，提高了下载文档效率。 在服务器上存放用户的信息 万维网站点使用 Cookie 来跟踪用户。 Cookie 表示在 HTTP 服务器和客户之间传递的状态信息。 使用 Cookie 的网站服务器为用户产生一个唯一的识别码。利用此识别码，网站就能够跟踪该用户在该网站的活动。 6.4.4 代理服务器 (proxy server) 代理服务器(proxy server)又称为万维网高速缓存(Web cache)，它代替浏览器发出 HTTP 请求； 可以在代理服务器中设置哪些网段的计算机能通过代理服务器上网，能通过代理服务器上什么网； 万维网高速缓存把最近的一些请求和响应暂存在本地磁盘中； 当与暂时存放的请求相同的新请求到达时，万维网高速缓存就把暂存的响应发送出去，而不需要按 URL 的地址再去因特网访问该资源。 使用代理服务器的场合 1.节省内网访问 Internet 的带宽。 安装代理服务器前： 内网的所有计算机上网的流量都通过这条2Mb/s的链路，这会造成该链路时延过大。 安装了代理服务器后： 浏览器访问因特网的服务器时，要先与校园网的代理服务器建立 TCP 连接，并向代理服务器发出 HTTP 请求报文。 若代理服务器已经存放了所请求的对象，则将此对象放入 HTTP 响应报文中返回给浏览器。 否则，代理服务器就代表发出请求的用户浏览器，与因特网上的源点服务器建立 TCP 连接，并发送 HTTP 请求报文。 源点服务器将所请求的对象放在 HTTP 响应报文中返回给校园网的代理服务器。 代理服务器收到此对象后，先复制在其本地存储器中（为今后使用），然后再将该对象放在 HTTP 响应报文中，通过已建立的 TCP 连接，返回给请求该对象的浏览器。 绕过路由器的防火墙访问外网 路由器设置的防火墙会拦截目标地址或源地址为特定地址的数据包。 路由器只识别数据包的源地址和目标地址，不关心数据包内容。 如图所示，在国内的用户PC1想访问国外的某些网站时，路由器收到PC1的请求后，判断出目标地址为国外的某网于是路由器的防火墙截断了该请求，导致PC1无法成功访问； 如果PC1通过国外的代理服务器中转就可以访问外网。PC1发出的请求数据包目标地址为国外某代理服务器，请求数据包到达路由器时，路由器判断出数据包的目标地址不是防火墙设置的屏蔽地址，故能够把数据包传输给国外的代理服务器，代理服务器再把数据包传输给外网的源服务器；从外网返回的数据包通过代理服务器中转之后到达路由器时源地址变为代理服务器地址，故能绕开路由器的防火墙，成功到达PC1；由此PC1能够访问外网。 避免IP地址被跟踪 当我们在网上发表言论时，有时候隐藏个人计算机的IP地址能够带来很大便利。通过代理服务器在网络上进行活动能够有效地防止个人计算机地IP地址被跟踪。 原理为改变数据包地目标地址或源地址，过程与”上2”类似。 6.4.5 浏览器浏览器就是在用户计算机上的万维网客户程序，相当于客户端。 浏览器的结构 浏览器中的缓存 浏览器将它取回的每一个页面副本都放入本地磁盘的缓存中。 当用户用点击某个超链接时，浏览器首先检查磁盘的缓存。若缓存中保存了超链接的URL指向的文件，浏览器就直接从缓存中得到该文件副本而不必从网络获取，这样就明显地改善浏览器的运行特性。 。 但缓存要占用磁盘大量的空间，而浏览器性能的改善只有在用户再次查看缓存中的页面时才有帮助。许多浏览器允许用户调整缓存策略。 6.5 电子邮件6.5.1 电子邮件概述 电子邮件(e-mail)是因特网上使用得最多的和最受用户欢迎的一种应用。 电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人邮箱中，收件人可随时上网到自己使用的邮件服务器进行读取。 1.1.电子邮件使用的协议 发送邮件的协议：SMTP 读取邮件的协议：POP3 和 IMAP MIME 在其邮件首部中说明了邮件的数据类型(如文本、声音、图像、视像等)，使用 MIME 可在邮件中同时传送多种类型的数据。 1.2.发送电子邮件的过程简略图例为： 如图用户x在qq服务器上注册了邮箱：&#120;&#64;&#113;&#113;&#x2e;&#99;&#x6f;&#109;；用户y在163服务器上注册了邮箱：&#x79;&#64;&#49;&#54;&#51;&#x2e;&#99;&#111;&#109;；这样qq服务器和163服务器就会分别给用户x和y分配一块空间，称为邮局，地址为他们的邮箱地址。邮局分为收件箱与发件箱。 用户需要在计算机上安装邮件服务器的客户端，比如：Fox mail。用户x使用Fox mail通过身份验证后可登录到个人的邮箱：&#x78;&#x40;&#113;&#113;&#46;&#99;&#111;&#x6d;，并可以下载收件箱中的邮件。 当用户x想发邮件给用户y时，在Fox mail中新建邮件，邮件的目标地址为：&#121;&#64;&#x31;&#54;&#51;&#x2e;&#x63;&#x6f;&#x6d;，并放入其发件箱中。随后Fox mail把发件箱中的邮件通过SMTP协议发送到邮局的收件箱中。邮局：&#x78;&#64;&#x71;&#113;&#46;&#x63;&#111;&#x6d;通过DNS服务器查找邮件交换机录找出邮局：&#x79;&#64;&#49;&#54;&#x33;&#x2e;&#x63;&#x6f;&#109;的IP地址，并通过发件箱使用SMTP协议发送到邮局：&#x79;&#64;&#x31;&#x36;&#51;&#46;&#x63;&#x6f;&#x6d;的收件箱中。最后，用户y使用Fox mail通过身份验证后，使用POP3或IMAP协议从邮局：&#121;&#64;&#x31;&#54;&#x33;&#46;&#99;&#111;&#109;的收件箱中下载邮件。由此用户y收到用户x发出的邮件。 详细图例为： 用户代理 UA(User Agent) 就是用户与电子邮件系统的接口，是电子邮件客户端软件（如Fox mail）。 邮件服务器的功能是发送和接收邮件，同时还要向发信人报告邮件传送的情况（已交付、被拒绝、丢失等）。 邮件服务器按照客户服务器方式工作。邮件服务器需要使用发送和读取两个不同的协议。 一个邮件服务器收信时可作为服务器，发信时可作为客户。 几个重要步骤 1.发件人调用 PC 机中的用户代理撰写和编辑要发送的邮件。 2.发件人的用户代理把邮件用 SMTP 协议发给发送方邮件服务器， 3.SMTP 服务器把邮件临时存放在邮件缓存队列中，等待发送。 4.发送方邮件服务器通过DNS服务器找到接收方邮件服务器地址后，其 SMTP 客户与接收方邮件服务器的 SMTP 服务器建立 TCP 连接，然后就把邮件缓存队列中的邮件依次发送出去。 5.运行在接收方邮件服务器中的SMTP服务器进 程收到邮件后，把邮件放入收件人的用户邮箱中，等待收件人进行读取。 6.收件人在打算收信时，就运行 PC 机中的用户代理，使用 POP3（或 IMAP）协议读取发送给自己的邮件。 注意：POP3 服务器和 POP3 客户之间的通信是由 POP3 客户发起的。 1.3.电子邮件的组成 电子邮件由信封(envelope)和内容(content)两部分组成。 在邮件的信封上，最重要的就是收件人的地址。 1.4.电子邮件地址的格式 TCP/IP 体系的电子邮件系统规定电子邮件地址的格式如下： **收件人邮箱名@邮箱所在主机的域名 ** 符号“@”读作“at”，表示“在”的意思。例如：电子邮件地址 &#84;&#x6f;&#109;&#64;&#x71;&#x71;&#46;&#99;&#111;&#109; 。”Tom”表示用户名，在该域名范围内是唯一的；qq.com”表示邮箱所在的主机的域名，必须是全世界唯一的。 6.5.2 简单邮件传送协议 SMTP SMTP 所规定的就是在两个相互通信的 SMTP 进程之间应如何交换信息。 由于 SMTP 使用客户服务器方式，因此负责发送邮件的 SMTP 进程就是 SMTP 客户，而负责接收邮件的 SMTP 进程就是 SMTP 服务器。 SMTP 规定了 14 条命令和 21 种应答信息。每条命令用 4 个字母组成，而每一种应答信息一般只有一行信息，由一个 3 位数字的代码开始，后面附上（也可不附上）很简单的文字说明。 2.1.SMTP 通信的三个阶段 连接建立：连接是在发送主机的 SMTP 客户和接收主机的 SMTP 服务器之间建立的。SMTP不使用中间的邮件服务器。 邮件传送 连接释放：邮件发送完毕后，SMTP 应释放 TCP 连接。 6.5.3 邮件读取协议POP3 和 IMAP3.1.POP3协议 邮局协议 POP 是一个非常简单、但功能有限的邮件读取协议，现在使用的是它的第三个版本 POP3。 POP 也使用客户服务器的工作方式。 在接收邮件的用户 PC 机中必须运行 POP 客户程序，而在用户所连接的 ISP 的邮件服务器中则运行 POP 服务器程序。 3.2.IMAP 协议 (Internet Message Access Protocol) IMAP 也是按客户服务器方式工作，现在较新的是版本 4，即 IMAP4。 用户在自己的 PC 机上就可以操纵 ISP 的邮件服务器的邮箱，就像在本地操纵一样。 IMAP 是一个联机协议。当用户 PC 机上的 IMAP 客户程序打开 IMAP 服务器的邮箱时，用户就可看到邮件的首部。 3.3.IMAP 的特点 IMAP最大的好处就是用户可以在不同的地方使用不同的计算机随时上网阅读和处理自己的邮件。 IMAP 还允许收件人只读取邮件中的某一个部分。例如，收到了一个带有视像附件（此文件可能很大）的邮件。为了节省时间，可以先下载邮件的正文部分，待以后有时间再读取或下载这个很长的附件。 IMAP 的缺点是如果用户没有将邮件复制到自己的 PC 机上，则邮件一直是存放在 IMAP 服务器上。因此用户需要经常与 IMAP 服务器建立连接。 注意 不要将邮件读取协议 POP 或 IMAP 与邮件传送协议 SMTP 弄混。 发信人的用户代理向源邮件服务器发送邮件，以及源邮件服务器向目的邮件服务器发送邮件，都是使用 SMTP 协议。 而 POP 协议或 IMAP 协议则是用户从目的邮件服务器上读取邮件所使用的协议。 6.5.4 基于万维网的电子邮件![基于万维网的电子邮件](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/6-应用层/MIME 和 SMTP 的关系 .png) 电子邮件从 A 发送到网易邮件服务器是使用 HTTP 协议。 两个邮件服务器之间的传送使用 SMTP。 邮件从新浪邮件服务器传送到 B 是使用 HTTP 协议。 6.5.5 通用因特网邮件扩充 MIME MIME 概述 SMTP 有以下缺点： SMTP 不能传送可执行文件或其他的二进制对象。 SMTP 限于传送 7 位的 ASCII 码。许多其他非英语国家的文字（如中文、俄文，甚至带重音符号的法文或德文）就无法传送。 SMTP 服务器会拒绝超过一定长度的邮件。 某些 SMTP 的实现并没有完全按照[RFC 821]的 SMTP 标准。 MIME 的特点 MIME 并没有改动 SMTP 或取代它。 MIME 的意图是继续使用目前的[RFC 822]格式，但增加了邮件主体的结构，并定义了传送非 ASCII 码的编码规则 **MIME 和 SMTP 的关系 ** **MIME 主要包括三个部分 ** 5 个新的邮件首部字段，它们可包含在[RFC 822]首部中。这些字段提供了有关邮件主体的信息。 定义了许多邮件内容的格式，对多媒体电子邮件的表示方法进行了标准化。 定义了传送编码，可对任何内容格式进行转换，而不会被邮件系统改变。 **MIME 增加 5 个新的邮件首部 ** MIME-Version: 标志 MIME 的版本。现在的版本号是 1.0。若无此行，则为英文文本； Content-Description: 这是可读字符串，说明此邮件是什么。和邮件的主题差不多； Content-Id: 邮件的唯一标识符； Content-Transfer-Encoding: 在传送时邮件的主体是如何编码的； Content-Type: 说明邮件的性质； **MIME的内容传送编码 (Content-Transfer-Encoding) ** 最简单的编码就是 7 位 ASCII 码，而每行不能超过 1000 个字符。MIME 对这种由 ASCII 码构成的邮件主体不进行任何转换。 另一种编码称为 quoted-printable，这种编码方法适用于当所传送的数据中只有少量的非 ASCII 码。 对于任意的二进制文件，可用 base64 编码。 **MIME内容类型 ** MIME的标准规定 Content-Type 说明必须含有两个标识符，即内容类型(type)和子类型(subtype)，中间用“/”分开。 MIME 标准定义了 7 个基本内容类型和 15 种子类型。","raw":null,"content":null,"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"计算机基础知识","slug":"计算机网络/计算机基础知识","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"408","slug":"408","permalink":"https://fan-yu-feng.github.io/tags/408/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络-4-运输层","slug":"计算机网络/计算机网络-4-运输层","date":"2020-08-09T11:48:46.000Z","updated":"2021-12-24T03:26:59.286Z","comments":true,"path":"2020/08/09/计算机网络/计算机网络-4-运输层/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-4-%E8%BF%90%E8%BE%93%E5%B1%82/","excerpt":"传输层概述 回顾\n应用层  Http Https  ftp DNS SMTP PoP3 RDP\n传输层     TCP    UDP\n网络层    IP（RIP OSPF    BGP）     ICMP IGMP ARP","text":"传输层概述 回顾 应用层 Http Https ftp DNS SMTP PoP3 RDP 传输层 TCP UDP 网络层 IP（RIP OSPF BGP） ICMP IGMP ARP 传输层的两个应用场景TCP 分段传输，给每段数据编号，接收端按照编号检查，丢哪个包就叫发送端重传），流量控制，是可靠性传输，建立会话：netstat -n可查看会话。例：下载文件，（发送方要把数据分成多个数据包并编上号，接收端收到之后检查编号是否完整，再把所有数据包按编号串起来才能完整接受）、访问网站、上传文件。 UDP 不编号，一个数据包就能完成数据通信，只扔出一个数据包，丢了就连接失败，不建立会话，是不可靠传输。例如：qq聊天、多播（老师把自己的电脑画面播到每个学生电脑上）； 运输层与应用层之间的关系 http协议，使用80端口，HTTP=TCP+80 使用https安全传输时，使用443端口，https=TCP+443 ftp=TCP+21 SMTP=TCP+25 POP3=TCP+110 RDP=TCP+3389 共享文件夹=TCP+445 SQL=TCP+1433 DNS=UDP+53 or TCP+53; 应用层协议其实就是传输层的两种主要协议加上相应端口来表示是哪一种应用层协议。其实就是传输层协议加上一个使用的端口号就表示一种应用。比如可以这样命名一个应用层协议：KON=TCP+4000 。 应用层协议和服务之间的关系服务（对外提供的服务）运行后在TCP或UDP的某个端口侦听客户端请求。 一台计算机上可能运行有多种服务，但是只有一个IP地址。 Web：80； ftp：21； smtp：25； pop3：110； 假设IP地址为：101.100.0.0，用端口来定位服务，用IP地址来定位计算机。 查看自己计算机侦听的端口： 测试远程计算机打开的端口： 1telnet 10.7.1.53 21 端口代表服务，如果telnet命令返回提示端口失败，说明不能访问这个服务。 更改端口增加服务器安全黑客可能会使用端口扫描工具，扫描到用户计算机打开侦听的端口，以此判断用户计算机提供的哪种服务，以展开攻击。 可以通过更改服务对应的端口增加服务器的安全性能。 Windows防火墙的作用 计算机的服务对应着一个端口。比如装上ftp服务，该计算机就在网卡上侦听21端口，是可见的，可用netstat -an查看侦听端口，安装Web服务，计算机就打开80端口侦听客户端的请求，若没有启用该服务，使用netstat -an命令查看时看不到80端口的。客户端要连接时，数据包要写上目标端口，比如目标端口为21，服务器就知道客户端访问的是ftp服务，也就是上面所说的用端口来区分服务。 如果把计算机的所有端口都关闭，那么该计算机相当于在互联网上隐身了，谁也访问不了它。但是它却可以访问其他计算机，因为Windows防火墙不拦截出去的流量，拦截进来的流量（计算机与外界通信完毕，端口关闭，是动态的）。例如：你ping别人不通，别人ping你通，说明别人设置了防火墙。 如果该计算机装了许多服务，但是只向外提供Web服务，只需要在网卡上打开80端口，关闭其余端口，发送过来的数据包只能访问80端口服务，若数据包目标端口为21端口，网卡会进行拦截，这样即使服务器本身运行了ftp服务，打开了21端口侦听，外面也访问不了，即使ftp服务有漏洞外面用户也攻击不了。也就是说在服务器上只开必要的端口，其实是增加了服务器的安全。 Win10则是设置防火墙，对对应的端口进行入站和出站的规则设置。如图进入防火墙设置，点击高级设置 点击出站或者入站规则，右击新建规则 点击端口、下一步，进入防火墙设置出站入站端口，可以对一些特定的端口进行连接设置。 总的来说，防火墙对于外部的主动访问时拒绝的，但是对于内部访问外部则是不理会。许多木马程序时依据此来进行入侵。 网络安全的一些应用 使用网络层安全设置，严格控制流量的出入。如果该计算机只提供Web服务，那么该计算机只允许目标地址或源地址为80端口的数据包通过，从而达到严格管控其他目标地址或源地址非80端口的数据包的出入。比如灰鸽子木马使用的是8000端口，即使用户主动下载并安装了木马程序，由于出去的相关数据包源地址为8000端口（非80端口），所以会被拦截，以此在网络层实现信息安全。 再如：一个放在公网公开的服务器A，只要能猜对该计算机的用户名和密码，任何网段的计算机都可以通过远程桌面控制该计算机。可以新增的网络层安全措施为：在服务器A上设置只允许计算机B的IP地址通过远程桌面控制服务器A，这样想要黑服务器A必须先获取计算机B的用户名和密码，再获取服务器A的用户名和密码才能成功黑入服务器A。由此通过网络层提高了服务器A的安全性能。 运输层协议 TCP/UDP（重点）一、用户数据报UDP概述 UDP 只在 IP 的数据报服务之上增加了很少一点的功能，即端口的功能和差错检测的功能。 虽然 UDP 用户数据报只能提供不可靠的交付，但 UDP 在某些方面有其特殊的优点。 UDP的主要特点 无连接，发送数据不需要连接 尽最大努力交付，不保证可靠交付，不使用拥塞控制 面向报文，符合多媒体通信要求 支持一对一、多对多、多对一、和多对多的通信要求 首部开销小只有8字节（IP20 字节） UDP是面向报文的 发送方应用程序交下来的报文，无论多长，不拆分也不合并，保留报文边界，一次发送一个报文，应用程序必须选择合适大小的报文。 UDP首部格式 可以看出UDP对于首部格式是没有编号字段的，因为UDP协议只传输一个数据包，所以不需要编号。 用户数据报 UDP 有两个字段：数据字段和首部字段。首部字段有 8 个字节，由 4 个字段组成，每个字段都是两个字节。 计算校验和：临时把“伪首部”和 UDP 用户数据报连接在一起。伪首部仅仅是为了计算检验和。 例： 明确需要计算“校验和”来检验UDP报文的准确性即可 UDP基于端口的分用 二、传输控制协议TCP概述TCP是面向连接的协议，要先确保网络畅通才能传数据（如电话），每个TCP连接只有两个点，是点到点的通信，TCP提供可靠的交互、全双工通信，并且面向字节流。 TCP字节的概念 注意： 连接为虚连接 TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）。 TCP 可把太长的数据块划分短一些再传送。TCP 也可等待积累有足够多的字节后再构成报文段发送出去。 每一条 TCP 连接有两个端点。 TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字(socket)或插口。 端口号拼接到(contatenated with) IP 地址即构成了套接字。即端点=IP地址+端口号。 每一条 TCP 连接唯一地被通信两端的两个端点（即两个套接字）所确定。即： TCP首部 TCP首部包括20字节的固定首部以及可变字长的其他选项，所以TCP首部长度可变。20个字节又分为5部分，每部分4个字节32位，如图中的5行，每行表示32位。 在传输层，TCP报文段包括：TCP首部和TCP数据部分；在网络层，TCP报文段成为IP数据部分，加上IP首部组成IP数据报；在数据链路层，还要在IP数据报前面加上数据链路层的首部。 源端口和目的端口字段——各占 2 字节（16位）。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。 序号字段——占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。比如分组的第一个数据包由文件的14个字节数据组成，那么该数据包所添加的序号就是1，同理第二个数据包由文件的59个字节数据组成，那么该数据包所添加的序号就是5； 确认号字段——占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。比如接收端收到由文件14个字节数据+TCP首部组成的数据包后，删除首部提取14个字节数据，返回的确认号为5，即告诉发送端下一次应该发送文件的第5个字节及其之后字节组成的数据包过来 数据偏移（即首部长度）——占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远，也就是TCP首部的长度。“数据偏移”的单位是 32 位字（以 4 字节为计算单位），最大1111表示15x4=60个字节，即表示TCP首部最大长度为60个字节，因此“选项”部分最多40个字节。 保留字段——占 6 位，保留为今后使用，但目前应置为 0。 这里的六位二进制位，分别表示不同含义： 紧急 URG —— 当 URG = 1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。 即URG=1的数据包不用排队直接优先传输。 同步 SYN —— 同步 SYN = 1 表示这是一个连接请求或连接接受报文。即A想与B建立连接，发送过去的第一个数据包（第一次握手）中SYN=1；B返回的数据包（第二次握手）中SYN=1表示同意建立连接。 确认 ACK —— 只有当 ACK = 1 时确认号字段才有效。当 ACK = 0 时，确认号无效。 ACK是对已接受数据的确认，当A与B还在请求连接阶段，A向B发送的第一个数据包（第一次握手）中ACK=0，无效，所以数据包中不显示，表示还没从B中接收到数据；序号Seq也为0，表示A还未向B发送数据；SYN=1，表示正在建立连接。 同理，B向A返回一个数据包（第二次握手）中，确认号ACK=1，表示B收到了A序号为0的数据包；序号Seq=0，也表示B还未向A发送数据；SYN=1表示同意建立连接。 A再向B发送一个数据包（第三次握手）中，确认号ACK=1，表示A收到了B发出的数据包；序号Seq=1，表示A已向B发送了1个数据包（即第一次握手）；SYN=0，表示已建立连接。 选项字段 —— 长度可变。TCP 最初只规定了一种选项，即最大报文段长度 MSS。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节。” 紧急指针字段 —— 占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。 检验和 —— 占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。 窗口字段 —— 占 2 字节，用来让对方设置发送窗口的依据，单位为字节。 抓包分析TCP首部我打开惠州学院的官网 https://www.hzu.edu.cn/ 刚开始，先建立连接，seq（序号=0），同步 SYN = 1 表示这是一个连接请求或连接接受报文。 这边的主机请求连接，目的主机给予回应，主机在确认，如图，为三次握手的过程，期间，主机和目的服务器协商TCP缓存、请求连接的事情 服务端同意连接，确认号ACK=1，Win是TCP连接缓存，相互告知自己TCP连接的缓存大小 主机发送确认号ACK=1，确认连接，序号Seq=1。然后就正式开始通信。可以看出请求通信是post请求。 可以看到计算机发出的第一个数据包（第一次握手）中，SYN=1，Seq=1，ACK=0无效，所以在蓝色框内只能看到序号Seq，看不到确认号ACK； 而在第三次握手中，请求建立连接的过程结束，SYN=0，ACK都为1 所以，抓包时看到大量的SYN数据包，说明计算机在大量建立会话。另外在建立连接（三次握手）时，SYN与ACK的值与正常通讯时不一样。 有一种攻击就是针对建立连接时SYN同步的机制 比如地址为102的计算机B想要与地址为101的计算机A建立连接，B向A发送请求连接数据包，并设置数据包中的源地址为不存在，A收到之后向该不存在的地址发出同意连接的数据包，发送完之后需要等待回复。于是B继续上述操作，以此类推A不断发出同意连接数据包并不断等待，由此大量耗费系统资源。 下图为使用SYN同步攻击软件攻击XP系统过程中，捕获的数据包： 红色框中的地址是攻击软件瞎编的不存在的地址，蓝色框中显示建立的会话全是请求连接的TCP报文。 可以看到在Land攻击时捕获的数据包，都是请求同步SYN数据包且源地址和目标地址都为攻击对象地址 192.168.80.66 。 推送 PSH (PuSH) —— 接收 TCP 收到 PSH = 1 的报文段，就尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。 复位 RST (ReSeT) —— 当 RST = 1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。 终止 FIN (FINis) —— 用来释放一个连接。FIN = 1 表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。 窗口字段 —— 占 2 字节，用来让对方设置发送窗口的依据，单位为字节。 TCP全部格式 TCP如何实现可靠传输使用确认和重传机制，我们在不可靠的网络上建立可靠传输的机制。这种可靠传输协议常称为自动重传请求ARQ (Automatic Repeat reQuest)。ARQ 表明重传的请求是自动进行的。接收方不需要请求发送方重传某个出错的分组 。 工作原理—停止等待 在发送完分组之后，需要保留已经发送的分组副本 对分组和确认分组都必须进行编号 超时重传的时间比数据在分组传输的平均往返时间长一些 ![image-20200811091209918](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/运输层/TCP工作原理-确认丢失和确认迟到 .png) 缺点：信道利用率太低停止等待协议的优点是简单，但缺点是信道利用率太低。 TD表示发送分组数据包用的时间，RTT是数据包传输往返的时间，TA是接受确认用的时间。 信道的利用率 U ： 解决信道利用率太低—-使用连续传输机制（流水线）连续ARQ协议 ACK表示确认报文。 现在大多采用这种方式，那如何保证可靠传输呢？采用连续ARQ协议。 假设发送窗口是5，也就是发送方一次性能发5个数据包。当发送方收到数据包1的接收确认后表示接收方接收了数据包1，之后发送窗口向前滑动一个数据包，在发送窗口中删除数据包1的缓存。 即如果发送了5个数据包后没有收到确认信息就会停止继续发送数据包。 滑动窗口方式仍需每个数据包对应一个确认，效率不高，接收端可采用累积确认。 累积确认 接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认，而是对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。 累积确认有的优点是：容易实现，即使确认丢失也不必重传。缺点是：不能向发送方反映出接收方已经正确收到的有分组的信息。 回退 如果发送方发送了前 5 个分组，而中间的第 3 个分组丢失了。这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。 这就叫做 Go-back-N（回退 N），表示需要再退回来重传已发送过的 N 个分组。 可见当通信线路质量不好时，连续 ARQ 协议会带来负面的影响。 TCP 可靠通信的具体实现（这部分并不是很详细，可参照书上的内容来学） TCP 连接的每一端都必须设有两个窗口——一个发送窗口和一个接收窗口。 TCP 的可靠传输机制用字节的序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段。 TCP 两端的四个窗口经常处于动态变化之中。 TCP连接的往返时间 RTT 也不是固定不变的。需要使用特定的算法估算较为合理的重传时间。 超时重传时间的选择 加权平均往返时间RTT TCP 每发送一个报文段，就对这个报文段设置一次计时器。只要计时器设置的重传时间到但还没有收到确认，就要重传这一报文段。 由于网络的通畅情况随时间变化，所以数据往返时间RTT是变化的。采用以下公式计算新的平均往返时间。 式中RTTs表示加权平均往返时间 （又称为平滑的往返时间），即传输数据时多次往返时间RTT的平均值。 式中，0 &lt; a &lt; 1。若 a 接近于零，表示新RTTs值较依赖旧RTT值，说明 RTT 值更新较慢，网速稳定；若选择 a 接近于 1，表示新RTTs值较依赖新RTT值，说明 RTT 值更新较快，网速不稳定。 RFC 2988 推荐的 a 值为 1/8，即 0.125。 超时重传时间 RTO (RetransmissionTime-Out) RTO 应略大于上面得出的加权平均往返时间 RTTs。 RFC 2988 建议使用下式计算 RTO： RTO = RTTs + 4 x RTTd RTTd 是 RTT 的偏差的加权平均值。 RFC 2988 建议这样计算 RTTd。第一次测量时，RTTd 值取为测量到的 RTT 样本值的一半。在以后的测量中，则使用下式计算加权平均的 RTTd： β 是个小于 1 的系数，其推荐值是 1/4，即 0.25。 TCP如何实现流量控制利用滑动窗口实现流量控制 一般说来，我们总是希望数据传输得更快一些。但如果发送方把数据发送得过快，接收方就可能来不及接收，这就会造成数据的丢失。 流量控制(flow control)就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。 流量控制举例： A 向 B 发送数据。在连接建立时，B 告诉 A：“我的接收窗口 rwnd = 400（字节）”。 TCP如何实避免网络拥塞简介 在某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏——产生拥塞(congestion)。 出现资源拥塞的条件： 对资源需求的总和 &gt; 可用资源 拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。 流量控制往往指在给定的发送端和接收端之间的点对点通信量的控制，它所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 拥塞控制所起的作用 吞吐量(throughput)表示在单位时间内通过某个网络（或信道、接口）的数据量。比如某网络的带宽为100M，那么该网络的最大吞吐量为100M/s 。 可以看到，理想的拥塞控制为：随着传输数据量（负载）的增加，数据传输速度（吞吐量）越来越快，当吞吐量达到网络的最大带宽时，继续增大传输数据量，传输的速度（吞吐量）也不会再增加，所以这样并不会造成网络拥塞导致传输速度（吞吐量）下降。例如，路由器间的带宽为100M，当传输150M数据时，路由器把处理不过来的50M数据扔掉，继续保持100M的传输速度。 当无拥塞控制时，假设两路由器间的网络带宽为100M，当传输的数据小于100M时，随着数据量（负载）的增加丢包情况越来越明显，此时成为轻度拥塞；当传输的数据量（负载）大于100M时，大量的数据包使路由器无法及时处理，错误情况越来越多，最后路由器死机，无法传输数据导致死锁，此时吞吐量为0。 在实际的拥塞控制中，网络设备随着传输的数据量（提供的负载）越来越大，传输的速度（吞吐量）越快，丢包率也越来越大，依靠拥塞控制机制会适当降低数据传输的速度（吞吐量），以减少拥塞。 拥塞控制方法简介 发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。 拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。如再考虑到接收方的接收能力，则发送窗口还可能小于拥塞窗口。 发送方控制拥塞窗口的原则是： 只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。 只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始和拥塞避免（1988年提出） 慢开始图例： 发送窗口一般等于拥塞窗口。 第一轮：刚开始cwnd=1，发送窗口也为1，发送方先发送一个报文M1测试连接通畅程度，当收到对M1报文的确认之后，cwnd+1，即发送窗口变为2，可以同时发送两个报文M2~M3； 第二轮：发送方发送两个报文M2M3，发送方收到了M2报文的确 认后使cwnd+1变为3，收到了M3报文确认后cwnd+1变为4，即每收到一个对新报文的确认（重传的不算在内）就使cwnd+1。由此cwnd=4，即发送窗口也为4，可以同时发送四个报文M4M7 。 以此类推第三轮之后cwnd=8。传输速度由慢开始，每轮翻倍，最后传输速度越来越快。 传输轮次 (transmission round) 使用慢开始算法后，每经过一个传输轮次，拥塞窗口 cwnd 就加倍。 一个传输轮次所经历的时间其实就是往返时间 RTT。 慢开始门限状态变量ssthresh 当 cwnd &lt; ssthresh 时，使用慢开始算法（cwnd每轮加倍）。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。 当网络出现拥塞时 无论处于慢开始阶段还是拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认数据包），就要把慢开始门限 ssthresh 设置为出现拥塞时的发送方发送窗口值（多数情况下等于cwnd）的一半（但不能小于2）。 然后把拥塞窗口 cwnd 重新设置为 1，执行慢开始算法。 这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 **慢开始和拥塞避免算法的实现举例 ** 可以看到，开始时采用慢开始算法，每经历一轮cwnd翻倍，传输的数据包翻倍，到第4轮时cwnd=16，意味着可以同时发送16个数据包，到达了设定的慢开始门限值ssthresh，随后采用拥塞避免算法。 采用拥塞避免算法期间，每经历一轮cwnd+1。当cwnd=24时，发送方不能准时收到确认数据包（即丢包），判断出现网络拥塞，于是把慢开始门限值ssthresh重新设为当前cwnd值（24）的一半，即12，并把cwnd重置为1 ，再次进入慢开始阶段。 可以看到：采用慢开始算法，cwnd按指数规律增长；采用拥塞避免算法，cwnd按线性规律增长。 注意 “拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。 “拥塞避免”是说在拥塞避免阶段把拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。 快重传和快恢复（1990年提出） 快重传举例 当不出现丢包情况时，接收方是每接收多个数据包才给发送方一个确认。例如每收到5个连续的数据包，发送以此确认信息。 当出现丢包情况时：如发送数据包M1~M5，丢失了M3，如按上述规律，接收方要等到接收完M5后才能向发送方反馈丢失M4的信息。实际上，接收方接连收到不连续的数据包M2、M4，就已经发现丢失了M3，可采用以下的快重传方式。 快重传举例 快重传算法要求接收方每收到一个失序的报文段后就立即发出重复确认。这样做可以让发送方尽早知道有报文段没有到达接收方。 发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段。 **快恢复算法 ** 当发送端收到连续三个重复的确认时，就执行“乘法减小”算法，把慢开始门限 ssthresh 减半。但接下去不执行慢开始算法。 由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，即拥塞窗口 cwnd 现在不设置为 1 。而是将cwnd当前值减半作为新的慢开始门限 ssthresh 值，并让cwnd的值等于这个新的慢开始门限ssthresh值。 也有人认为，由于接收了三个重复的ACK，按照上述规律没收到一个ACK，cwnd+1，所以cwnd=新ssthresh+3，这里采用前一种观点。 随后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。 这便是快恢复算法。 下为图例： ![image-20200129234028843](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/运输层/快恢复算法 .png) 快恢复算法 可以看到，当发送端收到3个重复的确认后，执行快重传算法，cwnd 快恢复是配套着快重传使用的，快恢复是相对于慢开始算法而言的。使用快恢复算法时，cwnd从较大值开始，通过拥塞避免算法逐渐线性增大，经过较短时间便能恢复比较快的传输速度；使用慢开始算法时，cwnd从1开始，需要较常时间才能达到较快的速度。 2.4.发送窗口的上限值前面讲过发送方的发送窗口是由接收方的接收窗口决定的。例如接收方的接收窗口为100字节，那么发送方的发送窗口就为100字节。实际上： 发送方的发送窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，即应按以下公式确定： 即刚开始发送数据时，由于网络情况未知cwnd的值由1开始按指数规律增大，而接收窗口的是固定的假设为100字节。此时 cwnd &lt; rwnd ，网络的拥塞窗口cwnd限制了发送窗口的最大值。 之后cwnd的值越来越大，最后被限制在接收方的接收窗口大小100字节上。此时此时 cwnd &gt; rwnd ，接收方的接收能力限制了发送窗口的最大值。 TCP传输连接管理:三次握手与四次挥手一、传输连接的三个阶段1.1.概述 传输连接就有三个阶段，即：连接建立、数据传送和连接释放。 连接建立过程中要解决以下三个问题： 要使每一方能够确知对方的存在。 要允许双方协商一些参数（如最大报文段长度，最大窗口大小，服务质量等）。 能够对运输实体资源（如缓存大小，连接表中的项目等）进行分配。 TCP 连接的建立都是采用客户服务器方式。 主动发起连接建立的应用进程叫做客户(client)。 被动等待连接建立的应用进程叫做服务器(server)。 二、TCP 的连接建立2.1.用三次握手建立 TCP 连接当客户端A想要访问服务器B上的服务，需要与B建立连接了，就要经历如下三次握手过程： 第一次握手：A先向B发送一个同步数据包（报文）。 在报文的TCP首部中：标志位：同步SYN为1，表示这是一个请求建立连接的数据包；确认标记位ACK为0，说明该数据包的确认号无效，所以该标志位可省略；序号Seq=x，x为所传送数据的第一个字节的序号。 第二次握手：B收到A发送的第一个数据包后，根据标志位SYN=1与ACK=1，判断出为主动建立连接的数据包。若B同意连接，则B发送一个数据包进行回应。 在数据包的TCP首部中：标志位：同步SYN=1；标志位：确认ACK=1；序号seq=y，y的值由B指定表示B发送数据时的第一个数据字节的序号；确认号ack=x+1，表示已经收到A发送的x个字节数据，并告诉A下次应从数据的第x+1个字节开始发送。 注意区分ACK和ack：在TCP首部中前者为标志位确认 ACK ——占 1 字节，只有当 ACK = 1 时确认号字段才有效。当 ACK = 0 时，确认号无效。；后者为确认号字段——占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。 第三次握手：A收到B的确认之后，再给A发送一个数据包。 在数据包的TCP首部中：已经没有有效的标志位：同步SYN了（即SYN=0），表示双方已同意建立连接；标志位确认ACK=1，表示收到B的确认数据包；序号seq=x+1，表示发出的数据包就是数据的第x+1个字节；确认号ack=y+1，表示收到了B发送y字节数据，并告诉B下次应从数据的第y+1个字节开始发送。 2.2.为何有第三次握手？客户端向服务器发出建立连接的请求以及服务器向客户端确认这个请求，这两个数据包（前两次握手）足以证明客户端与服务器之间的网络是畅通的，并且协商数据通信所需要的参数。比如协商接收窗口大小，所支持的数据包最大字节数等。 如果没有最后一个数据包确认（第三次握手），A先发出一个建立连接的请求数据包，由于网络原因绕远路了。A经过设定的超时时间后还未收到B的确认数据包，于是发出第二个建立连接的请求数据包，这次网路通畅，数据包很快到达B，B的确认数据包也很快就到达A。于是A与B开始传输数据，过了一会A第一次发出的建立连接的请求数据包到达了B，B以为是再次建立连接，所以又发出一个确认数据包。由于A已经收到了一个确认数据包，所以会忽略B发来的第二个确认数据包，但是B发出确认数据包之后就要一直等待A的回复，而A永远也不会回复。由此造成服务器资源浪费，这种情况多了B计算机可能就停止响应了。 第三次握手（第三个数据包）作用在于，告诉B计算机，B第二次握手发给A的确认数据包A收到了，是有效的。避免B计算机等待造成资源浪费。随后A与B可进行下一步的通信。 2.3.三次握手建立TCP连接过程的各状态 A发出请求建立连接的数据包之后进入SYN-SENT状态，表示发送了请求建立连接的同步数据包。 B收到A发出的请求建立连接的数据包之后，结束LISTEN状态，进入SYN-RCVD状态并向A发出确认数据包。 A收到确认数据包之后，结束SYN-SENT状态，进入ESTABLISHED状态，并向B发送确认数据包。 B收到A的确认数据包之后，结束SYN-RCVD状态，进入ESTABLISHED状态。 A与B都进入ESTABLISHED状态之后，开始传输数据，由此完成三次握手。 查看这些状态 可通过： 1netstat -n 在命令行窗口查看计算机建立的会话的装态。由于建立TCP连接的三次握手过程非常快，我们可以通过访问一个不存在的网址来查看：比如http://192.168.80.200 可以看到建立TCP连接时，本计算机访问了该地址的80端口（对应Web服务），并且TCP连接状态为SYN-SENT。此外本计算机还有其他已经建立的TCP连接，状态为ESTABLISHED。 如何查看SYN-RCVD状态呢？可通过模拟SYN攻击（大量模拟虚构地址与本计算机建立会话）即可查看该状态： 框内为SYN攻击虚构的地址，可看到建立TCP连接的会话都处于SYN-RECEIVED状态。 那么平常如果看到计算机有大量处于SYN-RECEIVED状态的会话说明有人利用SYN攻击器在攻击你的电脑。 三、TCP的连接释放3.1.使用四次挥手释放TCP连接数据传输结束后，通信的双方都可主动释放连接。下为A主动释放TCP连接。 第一次挥手：首先A向B发送连接释放请求报文（数据包），并停止发送数据。 在连接释放报文（数据包）的TCP首部中：标志位：终止FIN=1，意味着A要主动释放A—&gt;B的TCP连接；序号位seq为u，u值由A指定。随后等待B的确认。 第二次挥手：B收到连接释放报文之后，给A发送确认报文，此时TCP服务器进程通知高层应用进程，这样从A到B这个方向上的连接就释放了，TCP连接处于半关闭状态。此时A没有数据要发给B了，但是B还有数据要发送给A，A仍可以接收。 在确认报文的TCP首部中：标志位：确认ACK=1，表示收到了A发送的数据包，同意A释放连接；序号位seq=v，v值由B指定；确认号ack=u+1，表示已经收到A发送的u个字节数据，并告诉A下次应从数据的第u+1个字节开始发送，下面同理；此时B还可以向A传输数据。 第三次握手：若B已经没有向A发送的数据了，其应用进程就通知TCP释放连接，并向A发送确认报文。 在确认报文的TCP首部中：标志位：确认ACK=1，表示B已经把需要发给A的数据发完了；标志位：终止FIN=1，意味着B要释放B—&gt;A的TCP连接；序号seq=w，w值由B指定；确认号ack=u+1；此后B不再向A发送数据，但能接收数据。 第四次挥手：A收到B的连接释放报文段后，向B发出确认报文。 在确认报文的TCP首部中：标志位：确认ACK=1，表示收到B的确认报文，并同意B释放连接；序号seq=u+1；确认号ack=w+1； 由此通过四次挥手释放了TCP连接。 查看会话连接状态","raw":null,"content":null,"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"计算机基础知识","slug":"计算机网络/计算机基础知识","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"408","slug":"408","permalink":"https://fan-yu-feng.github.io/tags/408/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络-3-网络层","slug":"计算机网络/计算机网络-3-网络层","date":"2020-08-09T11:48:31.000Z","updated":"2021-12-24T03:26:59.285Z","comments":true,"path":"2020/08/09/计算机网络/计算机网络-3-网络层/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-3-%E7%BD%91%E7%BB%9C%E5%B1%82/","excerpt":"四、网络层4.1  网络层提供的两种服务4.1.1 虚电路服务\n虚电路表示这只是一条逻辑上的连接，分组都沿着这条逻辑连接按照存储转发方式传送，而并不是真正建立了一条物理连接。\n请注意，电路交换的电话通信是先建立了一条真正的连接。因此分组交换的虚连接和电路交换的连接只是类似，但并不完全一样。 \n","text":"四、网络层4.1 网络层提供的两种服务4.1.1 虚电路服务 虚电路表示这只是一条逻辑上的连接，分组都沿着这条逻辑连接按照存储转发方式传送，而并不是真正建立了一条物理连接。 请注意，电路交换的电话通信是先建立了一条真正的连接。因此分组交换的虚连接和电路交换的连接只是类似，但并不完全一样。 4.1.2 数据报服务因特网采用的设计思路 网络层向上只提供简单灵活的、无连接的、尽最大努力交付的数据报服务。 网络在发送分组时不需要先建立连接。每一个分组（即 IP 数据报）独立发送，与其前后的分组无关（不进行编号）。 网络层不提供服务质量的承诺。即所传送的分组可能出错、丢失、重复和失序（不按序到达终点），当然也不保证分组传送的时限。 尽最大努力交付的好处 由于传输网络不提供端到端的可靠传输服务，这就使网络中的路由器做的可以比较简单，而且价格低廉，节省成本。 如果主机中的进程之间的通信时需要可靠传输的，那么就由网络的主机中的运输层负责，（差错管理，和流量控制） 降低成本，运行方式灵活，能够适应多种应用。 如图，主机H1发送给主机H2的分组可以不同的路径传送数据报给H2. 4.1.3 数据报服务和虚电路的比较![数据报服务和虚电路的比较](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/网际协议 IP-1596974404574.png) 4.2 网际协议 IP网际协议IP是TCP/IP体系中两个最主要的协议之一；与IP协议配套时延的还有四个协议： 地址解析协议ARP（Address Resolution Protocol） 逆地址解析协议RARP（Reverse Address Resolution Protocol） 网络控制报文协议ICMP(Internet Group Management Protocol) 网际组管理协议IGMP（Internet Group Management Protocol） ![网际协议 IP](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/互连网络与虚拟互连网络 -1596974404574.png) 4.2.1 虚拟互连网络意义 所谓虚拟互联网络也就是逻辑互联网络，它的意思就是互连起来的各种物理网络的异构性本来是客观存在的，但是我们利用IP协议就可以使这些性能各异的网络从用户看来就好像使一个统一的网络 使用了IP协议的虚拟互联网络可以简称为IP网。 使用虚拟互联网络的好处使：当互联网上的主机进行通信时，就好像时在一个网络上通信一样，而看不见互联的各个具体的网络异构细节。 ![互连网络与虚拟互连网络](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/IP 地址中的网络号字段和主机号字段-1596974404574.png) 4.2.2 分类的 IP 地址​ IP地址就是每个连接因特网的主机（或者路由器）分配一个在全世界范围内是唯一的32位的标识符。IP 地址现在由因特网名字与号码指派公司ICANN (Internet Corporation for Assigned Names and Numbers)进行分配 。 ​ IP地址的编址方法 分类的 IP 地址。这是最基本的编址方法，在 1981 年就通过了相应的标准协议。 子网的划分。这是对最基本的编址方法的改进，其标准[RFC 950]在 1985 年通过。 构成超网。这是比较新的无分类编址方法。1993 年提出后很快就得到推广应用。 分类 IP 地址 每一类的地址都由两个固定长度的字段组成，其中一个字段是网络号（net-id），它标志主机或者路由器所连接到的网络，而另一个字段则是主机号（host-id），它标志着主机或者路由器 两级的IP地址表示：IP地址::={&lt;&gt;网络号,&lt;主机号&gt;} IP 地址中的网络号字段和主机号字段 ![IP 地址中的网络号字段和主机号字段](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/IP 地址与硬件地址（MAC地址）-1596974404574.png) A类地址：0000 0000 - 0111 1111 0-127 B类地址：1000 0000 - 1011 1111 128-191 C类地址：1100 0000 - 1101 1111 192-223 D类地址：1110 0000 - 1110 1111 224 -239 E类地址：1111 0000 - 1111 1111 240-255 网络类别 最大网络数 第一个可用的网络号 最后一个可用的网络号 每个网络中最大的主机数 A 126 1 126 256*256*256=16777214 B 16,383 128.1 191.255 65535 C 2097151 192.0.1 233.255.255 254 几个特殊的地址 127.0.0.1 本机环回地址 169.254.0.0 保留的私网地址 10.0.0.0 172.16.0.0 — 172.31.0.0 192.168.0.0 - 192.168.255.0 4.2.3 IP 地址与硬件地址（MAC地址） 两个计算机之间的通信过程（从MAC帧和IP数据包的层面来看） 交换机基于数据帧来转发地址，路由器基于数据包的IP地址来转发数据包 数据包在传输过程中不变，过网络设备的数据帧要用新的物理地址来重新封装 MAC地址决定了下一条哪个设备接收，而IP地址决定了数据包的起点和终点 4.2.4 地址解析协议 ARP 与逆地址解析协议RARPARP协议 不管网络层使用的是什么协议，在实际网络的链路上传送数据帧时，最终还是必须使用硬件地址。 每一个主机都设有一个 ARP 高速缓存(ARP cache)，里面有所在的局域网上的各主机和路由器的 IP 地址到硬件地址的映射表。 当主机 A 欲向本局域网上的某个主机 B 发送 IP 数据报时，就先在其 ARP 高速缓存中查看有无主机 B 的 IP 地址。如有，就可查出其对应的硬件地址，再将此硬件地址写入 MAC 帧，然后通过局域网将该 MAC 帧发往此硬件地址。 ARP协议通过广播解析本网段的计算机MAC地址 逆地址解析协议 RARP 逆地址解析协议 RARP 使只知道自己硬件地址的主机能够知道其 IP 地址。 这种主机往往是无盘工作站。 因此 RARP协议目前已很少使用。 4.2.5 IP 数据报的格式一个IP数据报由首部和数据两部分组成，首部是的前一部分是固定长度，共20字节，是所有的IP数据包所必须具有的；在首部的固定部分的后面是一些可选字节，其长度是可变的。 IP数据包各个字段 版本：占4位，即IP协议的版本，目前的版本号为4，IPv4协议 首部字长：占4位，可表示的最大数值是15个单位（一个单位为4个字节），因此IP首部长度最大值为60字节。 区分服务：8位，用来获得更好的服务，来设置数据包传送的优先级，表示这个数据包发送的紧急程度（实时性要求） 总长度：占16位，首部和数据之和的长度，单位为字节，因此数据报的最大长度为65535个字节（2的16次方），总长度必须不超过最大传送单元MTU 标识：占 16 位，它是一个计数器，用来产生数据报的标识。 标志：占3位，目前只有前两位有意义，用来告诉数据包是否分片，MF=1表示还有分片，MF=0表示最后一个分片，但是标志的中间的DF=0时才允许分片 片位移：占12位，较长的分组在分片后，片位移以8字节为偏移单位 生存时间：占8位，记为TTL（Time to live）数据报在网络中可通过路由器数的最大值。Windows默认为128 如图ping本机的TTL为128 当我ping一下p站，TTL就54，说明经过了74个路由器。 想上p站学习的同学可以看下这个注册一下，一直在用，很稳定 https://www.cuuc.club//auth/register?code=UZ97 ![pingP站的地址](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/4协议字段-1596974404574.png) 协议：占8位，字段指出此数据报携带的数据使用何种协议，以便目的主机的 IP 层将数据部分上交给哪个处理过程 首部检验和(16 位)字段只检验数据报的首部，不检验数据部分。这里不采用 CRC 检验码而采用简单的计算方法。如下图为首部校验和的运算方法 例子： IP头： 45 00 00 31 89 F5 00 00 6E 06 00 00（校验字段） DE B7 45 5D -&gt; 222.183.69.93 (源IP地址) C0 A8 00 DC -&gt; 192.168.0.220 (目的IP地址) 计算： 4500 + 0031 +89F5 + 0000 + 6e06+0000 + DEB7 + 455D + C0A8 + 00DC =3 22C4 （结果大于4bit,继续迭代计算) 0003 + 22C4 = 22C7 ~22C7 = DD38 -&gt;即为应填充的校验和 当接受到IP数据包时，要检查IP头是否正确，则对IP头进行检验，方法同上： 计算： 4500 + 0031 +89F5 + 0000 + 6E06+DD38 + DEB7 + 455D + C0A8 + 00DC =3 FFFC 0003 + FFFC = FFFF 得到的结果是全1（取反为0），正确。 可变部分：n选项字段的长度可变，从 1 个字节到 40 个字节不等，取决于所选择的项目。n增加首部的可变部分是为了增加 IP 数据报的功能，但这同时也使得 IP 数据报的首部长度成为可变的。这就增加了每一个路由器处理数据报的开销。 使用WireShark抓包分析 4.2.6 IP 层转发分组的流程根据目的网络地址就能确定下一跳路由器，这样做的结果是： IP 数据报最终一定可以找到目的主机所在目的网络上的路由器（可能要通过多次的间接交付）。 只有到达最后一个路由器时，才试图向目的主机进行直接交付。 ![IP 层转发分组的流程](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/IP 层转发分组的流程-1596974404575.png) 分组转发算法 (1) 从数据报的首部提取目的主机的 IP 地址 D, 得出目的网络地址为 N。 (2) 若网络 N 与此路由器直接相连，则把数据报直接交付目的主机 D；否则是间接交付，执行(3)。 (3) 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行(4)。 (4) 若路由表中有到达网络 N 的路由，则把数据报传送给路由表指明的下一跳路由器；否则，执行(5)。 (5) 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则，执行(6)。 (6) 报告转发分组出错。 默认路由 路由器还可采用默认路由以减少路由表所占用的空间和搜索路由表所用的时间。 这种转发方式在一个网络只有很少的对外连接时是很有用的。 默认路由在主机发送 IP 数据报时往往更能显示出它的好处。 如果一个主机连接在一个小网络上，而这个网络只用一个路由器和因特网连接，那么在这种情况下使用默认路由是非常合适的 4.3 划分子网和构造超网4.3.1 划分子网划分子网的基本思路 划分子网纯属一个单位内部的事情。单位对外仍然表现为没有划分子网的网络。 从主机号借用若干个位作为子网号 subnet-id，而主机号 host-id 也就相应减少了若干个位。 IP地址 ::= {&lt;网络号&gt;, &lt;子网号&gt;, &lt;主机号&gt;} B类地址，有两级结构，划分子网后变成了三级结构 划分子网只是把 IP 地址的主机号 host-id 这部分进行再划分，而不改变 IP 地址原来的网络号 net-id。 添加静态路由 Windows网关就是默认路由查看Windows本地路由表 子网掩码​ 从一个 IP 数据报的首部并无法判断源主机或目的主机所连接的网络是否进行了子网划分。使用子网掩码(subnet mask)可以找出 IP 地址中的子网部分。 (IP 地址) AND (子网掩码) =网络地址 默认子网掩码 ![默认子网掩码 ](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/默认子网掩码 -1596974404575.png) 对B类地址进行子网划分对 172.16.0.0 进行划分成两个子网 子网一 172.16.0.1 - 172.16.127.254 子网二 172.16.128.1 - 172.16.255.254 子网掩码 255.255.128.0 注意： 划分主机时，主机号不能全为0或者全为1 使用点到点网络，子网掩码最好是252 对C类地址进行等长子网划分对192.168.0.0 255.255.255.0 这个C类地址分别进行等分2、4、8个子网 等分成两个子网 192 168 0 0 000 0000 - 0111 1111 192 168 0 1 000 0000 - 1111 1111 可分配的主机号和划分的子网 192.168.0.1 - 192.168.0.126 192.168.0.128 - 192.168.0.254 子网掩码 1111 1111 1111 1111 1111 1111 1000 0000 255 255 255 128 等分成四个子网 拿出两位主机Id来进行划分 192 168 0 00 00 0000 - 0011 1111 192 168 0 01 00 0000 - 0111 1111 192 168 0 10 00 0000 - 1011 1111 192 168 0 11 00 0000 - 1111 1111 可分配的主机号和划分的子网 192.168.0.1 - 192.168.0.62 192.168.0.65 - 192.168.0.126 192.168.0.128 - 192.168.0.190 192.168.0.193 - 192.168.0.254 子网掩码 1111 1111 1111 1111 1111 1111 1100 0000 255 255 255 192 等分成八个子网 拿出三位主机Id来进行划分 192 168 0 000 0 0000 - 0001 1111 192 168 0 001 0 0000 - 0011 1111 192 168 0 010 0 0000 - 0101 1111 192 168 0 011 0 0000 - 0111 1111 192 168 0 100 0 0000 - 1001 1111 192 168 0 101 0 0000 - 1011 1111 192 168 0 110 0 0000 - 1101 1111 192 168 0 111 0 0000 - 1111 1111 可分配的主机号和划分的子网 192.168.0.1 - 192.168.0.30 192.168.0.33 - 192.168.0.62 192.168.0.65 - 192.168.0.94 192.168.0.97 - 192.168.0.126 192.168.0.129 - 192.168.0.158 192.168.0.161 - 192.168.0.190 192.168.0.193 - 192.168.0.222 192.168.0.225 - 192.168.0.254 子网掩码 1111 1111 1111 1111 1111 1111 1110 0000 255 255 255 224 对C类地址进行变长子网划分如将192.168.0.0这个C类子网划分为子网一有50个主机，子网二有100个主机 子网二有100台主机小于128-2 所以 分配192.168.0.0/25的第一个网段供其使用 192 168 0 0 000 0000 - 0111 1111 子网掩码 192. 168. 0. 128 子网一有50个主机小于64-2 将 192.168.0.128 - 192.168.0.192 这个网段提供给他使用 192 168 0 10 00 0000 - 1011 1111 子网掩码 192. 168. 0. 192 利用超网合并网段如图，将两个C类子网 192.168.0.0和 192.168.0.1两个C位地址合并成一个网段，两边的计算机就能通信，相当于在一个子网下， 我们可以看到将子网掩码往左移动一位，网络部分就一样了，这两个网段就在一个网段了。 192 168 0000 0000 0000 0000 192 168 0000 0001 0000 0000 1111 1111 1111 1111 1111 1110 0000 0000 255 255 254 0 合并规律总结 判断一个C类网络能不能合并为一个超网，可参照图中规则，若两个C类网络合并为一个网络，则可以将两个网络的第三部分对4区域，看是否在0、1或者23区域内，不在则说明不可合并。 ![合并规律总结](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/ICMP 报文的格式-1596974404575.png) 4.3.2 使用子网时分组转发使用子网划分后，路由器必须包括以下三项内容：目的网络地址、子网掩码和下一跳地址。路由器转发分组算法： 从收到的分组的首部提取目的 IP 地址 D。 先用各网络的子网掩码和 D 逐位相“与”，看是否和相应的网络地址匹配。若匹配，则将分组直接交付。否则就是间接交付，执行(3)。 若路由表中有目的地址为 D 的特定主机路由，则将分组传送给指明的下一跳路由器；否则，执行(4)。 对路由表中的每一行的子网掩码和 D 逐位相“与”，若其结果与该行的目的网络地址匹配，则将分组传送给该行指明的下一跳路由器；否则，执行(5)。 若路由表中有一个默认路由，则将分组传送给路由表中所指明的默认路由器；否则，执行(6)。 报告转发分组出错 4.3.3 无分类编址 CIDR（构造超网）网络前缀划分子网在一定程度上缓解了因特网在发展中遇到的困难。然而在 1992 年因特网仍然面临三个必须尽早解决的问题，这就是： B 类地址在 1992 年已分配了近一半，眼看就要在 1994 年 3 月全部分配完毕！ 因特网主干网上的路由表中的项目数急剧增长（从几千个增长到几万个）。 整个 IPv4 的地址空间最终将全部耗尽。 IP 编址问题的演进 1987 年，RFC 1009 就指明了在一个划分子网的网络中可同时使用几个不同的子网掩码。使用变长子网掩码 VLSM (Variable Length Subnet Mask)可进一步提高 IP 地址资源的利用率。 在 VLSM 的基础上又进一步研究出无分类编址方法，它的正式名字是无分类域间路由选择 CIDR (Classless Inter-Domain Routing)。 CIDR 最主要的特点 CIDR 消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，因而可以更加有效地分配 IPv4 的地址空间。 CIDR使用各种长度的“网络前缀”(network-prefix)来代替分类地址中的网络号和子网号。 IP 地址从三级编址（使用子网掩码）又回到了两级编址。 无分类的两级编址 无分类的两级编址的记法是： IP地址 ::= {&lt;网络前缀&gt;, &lt;主机号&gt;} (4-3) CIDR 还使用“斜线记法”(slash notation)，它又称为CIDR记法，即在 IP 地址面加上一个斜线“/”，然后写上网络前缀所占的位数（这个数值对应于三级编址中子网掩码中 1 的个数）。 CIDR 把网络前缀都相同的连续的 IP 地址组成“CIDR 地址块”。 CIDR 地址块 128.14.32.0/20 表示的地址块共有 212 个地址（因为斜线后面的 20 是网络前缀的位数，所以这个地址的主机号是 12 位）。 这个地址块的起始地址是 128.14.32.0。 在不需要指出地址块的起始地址时，也可将这样的地址块简称为“/20 地址块”。 128.14.32.0/20 地址块的最小地址：128.14.32.0 128.14.32.0/20 地址块的最大地址：128.14.47.255 全 0 和全 1 的主机号地址一般不使用。 构造超网 前缀长度不超过 23 位的 CIDR 地址块都包含了多个 C 类地址。 这些 C 类地址合起来就构成了超网。 CIDR 地址块中的地址数一定是 2 的整数次幂。 网络前缀越短，其地址块所包含的地址数就越多。而在三级结构的IP地址中，划分子网是使网络前缀变长 最长前缀匹配 使用 CIDR 时，路由表中的每个项目由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果。 应当从匹配结果中选择具有最长网络前缀的路由：最长前缀匹配(longest-prefix matching)。 网络前缀越长，其地址块就越小，因而路由就越具体(more specific) 。 最长前缀匹配又称为最长匹配或最佳匹配。 使用二叉线索查找路由表为了进行更加有效的查找，通常是将无分类编址的路由表存放在一种层次的数据结构中，然后自上而下地按层次进行查找。这里最常用的就是二叉线索(binary trie)。 4.4 网际控制报文协议 ICMP 为了提高 IP 数据报交付成功的机会，在网际层使用了网际控制报文协议 ICMP (Internet Control Message Protocol)。 ICMP 允许主机或路由器报告差错情况和提供有关异常情况的报告。 ICMP 不是高层协议，而是 IP 层的协议。 ICMP 报文作为 IP 层数据报的数据，加上数据报的首部，组成 IP 数据报发送出去。 ![image-20200806223915536](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/ICMP 差错报告报文的数据字段的内容-1596974404575.png) 4.4.1 ICMP 报文的种类差错报告报文ICMP 差错报告报文共有 5 种 终点不可达 源点抑制(Source quench) 时间超过 参数问题 改变路由（重定向）(Redirect) 不应发送 ICMP 差错报告报文的几种情况 对 ICMP 差错报告报文不再发送 ICMP 差错报告报文。 对第一个分片的数据报片的所有后续数据报片都不发送 ICMP 差错报告报文。 对具有多播地址的数据报都不发送 ICMP 差错报告报文。 对具有特殊地址（如127.0.0.0 或 0.0.0.0）的数据报不发送 ICMP 差错报告报文。 询问报文ICMP 询问报文有两种 回送请求和回答报文 时间戳请求和回答报文 下面的几种 ICMP 报文不再使用 信息请求与回答报文 掩码地址请求和回答报文 路由器询问和通告报文 4.4.2 ICMP 的应用举例 PING 用来测试两个主机之间的连通性。 PING 使用了 ICMP 回送请求与回送回答报文。 PING 是应用层直接使用网络层 ICMP 的例子，它没有通过运输层的 TCP 或UDP。 ping的应用举例 Traceroute 的应用举例 使用pathping跟踪数据包的路径。 使用pathping能够判断网络通还是不通，比如请求超时，你就不能判断在什么位置出现的网络故障造成的请求超时，使用pathping就可以跟踪数据包的路径，查出故障点，计算路由器的转发丢包率和链路丢包率和延迟，据此判断出网络拥塞的情况。如图所示 ![image-20200807001047280](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/Traceroute 的应用举例-1596974404575.png) 4.5 因特网的路由选择协议4.5.1 有关路由选择协议的几个基本概念1.理想的路由选择 完整与正确 计算简单 能适应通信量与网络拓扑的变化，有自适应性（稳健性） 具有稳定性 应是最佳的，相对于某种特定需求下较为合理的选择 从路由算法的自适应性考虑分两大类： 静态路由选择策略（非自适应路由选择）：简单，开销小，但不能适应网络状态的变化 动态路由选择策略（自适应路由选择）：能较好适应网络状态的变化，但实现较为复杂，开销大 2.分层次的路由选择协议将互联网划分为许多小的自治系统，记为AS，一个AS对其他AS表现出单一的和一致的路由选择策略。互联网把路由选择协议划分为两大类： 内部网关协议IGP：自治系统内部使用的路由选择协议，如RIP和OSPF 外部网关协议EGP：当源主机与目的主机处在不同的自治系统中所使用的路由选择协议，目前使用最多的是BGP-4 自治系统之间的路由选择也叫做域间路由选择(interdomain routing)，在自治系统内部的路由选择叫做域内路由选择(intradomain routing) 分析：本路由器与相邻路由器相距为1，通过相邻路由表可知，本路由器经过相邻路由器到达目的地址的距离会加1，所以d+1，下一跳设置为X。然后对路由表进行比较，目的地址未知则直接添加，目的地址已知，看本路由表下一跳是否为X，如果是，则更新，因为这是最新消息。如果不是，比较距离，距离比原来小可添加。如果长时间收不到更新路由表，则自动标记为不可达。 RIP2 协议的报文格式 RIP 协议的优缺点 RIP 存在的一个问题是当网络出现故障时，要经过比较长的时间才能将此信息传送到所有的路由器。 RIP 协议最大的优点就是实现简单，开销较小。 RIP 限制了网络的规模，它能使用的最大距离为 15（16 表示不可达） 4.5.2 内部网关协议 RIPRIP是一种分布式的基于距离向量的路由选择协议，网关就是默认路由“距离”的定义： 从一路由器到直接连接的网络的距离定义为 1。从一个路由器到非直接连接的网络的距离定义为所经过的路由器数加 1。 RIP 协 议 中 的 **“ 距 离 ” 也 称 为 “ 跳数”(hop count)**，因为每经过一个路由器，跳数就加 1。 RIP 允许一条路径最多只能包含 15 个路由器。“距离”的最大值为16 时即相当于不可达。可见 RIP 只适用于小型互联网。 12345678910111213路由选择算法已知地址为X的相邻路由器发来RIP报文，先将收到的报文下一跳该为X，所有距离加1，再对该表与自身路由表逐条进行比较。if（原路由表无目的网络N）&#123; 将该项目添加到路由表中&#125;if else（本机路由表下一跳为X）&#123; 将该条更新原本的项目&#125;if else（距离&lt;原来）&#123; 更新该条到路由表&#125;else&#123; 不做更新操作&#125;if（三分钟收不到更新路由表）&#123; 将此相邻路由表距离设置为16（不可达）&#125; 分析：本路由器与相邻路由器相距为1，通过相邻路由表可知，本路由器经过相邻路由器到达目的地址的距离会加1，所以d+1，下一跳设置为X。然后对路由表进行比较，目的地址未知则直接添加，目的地址已知，看本路由表下一跳是否为X，如果是，则更新，因为这是最新消息。如果不是，比较距离，距离比原来小可添加。如果长时间收不到更新路由表，则自动标记为不可达。 RIP协议缺点：RIP 不能在两个网络之间同时使用多条路由。RIP 选择一个具有最少路由器的路由（即最短路由），哪怕还存在另一条高速(低时延)但路由器较多的路由。RIP 协议的三个要点： 仅和相邻路由器交换信息。 交换的信息是当前本路由器所知道的全部信息，即自己的路由表。 按固定的时间间隔交换路由信息，例如，每隔 30 秒（广播）。 RIP2协议的报文格式 ![image-20200807124436611](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/RIP2 协议的报文格式-1596974404575.png) RIP2 报文中的路由部分由若干个路由信息组成。每个路由信息需要用 20 个字节。地址族标识符（又称为地址类别）字段用来标志所使用的地址协议。 路由标记填入自治系统的号码，这是考虑使RIP 有可能收到本自治系统以外的路由选择信息。再后面指出某个网络地址、该网络的子网掩码、下一跳路由器地址以及到此网络的距离。 nRIP2 报文中的路由部分由若干个路由信息组成。每个路由信息需要用 20 个字节。地址族标识符（又称为地址类别）字段用来标志所使用的地址协议。 4.5.3 内部网关协议 OSPF开放的最短路径优先OSPF，主要特征是使用分布式的链路状态协议。要点： 使用泛洪法，向本自治系统所有·路由器发送信息 发送的是有本路由器相邻的所有路由器的链路状态 只有链路状态改变时才使用泛洪发送信息 OSPF 将一个自治系统再划分为若干个更小的范围，叫作区域。区域也不能太大，在一个区域内的路由器最好不超过 200 个。 OSPF建立网络拓扑结构图的方式： 首先每个路由器会每10s对相邻的路由器发送问候（Hello）分组，来维持相邻路由器的可达性。 通过交换得到的链路状态信息，建立链路状态数据库，构造全网的拓扑结构图。 当链路状态发生改变时，每个路由器都能及时更新同步数据库。 OSPF 直接用 IP 数据报传送，OSPF 不用 UDP 而是直接用 IP 数据报传送。OSPF 构成的数据报很短。这样做可减少路由信息的通信量。数据报很短的另一好处是可以不必将长的数据报分片传送。分片传送的数据报只要丢失一个，就无法组装成原来的数据报，而整个数据报就必须重传。 OSPF 分组 OSPF 的五种分组类型 类型1，问候(Hello)分组。 类型2，数据库描述(Database Description)分组。 类型3，链路状态请求(Link State Request)分组。 类型4，链路状态更新(Link State Update)分组，用洪泛法对全网更新链路状态。 类型5，链路状态确认(Link State Acknowledgment)分组。 洪泛法 4.5.4 外部网关协议 BGP边界网关协议 BGP 只能是力求寻找一条能够到达目的网络且比较好的路由（不能兜圈子），而并非要寻找一条最佳路由。每一个自治系统的管理员要选择至少一个路由器作为该自治系统的“ BGP 发言人” ，一般为BGP边界路由器。 ![image-20200807133927638](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/BGP 发言人和自治系统 AS 的关系 -1596974404575.png) 通过BGP协议可将上图的网络看做是如下形式： 进而实现多级ISP的网络多级结构 4.5.6 路由器的构成 路由器是一种具有多个输入端口和多个输出端口的专用计算机，其任务是转发分组。也就是说，将路由器某个输入端口收到的分组，按照分组要去的目的地（即目的网络），把该分组从路由器的某个合适的输出端口转发给下一跳路由器。 下一跳路由器也按照这种方法处理分组，直到该分组到达终点为止。 4.6 IP 多播4.6.1 IP 多播的基本概念![image-20200807145417131](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/IP 多播的基本概念-1596974404576.png) 多播可明显地减少网络中资源的消耗 IP 多播的一些特点 (1) 多播使用组地址—— IP 使用 D 类地址支持多播。多播地址只能用于目的地址，而不能用于源地址。 (2) 永久组地址——由因特网号码指派管理局 IANA 负责指派。 (3) 动态的组成员 (4) 使用硬件进行多播 4.6.2 在局域网上进行硬件多播 因特网号码指派管理局 IANA 拥有的以太网地址块的高 24 位为 00-00-5E。 因此 TCP/IP 协议使用的以太网多播地址块的范围是：从 00-00-5E-00-00-00到 00-00-5E-FF-FF-FF D 类 IP 地址可供分配的有 28 位，在这 28 位中的前 5 位不能用来构成以太网硬件地址。 ![image-20200807145632540](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/D 类 IP 地址与以太网多播地址的映射关系 -1596974404576.png) 4.6.2 因特网组管理协议 IGMP 和多播路由选择协议IP多播需要两种协议 为了使路由器知道多播组成员的信息，需要利用网际组管理协议 IGMP (Internet Group Management Protocol)。 连接在局域网上的多播路由器还必须和因特网上的其他多播路由器协同工作，以便把多播数据报用最小代价传送给所有的组成员。这就需要使用多播路由选择协议。 ![image-20200807145731350](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/用隧道技术实现虚拟专用网 -1596974404576.png) IGMP IGMP是一个单独的协议，属于整个网际协议 IP 的一个组成部分。 IGMP 可分为两个阶段 第一阶段：当某个主机加入新的多播组时，该主机应向多播组的多播地址发送IGMP 报文，声明自己要成为该组的成员。本地的多播路由器收到 IGMP 报文后，将组成员关系转发给因特网上的其他多播路由器。 第二阶段：因为组成员关系是动态的，因此本地多播路由器要周期性地探询本地局域网上的主机，以便知道这些主机是否还继续是组的成员。只要对某个组有一个主机响应，那么多播路由器就认为这个组是活跃的。但一个组在经过几次的探询后仍然没有一个主机响应，则不再将该组的成员关系转发给其他的多播路由器。 4.7 虚拟专用网 VPN 和网络地址转换 NAT4.7.1 虚拟专用网 VPN 本地地址——仅在机构内部使用的 IP 地址，可以由本机构自行分配，而不需要向因特网的管理机构申请。 全球地址——全球唯一的IP地址，必须向因特网的管理机构申请 ![image-20200807150147018](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.网络层/IGMP 使多播路由器知道多播组成员信息 -1596974404576.png) A与B内部的通信本来不经过互联网，如果两者之间想要通信，可使用VPN技术，A将数据报作为内部数据发给路由器R1，路由器R1收到数据报后，对内部数据报加密（保证数据安全），然后重新加上数据报的首部，封装成互联网的外部数据报，到达R2，然后在进行解密，从而实现两者间的通信 4.7.2 网络地址转换 NATNAT原理：内部主机 X 用本地地址 IPX 和因特网上主机 Y 通信所发送的数据报必须经过 NAT 路由器。NAT 路由器将数据报的源地址 IPX 转换成全球地址 IPG，但目的地址 IPY 保持不变，然后发送到因特网。NAT 路由器收到主机 Y 发回的数据报时，知道数据报中的源地址是 IPY 而目的地址是 IPG。根据 NAT 转换表，NAT 路由器将目的地址 IPG转换为 IPX，转发给最终的内部主机 X。 现常用的NAT转换表利用运输层的端口号，使得多个拥有本地地址的主机共用一个路由器上的全球IP地址，使用端口号的NAT也叫网络地址与端口号转换NAPT。 使用netstat -n 可查看建立会话的目标端口和源端口","raw":null,"content":null,"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"计算机基础知识","slug":"计算机网络/计算机基础知识","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"408","slug":"408","permalink":"https://fan-yu-feng.github.io/tags/408/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络-2-链路层","slug":"计算机网络/计算机网络-2-链路层","date":"2020-08-09T11:48:18.000Z","updated":"2021-12-24T03:26:59.122Z","comments":true,"path":"2020/08/09/计算机网络/计算机网络-2-链路层/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-2-%E9%93%BE%E8%B7%AF%E5%B1%82/","excerpt":"3.数据链路层一些基本概念\n数据链路层的信道主要有以下两种类型：\n\n点对点信道：这种信道使用一对一的点对点通信方式。\n\n广播信道：这种信道使用一对多的广播通信方式，因此过程比较复杂。广播信道上连接的主机很多，因此必须使用专业的共享信道协议来协调这些主机的数据发送\n\n\n主机1向主机二发送数据，数据从应用层向下流动，到达物理层变成比特流，经过路由器转发，通过检查MAC地址，查看IP地址，然后选择路由，找到下一个地址，再向下到物理层，这样经过路由器转发，到达H2。","text":"3.数据链路层一些基本概念 数据链路层的信道主要有以下两种类型： 点对点信道：这种信道使用一对一的点对点通信方式。 广播信道：这种信道使用一对多的广播通信方式，因此过程比较复杂。广播信道上连接的主机很多，因此必须使用专业的共享信道协议来协调这些主机的数据发送 主机1向主机二发送数据，数据从应用层向下流动，到达物理层变成比特流，经过路由器转发，通过检查MAC地址，查看IP地址，然后选择路由，找到下一个地址，再向下到物理层，这样经过路由器转发，到达H2。 而从数据链路层的角度来看，我们只需要关心协议栈中水平方向中的各个数据链路层，我们想象数据链路层是从左到右沿水平方向传输的。 3.1 使用点对点信道的数据链路层3.1.1 数据链路和帧数据链路层的模型和帧 链路是一条无源的点到点的物理线路段，中间没有任何其他的交换节点 一条链路只是一条通路的一个组成部分 数据链路：除了物理线路外，还必须有通信协议来控制这些数据的传输。若把实现这些协议的硬件和软件加到链路上，就构成了数据链路。 现在最常用的方法是使用适配器（网卡）来实现这些协议的硬件和软件。 一般的适配器都包括了数据链路层和物理层这两层的功能。 帧：在数据链路层上传送的就是帧 3.1.2 三个基本问题封装成帧 封装成帧就是在一段数据的前后分别添加首部和尾部，然后构成一个帧，确定帧的界限 首部和尾部的一个重要作用就是进行帧定界 MTU 最大传送单元&lt;=1500个字节 计算机在接受一个帧时，收到了帧的首部和尾部才能认为这个帧是一个完整的数据帧，若没有收到一个完整的数据帧，则认为他是不完整的，则会将其丢弃。 帧定界符 控制字符SOH（Start Of Header）：放在帧的最前面，表示帧的首部 控制字符EOT（End Of Transmission）：表示帧的结束 透明传输问题 在封装成帧后，我们传输的数据中如果在数据中间出现部分EOT或者SOH这样的帧定界控制字符时，可能会导致数据意外的被丢弃，这时我们需要透明传输。如图所示 解决问题：实现透明传输 透明传输指数据中可能实际存在帧定界符，但是不被我们处理，就好像透明一样，我们采用的方法是在发送端的数据链路层在数据中长线控制字符时在前面插入转义字符”ESC“， 而在接收端的数据链路层在把数据传往网络层之前删除插入的转义字符 如果转义字符也出现数据当中，那么应在转义字符前面插入一个转义字符。当接收端收到连续的两个转义字符时，就删除其中前面的一个。 差错控制在传输过程中，可能会产生比特差错，1可能变成0，0可能变成1，在一段时间内传输错误他比特占所传输毕业总数的比率称为误码率BER。 数据链路层广泛使用循环冗余检验CRC： 在发送端，先把数据划分为组。假定每组 k 个比特。 假设待传送的一组数据 M = 101001（现在 k = 6）。我们在 M 的后面再添加供差错检测用的 n 位冗余码一起发送。 用二进制的模 2 运算进行 2的n次方 乘 M 的运算，这相当于在 M 后面添加 n 个 0（如n=3，M=101001000）。 得到的 (k + n) 位的数除以事先选定好的长度为 (n + 1) 位的除数 P，得出商是 Q 而余数是 R，余数 R 比除数 P 少1 位，即 R 是 n 位。 在接收端接受到数据后，进行CRC校验，将发送端发送的数据除于余数R（异或运算），运算的余数为0则说明没有差错，就接受；如果余数R不等于0，就说明这个帧有差错就丢弃。 但这种检测方法并不能确定究竟是哪一个或哪几个比特出现了差错。只要经过严格的挑选，并使用位数足够多的除数 P，那么出现检测不到的差错的概率就很小很小。 注意 仅用循环冗余检验 CRC 差错检测技术只能做到无差错接受(accept)。“无差错接受”是指：“凡是接受的帧（即不包括丢弃的帧），我们都能以非常接近于 1 的概率认为这些帧在传输过程中没有产生差错”。也就是说：“凡是接收端数据链路层接受的帧都没有传输差错”（有差错的帧就丢弃而不接受）。要做到“可靠传输”（即发送什么就收到什么）就必须再加上确认和重传机制。 例题： 现在 k = 6, M = 101001。 设 n = 3, 除数 P = 1101（除数n+1位） 被除数是 2nM = 101001000。 模 2 运算的结果是：商 Q = 110101，余数 R = 001。 把余数 R 作为冗余码添加在数据 M 的后面发送出去。发送的数据是：2nM + R ， 即：101001001，共 (k + n) 位。 传送的数据为101001+余数R=101001001 接收端收到数据则使用该数据除于1101（P），余数为0，则无误，余数不为0，则说明传送过程中出错。 除数是由数据链路层的协议实现的，我们不用关心这个除数是多少和余数是 3.2 点对点协议 PPP (Point-to-Point Protocol)。点对点协议PPP（Point-to-Point Protocol）是目前使用最广泛的数据链路层协议 3.2.1 PPP 协议的特点1. PPP 协议应满足的需求 简单——这是首要的要求 封装成帧 透明性 多种网络层协议 多种类型链路 差错检测 检测连接状态 最大传送单元 网络层地址协商 数据压缩协商 2. PPP 协议不需要的功能 纠错 流量控制 序号 多点线路 半双工或单工链路 3. PPP 协议的组成ppp协议由三个部分组成 一个将 IP 数据报封装到串行链路的方法。 链路控制协议 LCP (Link Control Protocol)。 网络控制协议 NCP (Network Control Protocol)。 3.2.2 PPP 协议的帧格式PPP帧的首部和尾部分别有四个字段和两个字段 首部的第一个字段和尾部第二个字段是标志字段F=0x7E(0111 1110) 地址字段地址字段 A 只置为 0xFF。地址字段实际上并不起作用。控制字段 C 通常置为 0x03。 协议字段： 当协议字段为 0x0021 时，PPP 帧的信息字段就是IP 数据报。 若为 0xC021, 则信息字段是 PPP 链路控制数据。 若为 0x8021，则表示这是网络控制数据。 PPP帧实现透明传输问题： 字节填充 当信息部分出现了0x7E时，将0x7E变成2字节的序列（0x7D,0x5E) 若信息部分出现了0x7D字节时，将其变为2字节的序列（0x7D,0x5D） 若信息部分出现了ASCII码的控制字符（即数值小于0x20的字符），则在字符前面要加入一个0x7D字节，同时将该字符的编码加以改变。 零比特填充 PPP 协议用在 SONET/SDH 链路时，是使用同步传输（一连串的比特连续传送，不是字节）。这时 PPP 协议采用零比特填充方法来实现透明传输。 在发送端，只要发现有 5 个连续 1，则立即填入一个 0。接收端对帧中的比特流进行扫描。每当发现 5 个连续1时，就把这 5 个连续 1 后的一个 0 删除， PPP 协议之所以不使用序号和确认机制是出于以下的考虑： 在数据链路层出现差错的概率不大时，使用比较简单的 PPP 协议较为合理。 在因特网环境下，PPP 的信息字段放入的数据是 IP 数据报。数据链路层的可靠传输并不能够保证网络层的传输也是可靠的。 帧检验序列 FCS 字段可保证无差错接受 3.2.3 PPP 协议的工作状态 当用户拨号接入 ISP 时，路由器的调制解调器对拨号做出确认，并建立一条物理连接。 PC 机向路由器发送一系列的 LCP 分组（封装成多个 PPP 帧）。 这些分组及其响应选择一些 PPP 参数，和进行网络层配置，NCP 给新接入的 PC机分配一个临时的 IP 地址，使 PC 机成为因特网上的一个主机。 通信完毕时，NCP 释放网络层连接，收回原来分配出去的 IP 地址。接着，LCP 释放数据链路层连接。最后释放的是物理层的连接。 3.3 使用广播信道的数据链路层3.3.1 局域网的数据链路层局域网局域网最主要的特点是：网络为一个单位所拥有，且地理范围和站点数目均有限。 局域网具有如下的一些主要优点： 具有广播功能，从一个站点可很方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源。 便于系统的扩展和逐渐地演变，各设备的位置可灵活调整和改变。 提高了系统的可靠性、可用性和残存性。 局域网的网络拓扑 适配器网络接口板又称为通信适配器（adapter）或网络接口卡NIC（Network Interface Card）或网卡。功能： 进行数据串行传输和并行传输的转换 对数据进行缓存 在计算机的操作系统中安装设备驱动程序 实现以太网协议 数据链路层的两个子层 为了使数据链路层能更好地适应多种局域网标准，802 委员会就将局域网的数据链路层拆成两个子层： 逻辑链路控制 LLC (Logical Link Control) 子层媒体接入控制 MAC (Medium Access Control)子层。 与接入到传输媒体有关的内容都放在 MAC子层，而 LLC 子层则与传输媒体无关，不管采用何种协议的局域网对 LLC 子层来说都是透明的 ![image-20200802213914491](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.链路层/局域网对 LLC 子层来说都是透明.png) 由于 TCP/IP 体系经常使用的局域网是 DIX Ethernet V2 而不是 802.3 标准中的几种局域网，因此现在 802 委员会制定的逻辑链路控制子层 LLC（即 802.2 标准）的作用已经不大了。很多厂商生产的适配器上就仅装有 MAC 协议而没有 LLC 协议。 3.3.2 CSMA/CD 协议载波监听多点接入/碰撞检测 CSMA/CD CSMA/CD 表示 Carrier Sense Multiple Access with Collision Detection。 “多点接入”表示许多计算机以多点接入的方式连接在一根总线上。 “载波监听”是指每一个站在发送数据之前先要检测一下总线上是否有其他计算机在发送数据，如果有，则暂时不要发送数据，以免发生碰撞。 总线上并没有什么“载波”。因此， “载波监听”就是用电子技术检测总线上有没有其他计算机发送的数据信号。 碰撞检测 “碰撞检测”就是计算机边发送数据边检测信道上的信号电压大小。 当几个站同时在总线上发送数据时，总线上的信号电压摆动值将会增大（互相叠加）。 当一个站检测到的信号电压摆动值超过一定的门限值时，就认为总线上至少有两个站同时在发送数据，表明产生了碰撞。 所谓“碰撞”就是发生了冲突。因此“碰撞检测”也称为“冲突检测”。 检测到碰撞后 在发生碰撞时，总线上传输的信号产生了严重的失真，无法从中恢复出有用的信息来。每一个正在发送数据的站，一旦发现总线上出现了碰撞，就要立即停止发送，免得继续浪费网络资源，然后等待一段随机时间后再次发送。 电磁波在总线上的有限传播速率的影响 当某个站监听到总线是空闲时，也可能总线并非真正是空闲的。A 向 B 发出的信息，要经过一定的时间后才能传送到 B。B 若在 A 发送的信息到达 B 之前发送自己的帧(因为这时 B 的载波监听检测不到 A 所发送的信息)，则必然要在某个时间和 A 发送的帧发生碰撞。碰撞的结果是两个帧都变得无用。 如图所示，电磁波在1KM电缆的传播时延为5us，单程端到端的传播时延为τ，从图中可知，判断是否发送碰撞的时间最多为2τ 在使用CSMA/CD协议时，一个站不能同时发送与接收信息（必须边发送边监听信道），因此以太网使用的是半双工通信。 争用期与退避算法最先发送数据帧的站，在发送数据帧后至多经过时间 2τ（两倍的端到端往返时延）就可知道发送的数据帧是否遭受了碰撞。以太网的端到端往返时延 2τ 称为争用期，或碰撞窗口。经过争用期这段时间还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 对于10Mb/s的以太网，通常取 2τ也就是51.2微秒作为争用期的长度，在争用期内可以发送512bit，也就是64字节，以太网发送数据时如果64字节未发生冲突，则后续的数据也不会发生冲突，因此以太网有规定最短的有效帧的长度 最短有效帧长 如果发生冲突，就一定时在发送前64字节之内 由于一检测到冲突就立即停止发送，这时已经发出去的数据一定时64字节 以太网规定了最短有效帧长度为64字节，但凡小于64字节的帧长度是由于冲突异常而中止的无效帧。 截止二进制指数退避算法 发生碰撞的站在停止发送数据后，要推迟退避一个随机时间才能再发送数据。 确定基本退避时间，一般是取为争用期 2τ。 定义重传次数 k ，k &lt;= 10，即k = Min[重传次数, 10] 从整数集合[0,1,…, (2k −1)]中随机地取出一个数，记为 r。重传所需的时延就是 r 倍的基本退避时间。 当重传达 16 次仍不能成功时即丢弃该帧，并向高层报告 强化碰撞 当发送数据的站一旦发现发生了碰撞时： 立即停止发送数据； 再继续发送若干比特（32或48比特）的人为干扰信号(jamming signal)，以便让所有用户都知道现在已经发生了碰撞。 3.4 使用广播信道的以太网以太网的两个标准： DIX Ethernet V2：世界上第一个局域网产品的规约 IEEE 802.3：第一个IEEE的以太网标准 以太网严格来说，是指符合DIX Ethernet V2标准打的局域网IEEE802委员会把局域网数据链路层拆成两个子层，即逻辑链路控制LLC子层和媒体接入控制MAC子层。与接入到传输媒体相关的内容都放在MAC子层上，而LLC子层与传输媒体无关，不管采用何种协议的局域网对LLC子层来说都是透明的。 以太网提供的服务是不可靠的交付，即尽最大努力的交付。 当目的站收到有差错的数据帧时就丢弃此帧，其他什么也不做。差错的纠正由高层来决定。 如果高层发现丢失了一些数据而进行重传，但以太网并不知道这是一个重传的帧，而是当作一个新的数据帧来发送。 以太网发送的数据都使用曼彻斯特编码 以太网的共享信道划分静态划分信道：频分复用、时分复用波分复用和玛分复用等，这种方式不适合局域网。动态媒体接入控制（多点接入）： 随机接入 受控接入 如多点线路探询或轮询 3.4.1 使用集线器的星形拓扑物理上是星型，逻辑上是总线型。为了降低成本，最初由粗的同轴电缆变成细的同轴电缆最后变成无屏蔽双绞线。每个站需要用两对双绞线，分别用于发送和接收；在星形的中心增加了一种可靠性高的设备，为集线器(hub)。 集线器的特点 集线器是使用电子器件来模拟实际电缆线的工作，因此整个系统仍然像一个传统的以太网那样运行。 使用集线器的以太网在逻辑上仍是一个总线网，各工作站使用的还是 CSMA/CD 协议，并共享逻辑上的总线。 集线器很像一个多接口的转发器，工作在物理层。 10Base-T 基于集线器的以太网标准 它的通信距离稍短，每个站到集线器的距离不超过100m。 这种10MB/s的无屏蔽双绞线星形网的出现，能降低成本和提高可靠性。 10Base-T的出现有很大的意义，类似标准有100Base-FX，10Base-T，100Base-T4. 以太网在局域网中的统治地位 10BASE-T 的通信距离稍短，每个站到集线器的距离不超过 100 m。 这种 10 Mb/s 速率的无屏蔽双绞线星形网的出现，既降低了成本，又提高了可靠性。 10BASE-T 双绞线以太网的出现，是局域网发展史上的一个非常重要的里程碑，它为以太网在局域网中的统治地位奠定了牢固的基础。 3.4.2 以太网的信道利用率 以太网的信道被占用的情况：争用期长度为 2t，即端到端传播时延的两倍。检测到碰撞后不发送干扰信号。帧长为 L (bit)，数据发送速率为 C (b/s)，因而帧的发送时间为 L/C = T0 (s)。 一个帧从开始发送，经可能发生的碰撞后，将再重传数次，到发送成功且信道转为空闲(即再经过时间 t 使得信道上无信号在传播)时为止，是发送一帧所需的平均时间。 定义信道利用率a=t/T0,是单纯端到端时延t和帧发送时间T0的比值 a→0 表示一发生碰撞就立即可以检测出来，并立即停止发送，因而信道利用率很高。 a 越大，表明争用期所占的比例增大，每发生一次碰撞就浪费许多信道资源，使得信道利用率明显降低。 在理想状态下，发送一针需要T0+t的时间，所以理想状态下，极限信道的利用率Amax=T0/（T0+t）=1/（1+a），也就是帧发送时间和检测碰撞的时间 3.4.3 以太网的 MAC 层 ​ 在局域网中，硬件地址又称为物理地址，或者MAC地址 IEEE 的注册管理机构 RA 负责向厂家分配地址字段的前三个字节(即高位 24 位)。 地址字段中的后三个字节(即低位 24 位)由厂家自行指派，称为扩展标识符，必须保证生产出的适配器没有重复地址。一个地址块可以生成224个不同的地址。这种 48 位地址称为 MAC-48，它的通用名称是EUI-48。“MAC地址”实际上就是适配器地址或适配器标识符EUI-48。 查看本机的MAC地址 1ipconfig &#x2F;all 如下图的物理地址 **适配器检查 MAC 地址 ** 适配器从网络上每收到一个 MAC 帧就首先用硬件检查 MAC 帧中的 MAC 地址. 如果是发往本站的帧则收下，然后再进行其他的处理。 否则就将此帧丢弃，不再进行其他的处理。 “发往本站的帧”包括以下三种帧： 单播(unicast)帧（一对一） 广播(broadcast)帧（一对全体） 多播(multicast)帧（一对多） MAC帧格式 常用的以太网MAC帧格式有两种标准 ： DIX Ethernet V2 标准 IEEE 的 802.3 标准 最常用的 MAC 帧是以太网 V2 的格式。 由于以太网要求帧长度最小为64字节，所以数据部分最小长度为46字节（64-6-6-4-2） 类型两个字节，指明数据部分是什么协议。 由于以太网使用的是曼彻斯特编码，在帧开始部分插入帧开始的标志符，结尾无信号则表示传输结束。在帧的前面插入的 8 字节中的第一个字段共 7 个字节，是前同步码，用来迅速实现 MAC 帧的比特同步。第二个字段是帧开始定界符，表示后面的信息就是MAC 帧 使用WireShark抓包查看MAC地址 笔主下载百度云的一个20Kb的小文件来进行抓包 如图为目的地址和本机的物理地址（可以参考上面查看本机的MAC地址），以及使用的类型：IPv4协议。 无效的MAC帧 数据字段的长度与长度字段的值不一致； 帧的长度不是整数个字节； 用收到的帧检验序列 FCS 查出有差错； 数据字段的长度不在 46 ~ 1500 字节之间。 有效的 MAC 帧长度为 64 ~ 1518 字节之间。 对于检查出的无效 MAC 帧就简单地丢弃。以太网不负责重传丢弃的帧。 帧间最小间隔 帧间最小间隔为 9.6 us，相当于 96 bit 的发送时间。 一个站在检测到总线开始空闲后，还要等待 9.6 s 才能再次发送数据。 这样做是为了使刚刚收到数据帧的站的接收缓存来得及清理，做好接收下一帧的准备。 3.5 扩展的以太网3.5.1 在物理层扩展以太网 主机使用光纤和一对光纤调制解调器连接到集线器 用多个集线器可连成更大的局域网 用集线器扩展局域网 优点 使原来属于不同碰撞域的局域网上的计算机能够进行跨碰撞域的通信。 扩大了局域网覆盖的地理范围。 缺点 碰撞域增大了，但总的吞吐量并未提高。 如果不同的碰撞域使用不同的数据率，那么就不能用集线器将它们互连起来。 3.5.2 在数据链路层扩展以太网网桥在数据链路层扩展局域网是使用网桥。 网桥工作在数据链路层，它根据 MAC 帧的目的地址对收到的帧进行转发。 网桥具有过滤帧的功能。当网桥收到一个帧时，并不是向所有的接口转发此帧，而是先检查此帧的目的 MAC 地址，然后再确定将该帧转发到哪一个接口 网桥使各网段成为隔离开的碰撞域 网桥的优点与缺点使用网桥带来的好处 过滤通信量。 扩大了物理范围。 提高了可靠性。 可互连不同物理层、不同 MAC 子层和不同速率（如10 Mb/s 和 100 Mb/s 以太网）的局域网。 使用网桥带来的缺点 存储转发增加了时延。 (存储转发) 在MAC 子层并没有流量控制功能。 具有不同 MAC 子层的网段桥接在一起时时延更大。 网桥只适合于用户数不太多(不超过几百个)和通信量不太大的局域网，否则有时还会因传播过的广播信息而产生网络拥塞。这就是所谓的广播风暴。 网桥与集线器（转发器）的区别 集线器在转发帧时，不对传输媒体进行检测。 网桥在转发帧之前必须执行 CSMA/CD 算法。 若在发送过程中出现碰撞，就必须停止发送和进行退避。 透明网桥 目前使用得最多的网桥是透明网桥(transparent bridge)。 “透明”是指局域网上的站点并不知道所发送的帧将经过哪几个网桥，因为网桥对各站来说是看不见的。 透明网桥是一种即插即用设备，其标准是 IEEE 802.1D。 网桥的自学习算法 若从 A 发出的帧从接口 x 进入了某网桥，那么从这个接口出发沿相反方向一定可把一个帧传送到 A。 网桥每收到一个帧，就记下其源地址和进入网桥的接口，作为转发表中的一个项目。 在建立转发表时是把帧首部中的源地址写在“地址”这一栏的下面。 在转发帧时，则是根据收到的帧首部中的目的地址来转发的。这时就把在“地址”栏下面已经记下的源地址当作目的地址，而把记下的进入接口当作转发接口。 网桥的自学习和转发帧的步骤归纳 在网桥的转发表中写入的信息除了地址和接口外，还有帧进入该网桥的时间。 这是因为以太网的拓扑可能经常会发生变化，站点也可能会更换适配器（这就改变了站点的地址）。另外，以太网上的工作站并非总是接通电源的。 把每个帧到达网桥的时间登记下来，就可以在转发表中只保留网络拓扑的最新状态信息。这样就使得网桥中的转发表能反映当前网络的最新拓扑状态。 网桥收到一帧后先进行自学习。查找转发表中与收到帧的源地址有无相匹配的项目。如没有，就在转发表中增加一个项目（源地址、进入的接口和时间）。如有，则把原有的项目进行更新。 转发帧。查找转发表中与收到帧的目的地址有无相匹配的项目。 如没有，则通过所有其他接口（但进入网桥的接口除外）按进行转发。 如有，则按转发表中给出的接口进行转发。 若转发表中给出的接口就是该帧进入网桥的接口，则应丢弃这个帧（因为这时不需要经过网桥进行转发）。 转发表的建立过程举例： 生成树算法透明网桥使用了生成树算法，这是为了避免产生转发的帧在网络中不断地兜圈子。 生成树的得出 互连在一起的网桥在进行彼此通信后，就能找出原来的网络拓扑的一个子集。在这个子集里，整个连通的网络中不存在回路，即在任何两个站之间只有一条路径。 为了避免产生转发的帧在网络中不断地兜圈子。 为了得出能够反映网络拓扑发生变化时的生成树，在生成树上的根网桥每隔一段时间还要对生成树的拓扑进行更新。 交换机随着网桥的接口的增加， 后来网桥和集线器合并了，计算机可以直接和交换机连接，这就是交换机。交换机就是网桥和集线器的合并升级版，能全双工，安全通信。端口带宽独享； 交换节的特点 以太网交换机的每个接口都直接与主机相连，并且一般都工作在全双工方式。 交换机能同时连通许多对的接口，使每一对相互通信的主机都能像独占通信媒体那样，进行无碰撞地传输数据。 以太网交换机由于使用了专用的交换结构芯片，其交换速率就较高。 独占传输媒体的带宽 对于普通 10 Mb/s 的共享式以太网，若共有 N 个用户，则每个用户占有的平均带宽只有总带宽(10 Mb/s)的 N 分之一。 使用以太网交换机时，虽然在每个接口到主机的带宽还是 10 Mb/s，但由于一个用户在通信时是独占而不是和其他网络用户共享传输媒体的带宽，因此对于拥有 N 对接口的交换机的总容量为 N=10 Mb/s。这正是交换机的最大优点。 3.5.3 虚拟局域网（VLAN）虚拟局域网VLAN是由一些局域网网段构成的与物理位置无关的逻辑组，虚拟局域网其实知识局域网给用户提供的一种服务，并不是一种新型的局域网。利用以太网交换机可以很方便地实现虚拟局域网 如图 当 B1 向 VLAN2 工作组内成员发送数据时，工作站 B2 和 B3 将会收到广播的信息。 B1 发送数据时，工作站 A1, A2 和 C1都不会收到 B1 发出的广播信息。 虚拟局域网限制了接收广播信息的工作站数，使得网络不会因传播过多的广播信息(即“广播风暴”)而引起性能恶化。 虚拟局域网使用的以太网帧格式 虚拟局域网协议允许在以太网的帧格式中插入一个 4 字节的标识符，称为 VLAN 标记(tag)，用来指明发送该帧的工作站属于哪一个虚拟局域网。 3.6 高速以太网3.6.1 100BASE-T 以太网 速率达到或超过 100 Mb/s 的以太网称为高速以太网。 在双绞线上传送 100 Mb/s 基带信号的星型拓扑以太网，仍使用 IEEE 802.3 的CSMA/CD 协议。100BASE-T 以太网又称为快速以太网(Fast Ethernet)。 100BASE-T 以太网的特点 可在全双工方式下工作而无冲突发生。因此，不使用 CSMA/CD 协议。 MAC 帧格式仍然是 802.3 标准规定的。 保持最短帧长不变，但将一个网段的最大电缆长度减小到 100 m。 帧间时间间隔从原来的 9.6 us 改为现在的 0.96 us。 三种不同的物理层标准 100BASE-TX 使用 2 对 UTP 5 类线或屏蔽双绞线 STP。 100BASE-FX 使用 2 对光纤。 100BASE-T4 使用 4 对 UTP 3 类线或 5 类线。 3.6.2 吉比特以太网 允许在 1 Gb/s 下全双工和半双工两种方式工作。 使用 802.3 协议规定的帧格式。 在半双工方式下使用 CSMA/CD 协议（全双工方式不需要使用 CSMA/CD 协议）。 与 10BASE-T 和 100BASE-T 技术向后兼容。 吉比特以太网的物理层3.6.3 10 吉比特以太网 1000BASE-X 基于光纤通道的物理层： 1000BASE-SX SX表示短波长 1000BASE-LX LX表示长波长 1000BASE-CX CX表示铜线 1000BASE-T 使用 4对 5 类线 UTP 吉比特以太网的配置举例 3.6.4 使用高速以太网进行宽带接入 以太网已成功地把速率提高到 1 ~ 10 Gb/s ，所覆盖的地理范围也扩展到了城域网和广域网，因此现在人们正在尝试使用以太网进行宽带接入。 以太网接入的重要特点是它可提供双向的宽带通信，并且可根据用户对带宽的需求灵活地进行带宽升级。 采用以太网接入可实现端到端的以太网传输，中间不需要再进行帧格式的转换。这就提高了数据的传输效率和降低了传输的成本。 3.7 其他类型的高速局域网接口3.7.1 10 吉比特以太网 10 吉比特以太网与 10 Mb/s，100 Mb/s 和 1 Gb/s 以太网的帧格式完全相同。 10 吉比特以太网还保留了 802.3 标准规定的以太网最小和最大帧长，便于升级。 10 吉比特以太网不再使用铜线而只使用光纤作为传输媒体。 10 吉比特以太网只工作在全双工方式，因此没有争用问题，也不使用 CSMA/CD 协议。 3.7.2 吉比特以太网的物理层 局域网物理层 LAN PHY。局域网物理层的数据率是 10.000 Gb/s。 可选的广域网物理层 WAN PHY。广域网物理层具有另一种数据率，这是为了和所谓的“Gb/s”的 SONET/SDH（即OC-192/STM-64）相连接。 为了使 10 吉比特以太网的帧能够插入到 OC-192/STM-64 帧的有效载荷中，就要使用可选的广域网物理层，其数据率为 9.95328 Gb/s。 3.7.3 端到端的以太网传输 10 吉比特以太网的出现，以太网的工作范围已经从局域网（校园网、企业网）扩大到城域网和广域网，从而实现了端到端的以太网传输。 这种工作方式的好处是： 成熟的技术 互操作性很好 在广域网中使用以太网时价格便宜。 统一的帧格式简化了操作和管理。 3.7.4 以太网从 10 Mb/s 到10 Gb/s 的演进以太网从 10 Mb/s 到 10 Gb/s 的演进证明了以太网是： 可扩展的（从 10 Mb/s 到 10 Gb/s）。 灵活的（多种传输媒体、全/半双工、共享/交换）。 易于安装。 稳健性好。 以太网接入举例 ![image-20200803215940931](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/3.链路层/吉比特以太网的配置举例 .png)","raw":null,"content":null,"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"计算机基础知识","slug":"计算机网络/计算机基础知识","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"408","slug":"408","permalink":"https://fan-yu-feng.github.io/tags/408/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络概述","slug":"计算机网络/计算机网络概述","date":"2020-08-08T09:15:37.000Z","updated":"2021-12-24T03:26:59.331Z","comments":true,"path":"2020/08/08/计算机网络/计算机网络概述/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0/","excerpt":"计算机网络这学期上了计算机网络的课程，觉得这门课十分有用，使我对于网络各个方面的内容有了大致的了解，现在暑假来了，准备复习总结，准备开学的考试，还有面试准备。\n计算机网络的定义和分类计算机网络的定义 首先，什么是计算机网络呢？一般认为，计算机网络是一个将分散的/具有独立功能的计算机系统，通过通信设备和线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。简而言之，计算机网络就是一些互联的、自治的计算机系统的集合。是网络的网络，互联网把许多网络连接在一起。","text":"计算机网络这学期上了计算机网络的课程，觉得这门课十分有用，使我对于网络各个方面的内容有了大致的了解，现在暑假来了，准备复习总结，准备开学的考试，还有面试准备。 计算机网络的定义和分类计算机网络的定义 首先，什么是计算机网络呢？一般认为，计算机网络是一个将分散的/具有独立功能的计算机系统，通过通信设备和线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。简而言之，计算机网络就是一些互联的、自治的计算机系统的集合。是网络的网络，互联网把许多网络连接在一起。 计算机网络的分类 1、按分布范围 广域网（WAN），广域网的任务是提供长距离通信，运送主机所发送的数据，覆盖范围通常为几万米到几十万米的区域。 城域网（MAN），城域网的覆盖范围可以跨越几个街区甚至整个城市，范围大概 5-50km。 局域网（LAN），局域网一般是用微机或者工作站通过高速线路相连接，覆盖范围较小，一般几十米到几千米的区域；局域网在计算机配置的数量上没有太多限制，少的可以只有 2 台，多的可以有几百台。传统上，局域网采用广播技术，广域网采用交换技术。、 个人区域网（PAN）。个人区域网是指在个人工作的地方将电子设备用无线技术连接起来的网络，也常常称为无线个人区域网，覆盖直径大小约为 10m。 2、按传输技术分类 广播式网络：所有的联网计算机都共享一个公共的通信信道，当一台计算机利用共享的通信信道发送报文分组时，所有其他的计算机都会收听到这个分组，接收到该分组的计算机通过检查目的地址，来决定是否接受该分组，局域网基本上都采用广播式通信技术，广域网中的无线、卫星通信网络也采用广播式通信技术 点对点网络：每条物理线路链接一对计算机。如果通信的两台主机之间没有直接相连的线路，那么他们呢之间的分组传输通过中间结点的接收、存储和转发，直至目的节点。广域网基本属于点对点网络 3、按使用者分类 公用网 专用网 4、按拓扑结构分类 星型网络 总线型网络 环形网络 网状型网络 5、按交换技术分类 电路交换网络：电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。适用于数据量很大的实时通信 报文交换网络：报文交换用于邮局通信系统，邮局接收到一份报文之后，先存储下来，然后把相同目的地的报文一起转发到下一个目的地，这个过程就是存储转发过程。 分组交换网络：分组交换也使用了存储转发，但是转发的是分组而不是报文。把整块数据称为一个报文，由于一个报文可能很长，需要先进行切分，来满足分组能处理的大小。在每个切分的数据前面加上首部之后就成为了分组，首部包含了目的地址和源地址等控制信息。 优点：高效、灵活、迅速、可靠 缺点：时延大、开销大 三种交换方式的比较 6、按传输介质分类 有线网和无线网络 几种常用的信道复用技术 计算机网络的性能指标 带宽：表示网络通信线路所能传送数据的能力，时数字信道所能传送的“最高数据率”。单位时 bit/s 比特每秒。 时延：指一个数据由一段传送到另一端所需要的时间，由以下四部分组成 发送时延:主机或路由器发送数据帧所需要的时间，即：从发送数据帧的第一个比特算起到该帧的最后一个比特发送完毕所需要的时间。 计算公式：发送时延=分组长度/信道宽度 传播时延:电磁波在信道中传播一定的距离需要花费的时间。 计算公式：传播时延=信道长度/电磁波传播速率 处理时延:主机或路由器在收到分组时要花费一定的时间进行处理。例如：分析分组的首部信息、从分组中提取数据部分、进行差错检验或查找适当的路由等等。 排队时延:分组在经过网络传输时，要经过许多路由器。但分组在进入路由器后要先在输入队列中排队等待处理。排队时延的长短取决于网络中的通信量。 总时延：排队时延+发送时延+传播时延+处理时延 时延带宽积：指发送端连续发送的数据且发送的第一个比特发送即将到达终点时，发送端已经发送的比特数、即传播时延*带宽 吞吐量：指单位时间内通过某个网络的数据量 速率：计算机网络在数字信道上的传播速率，b/s（比特每秒） 往返时间(RTT)：从发送方发送数据开始，到发送方收到接收方确认。 发送时间=数据长度/发送速率 有效数据率=数据长度/（发送时间+RTT） 计算机网络的体系结构基本概念 ISO：国际化标准组织 OSI/RM:互联网法律上的国际标准 TCP/IP Suite:因特网实际上的国家标准 Network Protocols:数据交换遵守的标准、规则、约定。 网络体系结构：计算机网络各层及其协议的集合。 计算机网络分层可以使整个计算机网络各层之间独立，灵活性好，结构上可分割开，能促进标准化工作，呈现高内聚和低耦合，易于实现和维护。 OSI 参考模型（7 层）和 TCP/IP 模型OSI 参考模型（7 层） 应用层：能够产生网络流量和用户交互的程序 表示层：两个通信系统交换信息的表示方式，加密、压缩等、开发人员需考虑。 会话层：不同主机之间的各个进程建立会话（netstat -nb 可查看木马程序） 传输层：为主机建立进程间的通信，提供端到端的可靠传输服务，提供流量控制，服务质量，数据传输管理；传输层的协议有 UDP、TCP。 网络层：IP 地址编址，选择最佳路径 数据链路层：封装数据、差错控制、添加物理层地址、MAC 地址 物理层：定义通信设备的数据通信设备和逻辑链接方法，还有电压标准，接口标准，如机械特性，电气特性，功能特性，过程特性。 TCP/IP 模型（四层） 应用层：包括 OSI 模型的应用层、表示层、会话层 传输层：对应 OSI 的传输层 网络层：对于 OSI 的网络层 网络接口层：对于 OSI 接口的数据链路层和物理层 两个模型的比较： 学习计算机网络时，我们往往采用折中的办法，即综合 OSIhe TCP/Ip 的优点，如图所示 五层协议对应的数据单元： OSI 与 TCP/IP 各层的结构与功能、协议 在应用层交互的数据叫报文，报文经过运输层（TCP/UDP）转换成段，然后在网络层经过路径选择，在首部添加 IP 地址变成数据包（也叫IP 数据报），在数据链路层加上 MAC 地址组装成帧，在物理层传输时加上帧头帧位变成比特流。 数据在各层之间的传递过程下面为两个主机之间发送数据的整个过程： 在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。 路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。 计算机 2 的物理层收到比特流后交给数据链路层 数据链路层剥去帧首部和帧尾部后把帧的数据部分交给网络层 网络层剥去分组首部后把分组的数据部分交给运输层 应用层剥去应用层 PDU 首部后把应用程序数据交给应用进程 这样就收取到了主机 AP1 发来的应用程序数据 重要的知识点总结 计算机网络把许多计算机连接在一起，而互联网把许多网络连接在一起，是网络的网络。 小写字母 i 开头的 internet（互联网）是通用名词，它泛指由多个计算机网络相互连接而成的网络。在这些网络之间的通信协议（即通信规则）可以是任意的。 大写字母 I 开头的 Internet（互联网）是专用名词，它指全球最大的，开放的，由众多网络相互连接而成的特定的互联网，并采用 TCP/IP 协议作为通信规则，其前身为 ARPANET。Internet 的推荐译名为因特网，现在一般流行称为互联网。 路由器是实现分组交换的关键构件，其任务是转发收到的分别，这是网络的核心部分最重要的功能。分组交换采用存储转发的技术，表示把一个报文分成几个分组后在进行传送，在发送报文之前，先把报文划分成为一个个更小的等长数据段。在每个数据段的前面加上一些由必要的控制信息组成的首部后，就构成了一个分组，分组又称为包，分组时在互联网中传送的数据单元，正是由于分组的头部包含了诸如目的地址和源地址等重要的控制信息，每一个分组才能在互联网中独立选择传输路径，并且正确的交付分组传输的终点。 互联网按工作方式可划分为边缘部分和核心部分。主机在网络的边缘部分，其作用是进行信息处理，由大量的网络和连接这些网络的路由器组成核心部分，其作用是提供联通性和交换。 计算机通信是计算机中进程（即运行着的程序）之间的通信。计算机网络采用的通信方式是客户-服务器方式（C/S 方式）和对等连接方式（P2P 方式）。 客户和服务器都是指通信中所涉及的应用进程。客户是服务请求方，服务器是服务提供方。 按照作用范围的不同，计算机网络分为广域网 WAN，城域网 MAN，局域网 LAN，个人区域网 PAN。 计算机网络最常用的性能指标是：速率，带宽，吞吐量，时延（发送时延，处理时延，排队时延），时延带宽积，往返时间和信道利用率。 网络协议即协议，是为进行网络中的数据交换而建立的规则。计算机网络的各层以及其协议集合，称为网络的体系结构。 五层体系结构由应用层，运输层，网络层（网际层），数据链路层，物理层组成。运输层最主要的协议是 TCP 和 UDP 协议，网络层最重要的协议是 IP 协议。","raw":null,"content":null,"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"计算机基础知识","slug":"计算机网络/计算机基础知识","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"408","slug":"408","permalink":"https://fan-yu-feng.github.io/tags/408/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络-物理层","slug":"计算机网络/计算机网络-1-物理层","date":"2020-08-08T09:15:37.000Z","updated":"2021-12-24T03:26:59.066Z","comments":true,"path":"2020/08/08/计算机网络/计算机网络-1-物理层/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-1-%E7%89%A9%E7%90%86%E5%B1%82/","excerpt":"物理层物理层的基本概念物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体\n主要任务：确定与传输媒体接口的一些特性：\n\n机械特性：接口形状、大小、引脚 数码\n电气特性：如规定电压范围（-5V到+5）\n功能特性：如规定-5V表示0.+5V表示1\n过程特性：规定连接时各个相关部件的工作步骤\n","text":"物理层物理层的基本概念物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体 主要任务：确定与传输媒体接口的一些特性： 机械特性：接口形状、大小、引脚 数码 电气特性：如规定电压范围（-5V到+5） 功能特性：如规定-5V表示0.+5V表示1 过程特性：规定连接时各个相关部件的工作步骤 基本术语 数据：运送消息的实体 信号：数据的电气的或者电磁的表现，或者说信号时适合在传输介质上传输的对象 模拟信号：代表消息的参数的取值时连续的 数字信号：代表消息的参数子在取值时时离散的 码元：使用时间域的波形来表示数字信号时，表示不同的离散数值的基本波形。 比特率：单位时间内传送的比特数 波特率：单位时间内载波调制状态改变的次数，针对数据信号对载波的调制速率 奈氏准则：在任何信道中，码元的传输的效率是有上限的，传输速率超过此上限，就会出现严重的码间串扰问题。使接收端对码元的判决（即识别）成为不可能。 信噪比：信号的平均功率和噪声的平均功率之比，记为S/N。信噪比（dB）=10*log10（S/N） 有关信道的基本概念信道：信号的传输媒体，有以下几种通信方式 单工通信（单向通信)：只有一个方向的通信，无反方向的通信（如广播电视） 半双工通信（双向交替通信）：通信双方可以互发消息，但是不能同时发消息（如对讲机） 全双工通信（双向同时通信）：可以同时收发信息（如打电话） 基带信号：来自信源的信号，指没有经过调制的数字信号或模拟信号。如计算机输出的数据信号：文件， 调制：基带信号中包含了许多低频的成分，甚至直流的成分，许多信道不支持低频或者直流分量，因此必须对基带信号进行调频 带通信号：基带信号经过载波调制后，把频率范围搬移到较高判断以便在信道中传输（频率高能使信号传输距离更远）几种最基本的调制方法 调幅（AM）：载波的振幅随基带数字信号而变化。 调频（FM）：载波的频率随基带的数字信号而变化 调相（PM）：在波的初始相位随基带数字信号而变化 常用编码 单极性不归零码：只使用一个电压值，高电平表示1，没电压表示0（如图a） 双极性不归零码：用正电平和负电平分别表示二进制数据的0和1，正负幅值相等(如图b) 单极性归零码：只使用一个电压值，高电平表示1，没电压表示0（如图a） 双极性归零码：用正电平和负电平分别表示二进制数据的0和1，正负幅值相等(如图b) 曼彻斯特编码：位周期中心向上跳代表0，向下跳代表1 差分曼彻斯特编码：位中心始终有跳变，边界有跳变代表0，无跳变代表1 差分曼彻斯特编码与曼彻斯特编码相同，但是抗干扰性能强于曼彻斯特编码 曼彻斯特编码与前两种相比能够表示没有数据传输，具有自同步能力 奈氏准则和和香农定理因为在任何实际的信道中，在传输信号的适合会产生各种失真以及带来多种干扰， 码元传输的速率越高，或者传输的距离越远，在信道中输出端的波形的失真就越严重 奈氏准则：在任何信道中，码元传输的速率是有上限的，否则就会出现码间串扰的问题，使接收端对码元的判决（即识别）成为不可能。如果信道的频带越宽，也就是能够通过的信号高频分量越多，那么就可以用更高的速率传送码元而不出现码间串扰。 理想低通信道最高码元传输速率=2WBaud（无干扰） W是理想低通信道的带宽，单位是Hz Baud是波特，是码元传输速率的单位 波特和比特的区别 Bit是信息量，如果一个码元含有三个Bit的信息量，1波特=3Bit/s （000-111） 香农定理 香农定理给出了带宽受限且有高斯白噪声干扰的信道的极限，无差错的信息传输速率 定义为：$$C=Wlog2(1+S/N) b/s$$ W为信道的带宽（Hz） S为信道内所传信号的平均功率 N为信道内部的高斯噪声功率 信噪比：信号的平均规律和噪声的平均功率之比。记为S/N，用dB为度量单位。香农公式表明：信道的带宽或信道中的信噪比越大，信息的极限传输速率就越高。香农公式和奈氏准则适用范围：香农公式：仅模拟信奈氏准则：模拟信号、数字信号都可。 奈氏准则和香农定理应用范围： 物理层下的传输媒体传输媒体分两大类 导引型传输媒体：通过固定媒体（铜线或者光纤）传播 非导引型传输媒体：在自由空间中传播（无线传播） 导引型传输媒体双绞线 屏蔽双绞线STP 无屏蔽双绞线UTP 同轴电缆 50欧同轴电缆：用于数字传输，多用于基带传输 70欧同轴电缆：用于模拟传输 光纤（外部干扰对其影响比较小） 光线在光纤中的反折射 光纤内部工作原理 多模光纤和单模光纤 单模光纤：光纤直径较小到一定的范围，使光线在传播中不产生多次反射，传播性能好 多模光纤：多条不同角度入射的光线在同一条光纤中传输（适合近距离） 非导引型传输媒体 无线传输所使用的频段很广。 短波通信主要是靠电离层的反射，但短波信道的通信质量较差。 微波在空间主要是直线传播 地面微波接力通信 卫星通信 信道复用技术 频分复用FDM用户在分配到一定的频带后，在通信过程中自始至终都占用这个频带。频分复用的所有用户在同样的时间占用不同的带宽资源（请注意，这里的“带宽”是频率带宽而不是数据的发送速率） 时分复用（Time Diviion Mutiplexing）时分复用技术则是将时间划分为一段段等长的时分复用帧（TDM帧）。每一个时分复用的用户在每一个TMD帧中占用了固定的时间段，时分复用的所有用户是在不同的时间占用同样的频带宽度 对于一些用户没使用信道时，则会造成资源浪费。 因此对于这个缺点，出现了改进的时分复用技术：统计时分复用技术 在数据帧中添加标记，来区分数据来源 波分复用WDM波分复用就是对光的频分复用 码分复用CDM(code Division multiplexing)​ 各个用户使用经过挑选的不同码型，靠不同的编码来区分各个用户原始信号的一种复用方式 ​ 每一个比特时间划分为m个短的时间间隔，称为码片 ​ 每个站被指派一个唯一的一个m bit码片序列 如果发送比特1，则发送自己的m bit码片序列 如果发送比特0，则发送该码片序列的二进制反码 特点 每个站分配的码片序列不仅必须各不相同，并且还必须互相正交(orthogonal)。 在实用的系统中是使用伪随机码序列。 令向量 S 表示站 S 的码片向量，令 T 表示其他任何站的码片向量。两个不同站的码片序列正交，就是向量 S 和T 的规格化内积(inner product)都是 0： 示例： 令向量 S 为(–1 –1 –1 +1 +1 –1 +1 +1)，向量 T 为(–1 –1 +1 –1 +1 +1 +1 –1)。把向量 S 和 T 的各分量值代入(2-3)式就可看出这两个码片序列是正交的。 他们每个位数相乘，除于8结果为0 另一个特点就是任何一个码片向量和该码片向量自己的规格化内积都是1 。一个码片向量和该码片反码的向量的规格化内积值是 –1。 CDMA的工作原理 分析：在S站发送1时，与S站的码片序列与扩频序列Sx的内积为1，发送0时内积为-1.**而其他站（T）的发送信号与S站的码片序列内积都为0**，就会被过滤掉，因此最终就能得到我们需要的接受的站的信号。（可以对照着图看格式化内积的公式，动手运算一遍就理解了） 例题：如下面四个码片序列 A：（-1，-1，-1，+1，+1，-1，+1，+1） B：（-1，-1，+1，-1，+1，+1，+1，-1） C：（-1，+1，-1，+1，+1，+1，-1，-1） D：（-1，+1，-1，-1，-1，-1，+1，+1） 收到的码片序列为R：（-1，+1，-3，+1，-1，-3，+1，+1） A*R=(1-1+3+1-1+3+1+1)/8=1 B*R=(1-1-3-1-1-3+1-1)/8=-1 C和R的格式化内积为0，D和R的格式化内积为1 由结果可知，C没收到信号，其他的均收到了这个格式化内积的信号 数字传输系统早期数字传输系统主要有两个缺点： 速率标准不统一 如果不对高次群的数字传输速率进行标准化，国际范围的高速数据传输就很难实现。 不是同步传输 在过去相当长的时间，为了节约经费，各国的数字网主要是采用准同步方式。 脉码调制 PCM 体制最初是为了在电话局之间的中继线上传送多路的电话。 由于历史上的原因，PCM 有两个互不兼容的国际标准，即北美的 24 路PCM（简称为 T1）和欧洲的 30 路 PCM（简称为 E1）。我国采用的是欧洲的 E1 标准。 E1 的速率是 2.048 Mb/s，而 T1 的速率是 1.544Mb/s。 当需要有更高的数据率时，可采用复用的方法 1、同步光纤网络SONET。整个同步光纤网络的主时钟来自于一个非常昂贵的铯原子钟；其基础传输速率是51.82Mbit/s，此速率对电信号称为第1级同步传送信号，即STS-1；对光信号称为第1级光载波，即OC-1。 2、同步数字系列SDH（以SONET为基础），一般认为SDH和SONET是同义词，不同点在于 SDH的基本速率是155.52Mbit/s，称为第1级同步传送模块，即STM-1，相当于SONET中OC-3的速率。 宽带接入技术ADSL技术ADSL(Asymmetric Digital Subscriber Line)：非对称 xDSL技术就时用数字技术对现有的模拟电话用户线进行改造，使它能够承载宽带业务（DSL 就是数字用户线(Digital Subscriber Line)的缩写。而 DSL 的前缀 x 则表示在数字用户线上实现的不同宽带方案。 ） 如图，该技术将0-4kHz的地段频率谱段留给传统的电话使用，而原来没有使用的高端频率谱段留给用户上网使用。其中，26-108Hz的频谱留给用户上传数据、138-1104留给用户下载数据使用 而接入则使用分离器分离信号，低频的信号则接电话，高频的接电脑。（一般在用户的两端都有ADSL调制解调器） DMT技术 DMT 调制技术采用频分复用的方法，把 40 kHz 以上一直到 1.1 MHz 的高端频谱划分为许多的子信道，其中 25 个子信道用于上行信道，而 249 个子信道用于下行信道。 每个子信道占据 4 kHz 带宽（严格讲是 4.3125 kHz），并使用不同的载波（即不同的音调）进行数字调制。这种做法相当于在一对用户线上使用许多小的调制解调器并行地传送数据。 ![image-20200801105743973](https://gitee.com/Fan_Yu_Feng/blogImage/raw/master/img/计算机网络/2.物理层/DMT 技术的频谱分布.png) 光纤同轴混合网（HFC）Hybrid Fiber CoaxHFC网是在目前覆盖很广的有线电视网CATV的基础上开发的一种居民宽带接入网。 HFC 网除可传送 CATV 外，还提供电话、数据和其他宽带交互型业务。 现有的 CATV 网是树形拓扑结构的同轴电缆网络，它采用模拟技术的频分复用对电视节目进行单向传输。而 HFC 网则需要对 CATV 网进行改造， HFC的主要特点 HFC网的主干线路采用光纤，HFC 网将原 CATV 网中的同轴电缆主干部分改换为光纤，并使用模拟光纤技术。 在模拟光纤中采用光的振幅调制 AM，这比使用数字光纤更为经济。 模拟光纤从头端连接到光纤结点(fiber node)，即光分配结点 ODN (Optical Distribution Node)。在光纤结点光信号被转换为电信号。在光纤结点以下就是同轴电缆。 FTTx 技术 （光纤到……）FTTx（光纤到……）也是一种实现宽带居民接入网的方案。这里字母 x 可代表不同意思。 光纤到家 FTTH (Fiber To The Home)：光纤一直铺设到用户家庭可能是居民接入网最后的解决方法。 光纤到大楼 FTTB (Fiber To The Building)：光纤进入大楼后就转换为电信号，然后用电缆或双绞线分配到各用户。 光纤到路边 FTTC (Fiber To The Curb)：从路边到各用户可使用星形结构双绞线作为传输媒体。 物理层设备中继器​ 中继器又称转发器，主要工作内容是将信号放大再转发出去，以消除信号经过一段长时间的电缆后，因为噪声或者其他原因而造成的失真和衰减。（增加信号强度），他工作于物理层，只是起到扩展传输距离的作用，对高层协议是透明的。 优点 扩大了通信距离。 增加了节点的最大数目。 各个网段可使用不同的通信速率。 提高了可靠性。当网络出现故障时，一般只影响个别网段。 性能得到改善 缺点 由于中继器对收到被衰减的信号再生（恢复）到发送时的状态，并转发出去，增加了延时。 CAN总线的MAC子层并没有流量控制功能。当网络上的负荷很重时，可能因中继器中缓冲区的存储空间不够而发生溢出，以致产生帧丢失的现象。 中继器若出现故障，对相邻两个子网的工作都将产生影响。 集线器（Hub）集线器实质上是一个多端口的中继器，Hub主要使用双绞线组建共享网络，集线器的主要功能是对接收到的信号进行再生整形放大，以扩大网络的传输距离，同时把所有节点集中在以它为中心的节点上。 几种基本的调制方法基带信号往往包含有较多的低频成分，甚至有直流成分，而许多信道并不能传输这种低频分量或直流分量。为了解决这一问题，就必须对基带信号进行调制(modulation)。 最基本的二元制调制方法有以下几种： 调幅(AM)：载波的振幅随基带数字信号而变化。 调频(FM)：载波的频率随基带数字信号而变化。 调相(PM) ：载波的初始相位随基带数字信号而变化。 最近访客","raw":null,"content":null,"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"计算机基础知识","slug":"计算机网络/计算机基础知识","permalink":"https://fan-yu-feng.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://fan-yu-feng.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"hexo 搭建博客-博客搭建（1）","slug":"Hexo搭建/hexo 搭建博客-博客搭建（1）","date":"2020-08-08T08:54:41.000Z","updated":"2021-12-24T03:26:59.016Z","comments":true,"path":"2020/08/08/Hexo搭建/hexo 搭建博客-博客搭建（1）/","link":"","permalink":"https://fan-yu-feng.github.io/2020/08/08/Hexo%E6%90%AD%E5%BB%BA/hexo%20%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2-%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%881%EF%BC%89/","excerpt":"补充：之前没怎么看官方文档，现在看了官方文档，发现许多问题都好解决了挺多。贴几个相关的官方链接和 Github链接。\nhexo next  yilia\n安装Nodejs和git\nNode.js (Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本)\nGit\n\n在dos命令行下输入以下命令安装\n\nnpm install -g cnpm –registry=http://registry.npm.taobao.org \n","text":"补充：之前没怎么看官方文档，现在看了官方文档，发现许多问题都好解决了挺多。贴几个相关的官方链接和 Github链接。 hexo next yilia 安装Nodejs和git Node.js (Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本) Git 在dos命令行下输入以下命令安装 npm install -g cnpm –registry=http://registry.npm.taobao.org 安装 hexo框架 cnpm install -g hexo-cli hexo -v #查看hexo版本 cd进入你的博客文件 hexo init #生成博客 初始化博客 访问博客 hexo -s 访问博客 在浏览器中输入 http://localhost:4000/ 现在博客就初期搭建好了，接下来就准备将其部署到网上，可以选择github或者gitee 我选择码云，速度比较快一点 创建gitee 仓库准备工作 接下来 去码云创建一个仓库（名字和你用户名一样） 如果没有注册码云的可以去注册一个 创建完之后在hexo的目录使用git 输入以下内容 vim _condfig.yml 在里面修改添加如下内容（最末尾位置） 123type: gitrepo: 你创建的码云仓库名称branch: master 部署之前需要先下载git依赖 cpnm install –save hexo-deployer-git hexo clean 清理一下 hexo g 重新生成内容 hexo d 部署 开启gitee page 部署博客到gitee这样就可以部署到码云上了 文章/主题配置更换主题：我使用yilia的主题 源地址：https://github.com/litten/hexo-theme-yilia 在hexo的源目录下 切换到主题目录 theme 使用git克隆该仓库 git clone https://github.com/litten/hexo-theme-yilia.git 然后打开 _config.yml文件，将主题改成如下（对应下载的目录名字） 记得将 .git文件目录删除掉， 不删除的话会影响后续分支目录的上传 重新启动一下 看看有没有错误 hexo clean hexo g hexo s 如果出现下图就没问题了 将其部署到gitee上去 使用命令就行了 hexo d 但是部署后出现了一个问题，在本地是更新主题后的页面，而远程更新后的页面没改变 我去查了一下，hexo clean 只是把public文件删除，但是hexo g的时候发现你并没有改配置文件，所以就没有改动，记录没改变，.deploy_git提交记录也就没改动，所以远程没改动配置文件。 我将.deploy_git文件删除之后，再执行hexo d -g 就更新成功了 头像设置存放位置头像/图标图片的存放位置是/themes/yilia/source/下任意位置，可以自己新建一个文件夹存放，我存放在assets文件夹下。 配置设置配置文件为/themes/yilia/_config.yml。设置头像为配置文件中avatar一项，设置图标为配置文件中favicon一项，设置路径的根目录为/themes/yilia/source/。例如，我的头像存放的地址是/themes/yilia/source/assets/me.png，设置则为avatar: /assets/me.png。（图标同理） 文章设置创建“分类”选项打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page categories 成功后会提示： 1INFO Created: ~/Documents/blog/source/categories/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1234---title: 文章分类date:--- 添加type: &quot;categories&quot;到内容中，添加后是这样的： 12345---title: categorisedate: 2020-08-08 17:06:45type: &quot;categories&quot;--- 保存并关闭文件。 给文章添加“categories”属性打开需要添加分类的文章，为其添加categories属性。下方的categories: web前端表示添加这篇文章到“web前端”这个分类。注意：hexo一篇文章只能属于一个分类，也就是说如果在“- web前端”下方添加“-xxx”，hexo不会产生两个分类，而是把分类嵌套（即该文章属于 “- web前端”下的 “-xxx ”分类）。 123456---title: 计算机网络概述date: 2020-08-08 17:15:37categories: - 计算机网络--- 至此，成功给文章添加分类，点击首页的“分类”可以看到该分类下的所有文章。当然，只有添加了categories: xxx的文章才会被收录到首页的“分类”中。 创建“标签”选项生成“标签”页并添加tpye属性打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page tags 成功后会提示： 1INFO Created: ~/Documents/blog/source/tags/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 12345---title: 分类date: 2020-08-08 17:06:45type: &quot;categories&quot;--- 可以改成你要该的分类名称，添加type: &quot;tags&quot;到内容中，添加后是这样的： 12345---title: 标签date: 2020-08-08 17:08:42type: &quot;tags&quot;--- 保存并关闭文件。 2.2 给文章添加“tags”属性打开需要添加标签的文章，为其添加tags属性。下方的tags:下方的- jQuery - 表格 - 表单验证就是这篇文章的标签了 1234567891011---title: 计算机网络概述date: 2020-08-08 17:15:37categories: - 计算机网络tags: - 408 - 网络--- 至此，成功给文章添加分类，点击首页的“标签”可以看到该标签下的所有文章。当然，只有添加了tags: xxx的文章才会被收录到首页的“标签”中。 细心的朋友可能已经发现，这两个的设置几乎一模一样！是的，没错，思路都是一样的。所以我们可以打开scaffolds/post.md文件，在tages:上面加入categories:,保存后，之后执行hexo new 文章名命令生成的文件，页面里就有categories:项了。 scaffolds目录下，是新建页面的模板，执行新建命令时，是根据这里的模板页来完成的，所以可以在这里根据你自己的需求添加一些默认值。","raw":null,"content":null,"categories":[{"name":"blog","slug":"blog","permalink":"https://fan-yu-feng.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://fan-yu-feng.github.io/tags/hexo/"}]}]}